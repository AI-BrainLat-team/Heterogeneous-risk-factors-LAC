{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "import matplotlib.font_manager\n",
    "from matplotlib import style\n",
    "style.use('seaborn') or plt.style.use('seaborn')\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, f1_score, accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "import operator\n",
    "\n",
    "\n",
    "from xgboost import plot_importance\n",
    "\n",
    "\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import PatchCollection\n",
    "import scipy.stats as ss\n",
    "\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import Lasso, MultiTaskLasso, Ridge, ElasticNet\n",
    "import math\n",
    "\n",
    "from regressors import stats\n",
    "\n",
    "\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import PatchCollection\n",
    "import scipy.stats as ss\n",
    "\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "\n",
    "import scipy\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_bib as mb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color(var, X_cat_, color_dict_):\n",
    "\n",
    "    X_factors = list(X_cat_.factors)\n",
    "    X_name = list(X_cat_.newname)\n",
    "\n",
    "    index_code = X_name.index(var)\n",
    "    cat = X_factors[index_code]\n",
    "\n",
    "    return color_dict_[cat]\n",
    "\n",
    "color_dict = {}\n",
    "color_dict['Country'] = '#484849'\n",
    "color_dict['HF'] = '#A31300'\n",
    "color_dict['LSF'] = '#FF9E0D'\n",
    "color_dict['PSF'] = '#FF4800'\n",
    "color_dict['SDHF'] = '#1C4F9E'\n",
    "color_dict['DF'] = '#009E32'\n",
    "\n",
    "def get_bar_colors(data_, X_cat_):\n",
    "    color_dict = {}\n",
    "    color_dict['Country'] = '#484849'\n",
    "    color_dict['HF'] = '#A31300'\n",
    "    color_dict['LSF'] = '#FF9E0D'\n",
    "    color_dict['PSF'] = '#FF4800'\n",
    "    color_dict['SDHF'] = '#1C4F9E'\n",
    "    color_dict['DF'] = '#009E32'\n",
    "    \n",
    "    #color_dict = {}\n",
    "    #color_dict = {'DF':'#5975a4', 'MF':'#cc8963', 'SF':'#5f9e6e', 'SLF':'#b55d60',\n",
    "    #              'n':'#857aab', 'country':'#8d7866'}#, '#d095bf'}\n",
    "\n",
    "    X_factors = list(X_cat_.factors)\n",
    "    X_name = list(X_cat_.newname)\n",
    "\n",
    "    bar_color_total = []\n",
    "    for i in list(data_.Features):\n",
    "        if(i == 'Country'):\n",
    "            bar_color_total.append(color_dict['Country'])\n",
    "            continue\n",
    "        index_code = X_name.index(i)\n",
    "        cat = X_factors[index_code]\n",
    "        bar_color_total.append(color_dict[cat])\n",
    "    return bar_color_total\n",
    "\n",
    "\n",
    "def plot_estimate_value(regression_model, X_cat_ = [], title = '',  xlim =[0, 2] ,fig_size = (8,12), size = 14, pvalue_type = 'False'):\n",
    "\n",
    "    df = regression_model[0]\n",
    "    df.index.name = 'Features'\n",
    "    df = df.iloc[1:-3, 0:-1]\n",
    "\n",
    "    for i in range(3):\n",
    "            #print(i, X_RAW_edu_level[X_RAW_edu_level.columns[i]].dtype)\n",
    "        df[df.columns[i]] = np.abs(pd.to_numeric(df[df.columns[i]],errors = 'coerce'))\n",
    "\n",
    "    df = df.reset_index()\n",
    "    data = df.sort_values('Estimate', ascending=False)\n",
    "\n",
    "    \n",
    "    if(len(X_cat_)>0):\n",
    "        \n",
    "        bar_color = get_bar_colors(data, X_cat_)\n",
    "        \n",
    "        plt.title(title)\n",
    "        sns.barplot(x=\"Estimate\", y=\"Features\", data = data, palette =bar_color)\n",
    "        plt.xlim(xlim)\n",
    "    else:\n",
    "        plt.title(title)\n",
    "        sns.barplot(x=\"Estimate\", y=\"Features\", data = data, color = 'darkblue')\n",
    "        plt.xlim(xlim)\n",
    "\n",
    "\n",
    "    y_step=0  \n",
    "    for i in range(df.shape[0]):\n",
    "        if(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],3)<=0.01):\n",
    "            color = 'green'\n",
    "        elif(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],3)<=0.05):\n",
    "            color = 'gray'\n",
    "        else:\n",
    "            color = 'red'        \n",
    "        \n",
    "        if(pvalue_type == 'color'):\n",
    "                plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]-0.005, y_step, \n",
    "                                 '' + str(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],2)),\n",
    "                                 size= size, rotation=0.,\n",
    "                                 ha=\"left\", va=\"center\", color = 'white',\n",
    "                                 bbox=dict(boxstyle=\"round\",\n",
    "                                           ec=color,\n",
    "                                            fc=color,\n",
    "                                           )\n",
    "                                 )\n",
    "                y_step+=1\n",
    "\n",
    "        elif(pvalue_type == 'value'):\n",
    "                plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                 '(' + str(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],8))+')',\n",
    "                                 size= size, rotation=0.,\n",
    "                                 ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                 )\n",
    "                y_step+=1\n",
    "        else:\n",
    "            if(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step]<0.01):\n",
    "                \n",
    "                    plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                     '**',\n",
    "                                     size= size, rotation=0.,\n",
    "                                     ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                     )\n",
    "            elif(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step]>= 0.01 and df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step]<0.05):\n",
    "                  \n",
    "                    plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                     '*',\n",
    "                                     size= size, rotation=0.,\n",
    "                                     ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                     )  \n",
    "            else:\n",
    "                    plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                     '',\n",
    "                                     size= size, rotation=0.,\n",
    "                                     ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                     )      \n",
    "            y_step+=1\n",
    "            \n",
    "         \n",
    "    text_diff =xlim[1]/2.2\n",
    "    plt.text(xlim[1] - text_diff, df.shape[0]-1.5,r'$ R^2 $(' + str(np.round(regression_model[1],2)) + ') \\t$F^2 $(' + str(np.round(regression_model[3],2)) + ')',\n",
    "                             size= 12, rotation=0.,\n",
    "                             ha=\"left\", va=\"center\", color = 'black',\n",
    "                             bbox=dict(boxstyle=\"round\",\n",
    "                                       ec='gray',\n",
    "                                        fc='gray',\n",
    "                                       )\n",
    "                             )\n",
    "\n",
    "\n",
    "    plt.locator_params(axis='x', nbins=4)\n",
    "    \n",
    "    \n",
    "    \n",
    "def plot_estimate_value_no_sort(regression_model, title = '',  xlim =[0, 2] ,fig_size = (8,12), size = 14, ylabel = True, ylabelR = False ):\n",
    "\n",
    "    df = regression_model\n",
    "    df.index.name = 'Features'\n",
    "    df = df.iloc[1:-3, 0:-1]\n",
    "\n",
    "    for i in range(3):\n",
    "            #print(i, X_RAW_edu_level[X_RAW_edu_level.columns[i]].dtype)\n",
    "        df[df.columns[i]] = np.abs(pd.to_numeric(df[df.columns[i]],errors = 'coerce'))\n",
    "\n",
    "    df = df.reset_index()\n",
    "\n",
    "    #plt.figure(figsize=(8,12))\n",
    "    plt.title(title)\n",
    "    sns.barplot(x=\"Estimate\", y=\"Features\", data = df, color = 'Brown')\n",
    "    if(ylabel == False):\n",
    "        plt.ylabel('')\n",
    "        plt.yticks([])\n",
    "    plt.xlim(xlim)\n",
    "    \n",
    "    if(ylabelR):\n",
    "        plt.tick_params (axis = 'y', which = 'both', labelleft = False, labelright = True)\n",
    "\n",
    "    y_step=0  \n",
    "    for i in range(df.shape[0]):\n",
    "        \n",
    "        if(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],3)<=0.01):\n",
    "            color = 'green'\n",
    "        elif(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],3)<=0.05):\n",
    "            color = 'yellow'\n",
    "        else:\n",
    "            color = 'red'   \n",
    "            \n",
    "        plt.text(df['Estimate'].iloc[y_step]+0.015, y_step, \n",
    "                         '' + str(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],5)),\n",
    "                         size= size, rotation=0.,\n",
    "                         ha=\"left\", va=\"center\", color = color,\n",
    "                         bbox=dict(boxstyle=\"round\",\n",
    "                                   ec=(50/255, 50/255, 50/255),\n",
    "                                    fc=(50/255, 50/255, 50/255),\n",
    "                                   )\n",
    "                         )\n",
    "        y_step+=1\n",
    "        \n",
    "\n",
    "def conf_interval(database):\n",
    "    r_squared_list = []\n",
    "\n",
    "    y_database = database['MMSE']\n",
    "    X_database = database.drop('MMSE', axis=1)\n",
    "\n",
    "    for i in range(0,100,10):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_database, y_database, train_size=0.75, test_size=.25, random_state=i)\n",
    "\n",
    "        opt_Ridge = BayesSearchCV(\n",
    "            Ridge(),\n",
    "            {\n",
    "                'alpha': ( 0.0001, 0.01, 0.001),\n",
    "                'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "                'max_iter': (1000, 10000, 100000, 1000000),\n",
    "            },\n",
    "            n_iter=10,\n",
    "            random_state=i, \n",
    "            scoring='r2',\n",
    "            cv=3\n",
    "        )\n",
    "\n",
    "        opt_Ridge.fit(X_train, y_train)\n",
    "\n",
    "        r_squared_list.append(opt_Ridge.score(X_test, y_test))\n",
    "\n",
    "\n",
    "    print(r'99% confidence interval (+-', np.round(np.std(r_squared_list)*2.58, 4),')')\n",
    "    return np.round(np.std(r_squared_list)*2.58, 4)\n",
    "\n",
    "\n",
    "def adj_r2_score_and_r2_score(clf, X, y):\n",
    "    n = X.shape[0]  # Number of observations\n",
    "    p = X.shape[1]  # Number of features\n",
    "    r_squared = r2_score(y, clf.predict(X))\n",
    "    return [1 - (1 - r_squared) * ((n - 1) / (n - p - 1)), r_squared]\n",
    "\n",
    "\n",
    "def mse(clf, X, y):\n",
    "    return mean_squared_error(y, clf.predict(X))\n",
    "\n",
    "def rmse(clf, X, y):\n",
    "    mse = mean_squared_error(y, clf.predict(X))\n",
    "    return math.sqrt(mse)    \n",
    "\n",
    "def coef_se(clf, X, y):\n",
    "    n = X.shape[0]\n",
    "    X1 = np.hstack((np.ones((n, 1)), np.matrix(X)))\n",
    "    se_matrix = scipy.linalg.sqrtm(\n",
    "        metrics.mean_squared_error(y, clf.predict(X)) *\n",
    "        np.linalg.inv(X1.T * X1)\n",
    "    )\n",
    "    return np.diagonal(se_matrix)\n",
    "\n",
    "def coef_tval(clf, X, y):\n",
    "    a = np.array(clf.intercept_ / coef_se(clf, X, y)[0])\n",
    "    b = np.array(clf.coef_ / coef_se(clf, X, y)[1:])\n",
    "    return np.append(a, b)\n",
    "\n",
    "def coef_tval_XGB_tree(clf, X, y):\n",
    "    a = np.nan\n",
    "    b = np.array(clf.feature_importances_ / coef_se(clf, X, y)[1:])\n",
    "    return np.append(a, b)\n",
    "\n",
    "def coef_pval(clf, X, y):\n",
    "\n",
    "    n = X.shape[0]\n",
    "    t = coef_tval(clf, X, y)\n",
    "    p = 2 * (1 - scipy.stats.t.cdf(abs(t), n - 1))\n",
    "    return p\n",
    "\n",
    "def coef_pval_XGB_tree(clf, X, y):\n",
    "\n",
    "    n = X.shape[0]\n",
    "    t = coef_tval_XGB_tree(clf, X, y)\n",
    "    p = 2 * (1 - scipy.stats.t.cdf(abs(t), n - 1))\n",
    "    return p\n",
    "\n",
    "def residuals(clf, X, y, r_type='standardized'):\n",
    "\n",
    "    # Make sure value of parameter 'r_type' is one we recognize\n",
    "    assert r_type in ('raw', 'standardized', 'studentized'), (\n",
    "        \"Invalid option for 'r_type': {0}\".format(r_type))\n",
    "    y_true = y.view(dtype='float')\n",
    "    # Use classifier to make predictions\n",
    "    y_pred = clf.predict(X)\n",
    "    # Make sure dimensions agree (Numpy still allows subtraction if they don't)\n",
    "    assert y_true.shape == y_pred.shape, (\n",
    "        \"Dimensions of y_true {0} do not match y_pred {1}\".format(y_true.shape,\n",
    "                                                                  y_pred.shape))\n",
    "    # Get raw residuals, or standardized or standardized residuals\n",
    "    resids = y_pred - y_true\n",
    "    if r_type == 'standardized':\n",
    "        resids = resids / np.std(resids)\n",
    "    elif r_type == 'studentized':\n",
    "        # Prepare a blank array to hold studentized residuals\n",
    "        studentized_resids = np.zeros(y_true.shape[0], dtype='float')\n",
    "        # Calcluate hat matrix of X values so you can get leverage scores\n",
    "        hat_matrix = np.dot(\n",
    "            np.dot(X, np.linalg.inv(np.dot(np.transpose(X), X))),\n",
    "            np.transpose(X))\n",
    "        # For each point, calculate studentized residuals w/ leave-one-out MSE\n",
    "        for i in range(y_true.shape[0]):\n",
    "            # Make a mask so you can calculate leave-one-out MSE\n",
    "            mask = np.ones(y_true.shape[0], dtype='bool')\n",
    "            mask[i] = 0\n",
    "            loo_mse = np.average(resids[mask] ** 2, axis=0)  # Leave-one-out MSE\n",
    "            # Calculate studentized residuals\n",
    "            studentized_resids[i] = resids[i] / np.sqrt(\n",
    "                loo_mse * (1 - hat_matrix[i, i]))\n",
    "        resids = studentized_resids\n",
    "    return resids\n",
    "\n",
    "\n",
    "def f_squared(clf, X, y):\n",
    "\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    r_squared = metrics.r2_score(y, clf.predict(X))\n",
    "    return r_squared  / (1 - r_squared)\n",
    "\n",
    "\n",
    "\n",
    "def summary(clf, X, y, xlabels=None, regressor = ''):\n",
    "\n",
    "    print('Resumen del regresor ' + regressor + '\\n')\n",
    "    \n",
    "    ncols = X.shape[1]\n",
    "    if xlabels is None:\n",
    "        xlabels = np.array(\n",
    "            ['x{0}'.format(i) for i in range(1, ncols + 1)], dtype='str')\n",
    "    elif isinstance(xlabels, (tuple, list)):\n",
    "        xlabels = np.array(xlabels, dtype='str')\n",
    "\n",
    "    # Create data frame of coefficient estimates and associated stats\n",
    "    coef_df = pd.DataFrame(\n",
    "        index=['_intercept'] + list(xlabels),\n",
    "        columns=['Estimate','t value', 'p value']\n",
    "    )\n",
    "    \n",
    "    if(regressor == 'XGBRegressor'):\n",
    "        coef_df['Estimate'] = np.concatenate(\n",
    "            (np.round(np.array([clf.intercept_[0]]), 6), np.round((clf.coef_), 6)))\n",
    "        #coef_df['MSE'] = np.round(mse(clf, X, y), 6)\n",
    "        #coef_df['RMSE'] = np.round(rmse(clf, X, y), 6)\n",
    "        coef_df['t value'] = np.round(coef_tval(clf, X, y), 4)\n",
    "        coef_df['p value'] = np.round(coef_pval(clf, X, y), 20)\n",
    "        # Create data frame to summarize residuals\n",
    "        resids = residuals(clf, X, y, r_type='raw')\n",
    "        resids_df = pd.DataFrame({\n",
    "            'Min': pd.Series(np.round(resids.min(), 4)),\n",
    "            '1Q': pd.Series(np.round(np.percentile(resids, q=25), 4)),\n",
    "            'Median': pd.Series(np.round(np.median(resids), 4)),\n",
    "            '3Q': pd.Series(np.round(np.percentile(resids, q=75), 4)),\n",
    "            'Max': pd.Series(np.round(resids.max(), 4)),\n",
    "        }, columns=['Min', '1Q', 'Median', '3Q', 'Max'])\n",
    "        # Output results\n",
    "        print(\"Residuals:\")\n",
    "        print(resids_df.to_string(index=False))\n",
    "        print('\\n')\n",
    "        print('Coefficients:')\n",
    "        print(coef_df.to_string(index=True))\n",
    "        print('---')\n",
    "        r_sq = adj_r2_score_and_r2_score(clf, X, y)[1]\n",
    "        r_sq_adj = adj_r2_score_and_r2_score(clf, X, y)[0]\n",
    "        f_sq = f_squared(clf, X, y)\n",
    "        \n",
    "        print('R-squared:  {0:.5f},    Adjusted R-squared:  {1:.5f}'.format(\n",
    "           r_sq, r_sq_adj))\n",
    "        print('F-squared:  {0:.5f}'.format(\n",
    "            f_sq))\n",
    "    elif(regressor == 'XGBRegressorNoLinear'):\n",
    "        coef_df = pd.DataFrame(\n",
    "            index=['_intercept'] + list(xlabels),\n",
    "            columns=['Estimate','t value', 'p value']\n",
    "        )\n",
    "\n",
    "        coef_df['Estimate'] = np.concatenate(\n",
    "                (np.round(np.array([np.nan]), 6), np.round((clf.feature_importances_), 6)))\n",
    "\n",
    "        coef_df['t value'] = np.round(coef_tval_XGB_tree(clf, X, y), 20)\n",
    "        coef_df['p value'] = np.round(coef_pval_XGB_tree(clf, X, y), 20)\n",
    "            # Create data frame to summarize residuals\n",
    "        resids = residuals(clf, X, y, r_type='raw')\n",
    "        resids_df = pd.DataFrame({\n",
    "                'Min': pd.Series(np.round(resids.min(), 4)),\n",
    "                '1Q': pd.Series(np.round(np.percentile(resids, q=25), 4)),\n",
    "                'Median': pd.Series(np.round(np.median(resids), 4)),\n",
    "                '3Q': pd.Series(np.round(np.percentile(resids, q=75), 4)),\n",
    "                'Max': pd.Series(np.round(resids.max(), 4)),\n",
    "        }, columns=['Min', '1Q', 'Median', '3Q', 'Max'])\n",
    "            # Output results\n",
    "        print(\"Residuals:\")\n",
    "        print(resids_df.to_string(index=False))\n",
    "        print('\\n')\n",
    "        print('Coefficients:')\n",
    "        print(coef_df.to_string(index=True))\n",
    "        print('---')\n",
    "        r_sq = adj_r2_score_and_r2_score(clf, X, y)[1]\n",
    "        r_sq_adj = adj_r2_score_and_r2_score(clf, X, y)[0]\n",
    "        f_sq = f_squared(clf, X, y)\n",
    "\n",
    "        print('R-squared:  {0:.5f},    Adjusted R-squared:  {1:.5f}'.format(\n",
    "               r_sq, r_sq_adj))\n",
    "        print('F-squared:  {0:.5f}'.format(\n",
    "                f_sq))\n",
    "    else:\n",
    "        coef_df['Estimate'] = np.concatenate(\n",
    "            (np.round(np.array([clf.intercept_]), 6), np.round((clf.coef_), 6)))\n",
    "        #coef_df['MSE'] = np.round(mse(clf, X, y), 6)\n",
    "        #coef_df['RMSE'] = np.round(rmse(clf, X, y), 6)\n",
    "        coef_df['t value'] = np.round(coef_tval(clf, X, y), 20)\n",
    "        coef_df['p value'] = np.round(coef_pval(clf, X, y), 20)\n",
    "        # Create data frame to summarize residuals\n",
    "        resids = residuals(clf, X, y, r_type='raw')\n",
    "        resids_df = pd.DataFrame({\n",
    "            'Min': pd.Series(np.round(resids.min(), 4)),\n",
    "            '1Q': pd.Series(np.round(np.percentile(resids, q=25), 4)),\n",
    "            'Median': pd.Series(np.round(np.median(resids), 4)),\n",
    "            '3Q': pd.Series(np.round(np.percentile(resids, q=75), 4)),\n",
    "            'Max': pd.Series(np.round(resids.max(), 4)),\n",
    "        }, columns=['Min', '1Q', 'Median', '3Q', 'Max'])\n",
    "        # Output results\n",
    "        print(\"Residuals:\")\n",
    "        print(resids_df.to_string(index=False))\n",
    "        print('\\n')\n",
    "        print('Coefficients:')\n",
    "        print(coef_df.to_string(index=True))\n",
    "        print('---')\n",
    "        \n",
    "        r_sq = adj_r2_score_and_r2_score(clf, X, y)[1]\n",
    "        r_sq_adj = adj_r2_score_and_r2_score(clf, X, y)[0]\n",
    "        f_sq = f_squared(clf, X, y)\n",
    "        \n",
    "        print('R-squared:  {0:.5f},    Adjusted R-squared:  {1:.5f}'.format(\n",
    "           r_sq, r_sq_adj))\n",
    "        print('F-squared:  {0:.5f}'.format(\n",
    "            f_sq))\n",
    "        \n",
    "        \n",
    "    print('---------------------------------------------------------------------------\\n\\n')\n",
    "    \n",
    "    \n",
    "    \n",
    "    empty_str = []\n",
    "    for i in range(coef_df.shape[0]):\n",
    "        empty_str.append('')\n",
    "    \n",
    "    coef_df['value'] = empty_str\n",
    "    \n",
    "    coef_df = coef_df.T\n",
    "    coef_df['R-squared'] = ['','','', r_sq]\n",
    "    coef_df['Adjusted R-squared'] = ['','','', r_sq_adj]\n",
    "    coef_df['F-squared'] = ['','','', f_sq]\n",
    "    return [coef_df.T, r_sq, r_sq_adj, f_sq]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sabe_chile = pd.read_excel('../Data/cross/SABE_chile.xlsx')\n",
    "sabe_chile = sabe_chile.iloc[:,1::]\n",
    "\n",
    "sabe_uruguay = pd.read_excel('../Data/cross/SABE_uruguay.xlsx')\n",
    "sabe_uruguay = sabe_uruguay.iloc[:,1::]\n",
    "\n",
    "sabe_ecuador = pd.read_excel('../Data/cross/SABE_ecuador.xlsx')\n",
    "sabe_ecuador = sabe_ecuador.iloc[:,1::]\n",
    "\n",
    "sabe_colombia = pd.read_excel('../Data/cross/SABE_colombia.xlsx')\n",
    "sabe_colombia = sabe_colombia.iloc[:,1::]\n",
    "\n",
    "sabe_costarica = pd.read_excel('../Data/cross/SABE_costarica.xlsx')\n",
    "sabe_costarica = sabe_costarica.iloc[:,1::]\n",
    "\n",
    "sabe_korea = pd.read_excel('../Data/cross/SABE_korea.xlsx')\n",
    "sabe_korea = sabe_korea.iloc[:,1::]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add colors for future use, remove non-common features, order all df vars in same order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_chile_01 = sabe_chile.copy()\n",
    "X_uruguay_01 = sabe_uruguay.copy()\n",
    "X_ecuador_01 = sabe_ecuador.copy()\n",
    "X_colombia_01 = sabe_colombia.copy()\n",
    "X_costarica_01 = sabe_costarica.copy()\n",
    "X_korea_01 = sabe_korea.copy()\n",
    "\n",
    "\n",
    "X_cat = pd.read_csv('../Data/cross/var_name_color_code_new.csv', encoding='latin-1', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_col = list(X_chile_01.columns)\n",
    "order_col.remove('FS_Adversidad_AgresionVerb_j28')\n",
    "order_col.remove('FS_Adversidad_AgresionFis_j27')\n",
    "order_col.remove('FM_CardioMetab_IMC_none')\n",
    "order_col.remove('FS_EstSocEcon_ElectricEquipment_none')\n",
    "order_col.remove('FM_CardioMetab_ACV_c09')\n",
    "\n",
    "X_chile_01     =  X_chile_01[order_col]\n",
    "X_uruguay_01   =  X_uruguay_01[order_col]\n",
    "X_ecuador_01   =  X_ecuador_01[order_col]\n",
    "X_colombia_01  =  X_colombia_01[order_col]\n",
    "\n",
    "\n",
    "X_chile_01.columns =  X_cat.newname\n",
    "X_uruguay_01.columns =  X_cat.newname\n",
    "X_ecuador_01.columns =  X_cat.newname\n",
    "X_colombia_01.columns =  X_cat.newname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_chile_01.shape, '\\n', X_uruguay_01.shape, '\\n', X_ecuador_01.shape, '\\n', \n",
    "      X_colombia_01.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Sanity check\n",
    "for i in range(len(order_col)):\n",
    "    print('', X_chile_01.columns[i], '\\n', X_uruguay_01.columns[i], '\\n', X_ecuador_01.columns[i], '\\n', \n",
    "          X_colombia_01.columns[i])\n",
    "    print('-------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_chile_01.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_chile_n_IMC_ACV = X_chile_01.drop(['Barthel' ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_chile_n_IMC_ACV.dropna(inplace=True)\n",
    "print(X_chile_n_IMC_ACV.shape, X_chile_01.shape, X_chile_01.shape[0] - X_chile_n_IMC_ACV.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_chile = X_chile_n_IMC_ACV['MMSE']\n",
    "X_chile = X_chile_n_IMC_ACV.drop('MMSE', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uruguay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_uruguay_n_IMC_ACV = X_uruguay_01.drop(['Barthel' ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_uruguay_n_IMC_ACV.dropna(inplace=True)\n",
    "print(X_uruguay_n_IMC_ACV.shape, X_uruguay_01.shape, X_uruguay_01.shape[0] - X_uruguay_n_IMC_ACV.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_uruguay = X_uruguay_n_IMC_ACV['MMSE']\n",
    "X_uruguay = X_uruguay_n_IMC_ACV.drop('MMSE', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecuador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ecuador_n_IMC_ACV = X_ecuador_01.drop(['Barthel' ], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ecuador_n_IMC_ACV.dropna(inplace=True)\n",
    "print(X_ecuador_n_IMC_ACV.shape, X_ecuador_01.shape, X_ecuador_01.shape[0] - X_ecuador_n_IMC_ACV.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ecuador = X_ecuador_n_IMC_ACV['MMSE']\n",
    "X_ecuador = X_ecuador_n_IMC_ACV.drop('MMSE', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colombia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_colombia_n_IMC_ACV = X_colombia_01.drop(['Barthel' ], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_colombia_n_IMC_ACV.dropna(inplace=True)\n",
    "print(X_colombia_n_IMC_ACV.shape, X_colombia_01.shape, X_colombia_01.shape[0] - X_colombia_n_IMC_ACV.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_colombia = X_colombia_n_IMC_ACV['MMSE']\n",
    "X_colombia = X_colombia_n_IMC_ACV.drop('MMSE', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HIC: Chile and Uruguay joint data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_chile_n_IMC_ACV_colEcua = X_chile_n_IMC_ACV.copy()\n",
    "X_uruguay_n_IMC_ACV_colEcua = X_uruguay_n_IMC_ACV.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_chile_n_IMC_ACV_colEcua['Country'] = np.ones([X_chile_n_IMC_ACV_colEcua.shape[0]])\n",
    "X_uruguay_n_IMC_ACV_colEcua['Country'] = np.ones([X_uruguay_n_IMC_ACV_colEcua.shape[0]])*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_chile_uruguay_n_IMC_ACV = shuffle(pd.concat([X_chile_n_IMC_ACV_colEcua, X_uruguay_n_IMC_ACV_colEcua], axis=0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_chile_uruguay = X_chile_uruguay_n_IMC_ACV['MMSE']\n",
    "X_chile_uruguay = X_chile_uruguay_n_IMC_ACV.drop('MMSE', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_chile_uruguay.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_chile_uruguay, y_chile_uruguay, train_size=0.75, test_size=.25, random_state=0)\n",
    "\n",
    "opt_Ridge = BayesSearchCV(\n",
    "    Ridge(),\n",
    "    {\n",
    "        'alpha': (0.0001, 0.01, 0.001),\n",
    "        'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "        'max_iter': (1000, 10000, 100000, 1000000),\n",
    "        #'tol:' : (1e-6, 1e-3, 1e+1),\n",
    "        #'n_estimators': (100, 1000),\n",
    "\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "opt_Ridge.fit(X_train, y_train)\n",
    "\n",
    "print('Ridge')\n",
    "print(\"val. score: %s\" % opt_Ridge.best_score_)\n",
    "print(\"test score: %s\" % opt_Ridge.score(X_test, y_test))\n",
    "print(\"best parameters: %s\" % str(opt_Ridge.best_params_))\n",
    "print('---------------------------------------------\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelRidge_chile_uruguay = Ridge(alpha=opt_Ridge.best_params_['alpha'], solver = opt_Ridge.best_params_['solver'], \n",
    "                         max_iter=opt_Ridge.best_params_['max_iter'])\n",
    "modelRidge_chile_uruguay.fit(X_chile_uruguay, y_chile_uruguay)\n",
    "\n",
    "parameter_dict['chile_uruguay'] = opt_Ridge.best_params_\n",
    "\n",
    "modelRidge_sum_chile_uruguay = summary(modelRidge_chile_uruguay, X_chile_uruguay, y_chile_uruguay, X_chile_uruguay.columns, 'Ridge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LMIC: Ecuador and Colombia joint data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ecuador_n_IMC_ACV_colEcua = X_ecuador_n_IMC_ACV.copy()\n",
    "X_colombia_n_IMC_ACV_colEcua = X_colombia_n_IMC_ACV.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ecuador_n_IMC_ACV_colEcua['Country'] = np.ones([X_ecuador_n_IMC_ACV_colEcua.shape[0]])\n",
    "X_colombia_n_IMC_ACV_colEcua['Country'] = np.ones([X_colombia_n_IMC_ACV_colEcua.shape[0]])*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ecuador_colombia_n_IMC_ACV = shuffle(pd.concat([X_ecuador_n_IMC_ACV_colEcua, X_colombia_n_IMC_ACV_colEcua], axis=0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ecuador_colombia = X_ecuador_colombia_n_IMC_ACV['MMSE']\n",
    "X_ecuador_colombia = X_ecuador_colombia_n_IMC_ACV.drop('MMSE', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_ecuador_colombia.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_ecuador_colombia, y_ecuador_colombia, train_size=0.75, test_size=.25, random_state=0)\n",
    "\n",
    "opt_Ridge = BayesSearchCV(\n",
    "    Ridge(),\n",
    "    {\n",
    "        'alpha': (0.0001, 0.01, 0.001),\n",
    "        'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "        'max_iter': (1000, 10000, 100000, 1000000),\n",
    "        #'tol:' : (1e-6, 1e-3, 1e+1),\n",
    "        #'n_estimators': (100, 1000),\n",
    "\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "opt_Ridge.fit(X_train, y_train)\n",
    "\n",
    "print('Ridge')\n",
    "print(\"val. score: %s\" % opt_Ridge.best_score_)\n",
    "print(\"test score: %s\" % opt_Ridge.score(X_test, y_test))\n",
    "print(\"best parameters: %s\" % str(opt_Ridge.best_params_))\n",
    "print('---------------------------------------------\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelRidge_ecuador_colombia = Ridge(alpha=opt_Ridge.best_params_['alpha'], solver = opt_Ridge.best_params_['solver'], \n",
    "                         max_iter=opt_Ridge.best_params_['max_iter'])\n",
    "modelRidge_ecuador_colombia.fit(X_ecuador_colombia, y_ecuador_colombia)\n",
    "\n",
    "parameter_dict['ecuador_colombia'] = opt_Ridge.best_params_\n",
    "\n",
    "modelRidge_sum_ecuador_colombia = summary(modelRidge_ecuador_colombia, X_ecuador_colombia, y_ecuador_colombia, X_ecuador_colombia.columns, 'Ridge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All LAC: Chile, Uruguay, Ecuador, Colombia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_chile_n_IMC_ACV_colEcua_01 = X_chile_n_IMC_ACV.copy()\n",
    "X_uruguay_n_IMC_ACV_colEcua_01 = X_uruguay_n_IMC_ACV.copy()\n",
    "X_ecuador_n_IMC_ACV_colEcua_01 = X_ecuador_n_IMC_ACV.copy()\n",
    "X_colombia_n_IMC_ACV_colEcua_01 = X_colombia_n_IMC_ACV.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_chile_n_IMC_ACV_colEcua_01['Country']   = np.ones([X_chile_n_IMC_ACV_colEcua_01.shape[0]])\n",
    "X_uruguay_n_IMC_ACV_colEcua_01['Country'] = np.ones([X_uruguay_n_IMC_ACV_colEcua_01.shape[0]])\n",
    "X_ecuador_n_IMC_ACV_colEcua_01['Country'] = np.ones([X_ecuador_n_IMC_ACV_colEcua.shape[0]])*2\n",
    "X_colombia_n_IMC_ACV_colEcua_01['Country'] = np.ones([X_colombia_n_IMC_ACV_colEcua.shape[0]])*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_n_IMC_ACV = shuffle(pd.concat([X_chile_n_IMC_ACV_colEcua_01, X_uruguay_n_IMC_ACV_colEcua_01, X_ecuador_n_IMC_ACV_colEcua_01, X_colombia_n_IMC_ACV_colEcua_01], axis=0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = X_all_n_IMC_ACV['MMSE']\n",
    "X_all = X_all_n_IMC_ACV.drop('MMSE', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, train_size=0.75, test_size=.25, random_state=0)\n",
    "\n",
    "opt_Ridge = BayesSearchCV(\n",
    "    Ridge(),\n",
    "    {\n",
    "        'alpha': (0.0001, 0.01, 0.001),\n",
    "        'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "        'max_iter': (1000, 10000, 100000, 1000000),\n",
    "        #'tol:' : (1e-6, 1e-3, 1e+1),\n",
    "        #'n_estimators': (100, 1000),\n",
    "\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "opt_Ridge.fit(X_train, y_train)\n",
    "\n",
    "print('Ridge')\n",
    "print(\"val. score: %s\" % opt_Ridge.best_score_)\n",
    "print(\"test score: %s\" % opt_Ridge.score(X_test, y_test))\n",
    "print(\"best parameters: %s\" % str(opt_Ridge.best_params_))\n",
    "print('---------------------------------------------\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelRidge_all = Ridge(alpha=opt_Ridge.best_params_['alpha'], solver = opt_Ridge.best_params_['solver'], \n",
    "                         max_iter=opt_Ridge.best_params_['max_iter'])\n",
    "modelRidge_all.fit(X_all, y_all)\n",
    "\n",
    "parameter_dict['all'] = opt_Ridge.best_params_\n",
    "\n",
    "modelRidge_sum_all = summary(modelRidge_all, X_all, y_all, X_all.columns, 'Ridge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-test between HIC and LMIC Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_order_var(model_):\n",
    "\n",
    "    df = model_[0]['Estimate'].iloc[1:-3]\n",
    "    df = np.abs(pd.to_numeric(df,errors = 'coerce'))\n",
    "    df = list(df.sort_values(ascending=False).index)\n",
    "    return df\n",
    "\n",
    "def beta_values_ttest(modelRidge_sum_model1, modelRidge_sum_model2, X_1, X_2, only_significance = False):\n",
    "    col = get_order_var(modelRidge_sum_model1)\n",
    "    df = modelRidge_sum_model1\n",
    "\n",
    "    feature_sign = []\n",
    "\n",
    "    for i in col:\n",
    "        if df[0]['p value'][i] < 0.05:\n",
    "            feature_sign.append(i)\n",
    "\n",
    "\n",
    "    df = modelRidge_sum_model2\n",
    "\n",
    "    for i in col:\n",
    "        if df[0]['p value'][i] < 0.05 and i not in feature_sign:\n",
    "            feature_sign.append(i)\n",
    "\n",
    "\n",
    "    beta_dict = {}\n",
    "    for i in feature_sign:\n",
    "\n",
    "        beta_dict['HIC_' + i] = []\n",
    "        beta_dict['LMIC_' + i] = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    y_database = X_1['MMSE']\n",
    "    X_database = X_1.drop('MMSE', axis=1)\n",
    "    \n",
    "    if(only_significance):\n",
    "        X_database = X_database[feature_sign]\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(0,100,10):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_database, y_database, train_size=0.75, test_size=.25, random_state=i)\n",
    "\n",
    "        opt_Ridge = BayesSearchCV(\n",
    "                Ridge(),\n",
    "                {\n",
    "                    'alpha': ( 0.0001, 0.01, 0.001),\n",
    "                    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "                    'max_iter': (1000, 10000, 100000, 1000000),\n",
    "                },\n",
    "                n_iter=10,\n",
    "                random_state=i, \n",
    "                scoring='r2',\n",
    "                cv=3\n",
    "            )\n",
    "\n",
    "        opt_Ridge.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "        model = Ridge(alpha=opt_Ridge.best_params_['alpha'], solver = opt_Ridge.best_params_['solver'], \n",
    "                                 max_iter=opt_Ridge.best_params_['max_iter'])\n",
    "\n",
    "        model.fit(X_test, y_test)\n",
    "\n",
    "        coef_df = pd.DataFrame(\n",
    "            index=['_intercept'] + list(X_test.columns),\n",
    "            columns=['Estimate']\n",
    "            )\n",
    "\n",
    "        coef_df['Estimate'] = np.concatenate((np.round(np.array([model.intercept_]), 12), np.round((model.coef_), 12)))\n",
    "\n",
    "        # save Coefficients HIC\n",
    "        for j in feature_sign:\n",
    "            beta_dict['HIC_' + j].append(np.abs(coef_df['Estimate'][j])) \n",
    "\n",
    "\n",
    "    y_database = X_2['MMSE']\n",
    "    X_database = X_2.drop('MMSE', axis=1)\n",
    "    if(only_significance):\n",
    "        X_database = X_database[feature_sign]\n",
    "\n",
    "    for i in range(0,100,10):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_database, y_database, train_size=0.75, test_size=.25, random_state=i)\n",
    "\n",
    "        opt_Ridge = BayesSearchCV(\n",
    "                Ridge(),\n",
    "                {\n",
    "                    'alpha': ( 0.0001, 0.01, 0.001),\n",
    "                    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "                    'max_iter': (1000, 10000, 100000, 1000000),\n",
    "                },\n",
    "                n_iter=10,\n",
    "                random_state=i, \n",
    "                scoring='r2',\n",
    "                cv=3\n",
    "            )\n",
    "\n",
    "        opt_Ridge.fit(X_train, y_train)\n",
    "\n",
    "        model = Ridge(alpha=opt_Ridge.best_params_['alpha'], solver = opt_Ridge.best_params_['solver'], \n",
    "                                 max_iter=opt_Ridge.best_params_['max_iter'])\n",
    "\n",
    "        model.fit(X_test, y_test)\n",
    "\n",
    "        coef_df = pd.DataFrame(\n",
    "            index=['_intercept'] + list(X_test.columns),\n",
    "            columns=['Estimate']\n",
    "            )\n",
    "\n",
    "        coef_df['Estimate'] = np.concatenate((np.round(np.array([model.intercept_]), 12), np.round((model.coef_), 12)))\n",
    "\n",
    "        #Save coefficients LMIC\n",
    "        for j in feature_sign:\n",
    "            beta_dict['LMIC_'+ j].append(np.abs(coef_df['Estimate'][j]))\n",
    "\n",
    "    beta_df = pd.DataFrame(beta_dict)\n",
    "\n",
    "\n",
    "    from scipy import stats\n",
    "    import statsmodels.api\n",
    "\n",
    "    result_scipy_df = pd.DataFrame(\n",
    "            index=['p value'] ,\n",
    "            columns=feature_sign\n",
    "            )\n",
    "\n",
    "    result_stats_df = pd.DataFrame(\n",
    "            index=['p value'] ,\n",
    "            columns=feature_sign\n",
    "            )\n",
    "\n",
    "    for i in feature_sign:\n",
    "        result_scipy_df[i] = stats.ttest_ind(beta_dict['HIC_'+ i], beta_dict['LMIC_' + i], equal_var=False)[1]\n",
    "        result_stats_df[i] = statsmodels.stats.weightstats.ttest_ind(beta_dict['HIC_'+ i], beta_dict['LMIC_' + i], alternative=\"two-sided\",usevar=\"unequal\")[1]\n",
    "\n",
    "\n",
    "    beta_df_stat = beta_df.describe().round(3).iloc[1:3,:]\n",
    "    beta_df_stat = beta_df_stat.append(beta_df_stat.iloc[1,:]*1.95,ignore_index=True)\n",
    "    beta_df_stat = beta_df_stat.append(beta_df_stat.iloc[1,:]*2.58,ignore_index=True)\n",
    "\n",
    "    beta_df_stat = beta_df_stat.rename(index={0:'mean', 1:'std', 2:'95', 3:'99'})\n",
    "    beta_df_stat.round(3)\n",
    "\n",
    "\n",
    "    general_result_df = pd.DataFrame(\n",
    "            index=feature_sign,\n",
    "            columns=['HIC_mean', 'HIC_std','LMIC_mean','LMIC_std', 'ttest']\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "    count = 0\n",
    "    for i in feature_sign:\n",
    "        general_result_df.iloc[count, 0] = np.round(beta_df_stat['HIC_' + i][0],2)\n",
    "        general_result_df.iloc[count, 1] = np.round(beta_df_stat['HIC_' + i][1],2)\n",
    "\n",
    "        general_result_df.iloc[count, 2] = np.round(beta_df_stat['LMIC_' + i][0],2)\n",
    "        general_result_df.iloc[count, 3] = np.round(beta_df_stat['LMIC_' + i][1],2)\n",
    "\n",
    "        general_result_df.iloc[count, 4] = np.round(result_stats_df[i][0],2)\n",
    "\n",
    "        count +=1\n",
    "\n",
    "    return general_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coef_t_test = beta_values_ttest(modelRidge_sum_chile_uruguay, modelRidge_sum_ecuador_colombia, \n",
    "                  X_chile_uruguay_n_IMC_ACV, X_ecuador_colombia_n_IMC_ACV, True)#.to_excel('./Cognition_beta_ttest_all_feat.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coef_t_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-Statistic (HIC, LMIC, ALL LAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_stat(clf, X, y):\n",
    "    \"\"\"Calculate summary F-statistic for beta coefficients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The F-statistic value.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    r_squared = metrics.r2_score(y, clf.predict(X))\n",
    "    return (r_squared / p) / ((1 - r_squared) / (n - p - 1))\n",
    "\n",
    "\n",
    "def f_stat_pvalue(clf, X, y):\n",
    "    \"\"\"Calculate summary F-statistic p value for beta coefficients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The F-statistic p value.\n",
    "    \"\"\"\n",
    "    n = X.shape[0] # Esto se extrae par los grados de libertad del numeador y el denomindor (no. predictores, no. sujetos - no. predictores-1)\n",
    "    p = X.shape[1]\n",
    "    r_squared = metrics.r2_score(y, clf.predict(X))\n",
    "    \n",
    "    return np.round(scipy.stats.f.sf(f_stat(clf, X, y), n, (n - p - 1)), 15)\n",
    "\n",
    "def compute_f_statistics(clf, X, y):\n",
    "    return [f_stat(clf, X, y), f_stat_pvalue(clf, X, y)]\n",
    "\n",
    "F_statistics = {}\n",
    "\n",
    "\n",
    "\n",
    "F_statistics['HIC'] = [compute_f_statistics(modelRidge_chile_uruguay, X_chile_uruguay, y_chile_uruguay)]\n",
    "F_statistics['LMIC'] = [compute_f_statistics(modelRidge_ecuador_colombia, X_ecuador_colombia, y_ecuador_colombia)]\n",
    "F_statistics['ALL'] = [compute_f_statistics(modelRidge_all, X_all, y_all)]\n",
    "\n",
    "F_statistics_pd = pd.DataFrame(F_statistics, index = ['F-statisitcs, F-pvalue']).T\n",
    "F_statistics_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HIC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRidge_sum_chile_uruguay[0]#.to_excel('Results/cross_sectional/MMSE_Ridge_chile_plus_uruguay.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_statistics_pd.iloc[0:1,0:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LMIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRidge_sum_ecuador_colombia[0]#.to_excel('Results/cross_sectional/MMSE_Ridge_ecuador_plus_colombia.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_statistics_pd.iloc[1:2,0:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All LAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRidge_sum_all[0]#.to_excel('Results/cross_sectional/MMSE_Ridge_all.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_statistics_pd.iloc[2:3,0:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_pd = pd.DataFrame(parameter_dict).T\n",
    "parameter_pd.reset_index(drop=True, inplace=True)\n",
    "parameter_pd[''] =[\"HIC\", \"LMIC\", \"ALL\"]\n",
    "parameter_pd.set_index('', inplace=True)\n",
    "parameter_pd#.to_excel('Results/cross_sectional/MMSE_hyperparameters.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_interval_dict = {}\n",
    "\n",
    "\n",
    "conf_interval_dict['HIC'] = [conf_interval(X_chile_uruguay_n_IMC_ACV)]\n",
    "conf_interval_dict['LMIC'] = [conf_interval(X_ecuador_colombia_n_IMC_ACV)]\n",
    "conf_interval_dict['ALL'] = [conf_interval(X_all_n_IMC_ACV)]\n",
    "\n",
    "conf_interval_pd = pd.DataFrame(conf_interval_dict, index = ['conf interval']).T\n",
    "conf_interval_pd#.to_excel('Results/cross_sectional/MMSE_conf_interval.xlsx')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
