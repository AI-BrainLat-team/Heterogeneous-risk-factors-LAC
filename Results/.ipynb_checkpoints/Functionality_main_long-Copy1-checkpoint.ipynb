{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelo/anaconda3/envs/HBL/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "import matplotlib.font_manager\n",
    "from matplotlib import style\n",
    "style.use('seaborn') or plt.style.use('seaborn')\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, f1_score, accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "import operator\n",
    "\n",
    "\n",
    "from xgboost import plot_importance\n",
    "\n",
    "\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import PatchCollection\n",
    "import scipy.stats as ss\n",
    "\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import Lasso, MultiTaskLasso, Ridge, ElasticNet\n",
    "import math\n",
    "\n",
    "#from regressors import stats\n",
    "\n",
    "\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import PatchCollection\n",
    "import scipy.stats as ss\n",
    "\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "\n",
    "import scipy\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "import colorsys\n",
    "import matplotlib.colors as cconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import my_bib as mb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_color(var, X_cat_, color_dict_):\n",
    "\n",
    "    X_factors = list(X_cat_.factors)\n",
    "    X_name = list(X_cat_.newname)\n",
    "\n",
    "    index_code = X_name.index(var)\n",
    "    cat = X_factors[index_code]\n",
    "\n",
    "    return color_dict_[cat]\n",
    "\n",
    "color_dict = {}\n",
    "color_dict['Country'] = [40/255, 43/255, 95/255]\n",
    "color_dict['HF'] = '#A31300'\n",
    "color_dict['LSF'] = '#FF9E0D'\n",
    "color_dict['PSF'] = '#FF4800'\n",
    "color_dict['SDHF'] = '#1C4F9E'\n",
    "color_dict['DF'] = '#009E32'\n",
    "\n",
    "def get_bar_colors(data_, X_cat_):\n",
    "    color_dict = {}\n",
    "    color_dict['Country'] = [40/255, 43/255, 95/255]\n",
    "    color_dict['HF'] = '#A31300'\n",
    "    color_dict['LSF'] = '#FF9E0D'\n",
    "    color_dict['PSF'] = '#FF4800'\n",
    "    color_dict['SDHF'] = '#1C4F9E'\n",
    "    color_dict['DF'] = '#009E32'\n",
    "    \n",
    "    #color_dict = {}\n",
    "    #color_dict = {'DF':'#5975a4', 'MF':'#cc8963', 'SF':'#5f9e6e', 'SLF':'#b55d60',\n",
    "    #              'n':'#857aab', 'country':'#8d7866'}#, '#d095bf'}\n",
    "\n",
    "    X_factors = list(X_cat_.factors)\n",
    "    X_name = list(X_cat_.newname)\n",
    "\n",
    "    bar_color_total = []\n",
    "    for i in list(data_.Features):\n",
    "        if(i == 'Country'):\n",
    "            bar_color_total.append(color_dict['Country'])\n",
    "            continue\n",
    "        index_code = X_name.index(i)\n",
    "        cat = X_factors[index_code]\n",
    "        bar_color_total.append(color_dict[cat])\n",
    "    return bar_color_total\n",
    "\n",
    "\n",
    "def plot_estimate_value(regression_model, X_cat_ = [], title = '',  xlim =[0, 2] ,fig_size = (8,12), size = 14, pvalue_type = 'False'):\n",
    "\n",
    "    df = regression_model[0]\n",
    "    df.index.name = 'Features'\n",
    "    df = df.iloc[1:-3, 0:-1]\n",
    "\n",
    "    for i in range(3):\n",
    "            #print(i, X_RAW_edu_level[X_RAW_edu_level.columns[i]].dtype)\n",
    "        df[df.columns[i]] = np.abs(pd.to_numeric(df[df.columns[i]],errors = 'coerce'))\n",
    "\n",
    "    df = df.reset_index()\n",
    "    data = df.sort_values('Estimate', ascending=False)\n",
    "\n",
    "    \n",
    "    if(len(X_cat_)>0):\n",
    "        \n",
    "        bar_color = get_bar_colors(data, X_cat_)\n",
    "        \n",
    "        plt.title(title)\n",
    "        sns.barplot(x=\"Estimate\", y=\"Features\", data = data, palette =bar_color)\n",
    "        plt.xlim(xlim)\n",
    "    else:\n",
    "        plt.title(title)\n",
    "        sns.barplot(x=\"Estimate\", y=\"Features\", data = data, color = 'darkblue')\n",
    "        plt.xlim(xlim)\n",
    "\n",
    "\n",
    "    y_step=0  \n",
    "    for i in range(df.shape[0]):\n",
    "        if(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],3)<=0.01):\n",
    "            color = 'green'\n",
    "        elif(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],3)<=0.05):\n",
    "            color = 'gray'\n",
    "        else:\n",
    "            color = 'red'        \n",
    "        \n",
    "        if(pvalue_type == 'color'):\n",
    "                plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]-0.005, y_step, \n",
    "                                 '' + str(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],2)),\n",
    "                                 size= size, rotation=0.,\n",
    "                                 ha=\"left\", va=\"center\", color = 'white',\n",
    "                                 bbox=dict(boxstyle=\"round\",\n",
    "                                           ec=color,\n",
    "                                            fc=color,\n",
    "                                           )\n",
    "                                 )\n",
    "                y_step+=1\n",
    "\n",
    "        elif(pvalue_type == 'value'):\n",
    "                plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                 '(' + str(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],8))+')',\n",
    "                                 size= size, rotation=0.,\n",
    "                                 ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                 )\n",
    "                y_step+=1\n",
    "        else:\n",
    "            if(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step]<0.01):\n",
    "                \n",
    "                    plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                     '**',\n",
    "                                     size= size, rotation=0.,\n",
    "                                     ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                     )\n",
    "            elif(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step]>= 0.01 and df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step]<0.05):\n",
    "                  \n",
    "                    plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                     '*',\n",
    "                                     size= size, rotation=0.,\n",
    "                                     ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                     )  \n",
    "            else:\n",
    "                    plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                     '',\n",
    "                                     size= size, rotation=0.,\n",
    "                                     ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                     )      \n",
    "            y_step+=1\n",
    "            \n",
    "         \n",
    "    text_diff =xlim[1]/2.2\n",
    "    plt.text(xlim[1] - text_diff, df.shape[0]-1.5,r'$ R^2 $(' + str(np.round(regression_model[1],2)) + ') \\t$F^2 $(' + str(np.round(regression_model[3],2)) + ')',\n",
    "                             size= 12, rotation=0.,\n",
    "                             ha=\"left\", va=\"center\", color = 'black',\n",
    "                             bbox=dict(boxstyle=\"round\",\n",
    "                                       ec='gray',\n",
    "                                        fc='gray',\n",
    "                                       )\n",
    "                             )\n",
    "\n",
    "\n",
    "    plt.locator_params(axis='x', nbins=4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_estimate_value_no_sort(regression_model, title = '',  xlim =[0, 2] ,fig_size = (8,12), size = 14, ylabel = True, ylabelR = False ):\n",
    "\n",
    "    df = regression_model\n",
    "    df.index.name = 'Features'\n",
    "    df = df.iloc[1:-3, 0:-1]\n",
    "\n",
    "    for i in range(3):\n",
    "            #print(i, X_RAW_edu_level[X_RAW_edu_level.columns[i]].dtype)\n",
    "        df[df.columns[i]] = np.abs(pd.to_numeric(df[df.columns[i]],errors = 'coerce'))\n",
    "\n",
    "    df = df.reset_index()\n",
    "\n",
    "    #plt.figure(figsize=(8,12))\n",
    "    plt.title(title)\n",
    "    sns.barplot(x=\"Estimate\", y=\"Features\", data = df, color = 'Brown')\n",
    "    if(ylabel == False):\n",
    "        plt.ylabel('')\n",
    "        plt.yticks([])\n",
    "    plt.xlim(xlim)\n",
    "    \n",
    "    if(ylabelR):\n",
    "        plt.tick_params (axis = 'y', which = 'both', labelleft = False, labelright = True)\n",
    "\n",
    "    y_step=0  \n",
    "    for i in range(df.shape[0]):\n",
    "        if(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],3)<=0.01):\n",
    "            color = 'green'\n",
    "        elif(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],3)<=0.05):\n",
    "            color = 'gray'\n",
    "        else:\n",
    "            color = 'red'        \n",
    "        \n",
    "        plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]-0.005, y_step, \n",
    "                         '' + str(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],3)),\n",
    "                         size= size, rotation=0.,\n",
    "                         ha=\"left\", va=\"center\", color = 'white',\n",
    "                         bbox=dict(boxstyle=\"round\",\n",
    "                                   ec=color,\n",
    "                                    fc=color,\n",
    "                                   )\n",
    "                         )\n",
    "        y_step+=1\n",
    "        \n",
    "\n",
    "        \n",
    "def conf_interval(database):\n",
    "    r_squared_list = []\n",
    "\n",
    "    y_database = database['Barthel']\n",
    "    X_database = database.drop('Barthel', axis=1)\n",
    "\n",
    "    for i in range(0,100,10):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_database, y_database, train_size=0.75, test_size=.25, random_state=i)\n",
    "\n",
    "        opt_Ridge = BayesSearchCV(\n",
    "            Ridge(),\n",
    "            {\n",
    "                'alpha': ( 0.0001, 0.01, 0.001),\n",
    "                'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "                'max_iter': (1000, 10000, 100000, 1000000),\n",
    "            },\n",
    "            n_iter=10,\n",
    "            random_state=i, \n",
    "            scoring='r2',\n",
    "            cv=3\n",
    "        )\n",
    "\n",
    "        opt_Ridge.fit(X_train, y_train)\n",
    "\n",
    "        r_squared_list.append(opt_Ridge.score(X_test, y_test))\n",
    "\n",
    "\n",
    "    print(r'99% confidence interval (+-', np.round(np.std(r_squared_list)*2.58, 4),')')\n",
    "    return np.round(np.std(r_squared_list)*2.58, 4)\n",
    "\n",
    "\n",
    "def adj_r2_score_and_r2_score(clf, X, y):\n",
    "    n = X.shape[0]  # Number of observations\n",
    "    p = X.shape[1]  # Number of features\n",
    "    r_squared = r2_score(y, clf.predict(X))\n",
    "    return [1 - (1 - r_squared) * ((n - 1) / (n - p - 1)), r_squared]\n",
    "\n",
    "\n",
    "def mse(clf, X, y):\n",
    "    return mean_squared_error(y, clf.predict(X))\n",
    "\n",
    "def rmse(clf, X, y):\n",
    "    mse = mean_squared_error(y, clf.predict(X))\n",
    "    return math.sqrt(mse)    \n",
    "\n",
    "def coef_se(clf, X, y):\n",
    "    n = X.shape[0]\n",
    "    X1 = np.hstack((np.ones((n, 1)), np.matrix(X)))\n",
    "    se_matrix = scipy.linalg.sqrtm(\n",
    "        metrics.mean_squared_error(y, clf.predict(X)) *\n",
    "        np.linalg.inv(X1.T * X1)\n",
    "    )\n",
    "    return np.diagonal(se_matrix)\n",
    "\n",
    "def coef_tval(clf, X, y):\n",
    "    a = np.array(clf.intercept_ / coef_se(clf, X, y)[0])\n",
    "    b = np.array(clf.coef_ / coef_se(clf, X, y)[1:])\n",
    "    return np.append(a, b)\n",
    "\n",
    "def coef_tval_XGB_tree(clf, X, y):\n",
    "    a = np.nan\n",
    "    b = np.array(clf.feature_importances_ / coef_se(clf, X, y)[1:])\n",
    "    return np.append(a, b)\n",
    "\n",
    "def coef_pval(clf, X, y):\n",
    "\n",
    "    n = X.shape[0]\n",
    "    t = coef_tval(clf, X, y)\n",
    "    p = 2 * (1 - scipy.stats.t.cdf(abs(t), n - 1))\n",
    "    return p\n",
    "\n",
    "def coef_pval_XGB_tree(clf, X, y):\n",
    "\n",
    "    n = X.shape[0]\n",
    "    t = coef_tval_XGB_tree(clf, X, y)\n",
    "    p = 2 * (1 - scipy.stats.t.cdf(abs(t), n - 1))\n",
    "    return p\n",
    "\n",
    "def residuals(clf, X, y, r_type='standardized'):\n",
    "\n",
    "    # Make sure value of parameter 'r_type' is one we recognize\n",
    "    assert r_type in ('raw', 'standardized', 'studentized'), (\n",
    "        \"Invalid option for 'r_type': {0}\".format(r_type))\n",
    "    y_true = y.view(dtype='float')\n",
    "    # Use classifier to make predictions\n",
    "    y_pred = clf.predict(X)\n",
    "    # Make sure dimensions agree (Numpy still allows subtraction if they don't)\n",
    "    assert y_true.shape == y_pred.shape, (\n",
    "        \"Dimensions of y_true {0} do not match y_pred {1}\".format(y_true.shape,\n",
    "                                                                  y_pred.shape))\n",
    "    # Get raw residuals, or standardized or standardized residuals\n",
    "    resids = y_pred - y_true\n",
    "    if r_type == 'standardized':\n",
    "        resids = resids / np.std(resids)\n",
    "    elif r_type == 'studentized':\n",
    "        # Prepare a blank array to hold studentized residuals\n",
    "        studentized_resids = np.zeros(y_true.shape[0], dtype='float')\n",
    "        # Calcluate hat matrix of X values so you can get leverage scores\n",
    "        hat_matrix = np.dot(\n",
    "            np.dot(X, np.linalg.inv(np.dot(np.transpose(X), X))),\n",
    "            np.transpose(X))\n",
    "        # For each point, calculate studentized residuals w/ leave-one-out MSE\n",
    "        for i in range(y_true.shape[0]):\n",
    "            # Make a mask so you can calculate leave-one-out MSE\n",
    "            mask = np.ones(y_true.shape[0], dtype='bool')\n",
    "            mask[i] = 0\n",
    "            loo_mse = np.average(resids[mask] ** 2, axis=0)  # Leave-one-out MSE\n",
    "            # Calculate studentized residuals\n",
    "            studentized_resids[i] = resids[i] / np.sqrt(\n",
    "                loo_mse * (1 - hat_matrix[i, i]))\n",
    "        resids = studentized_resids\n",
    "    return resids\n",
    "\n",
    "\n",
    "def f_squared(clf, X, y):\n",
    "\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    r_squared = metrics.r2_score(y, clf.predict(X))\n",
    "    return r_squared  / (1 - r_squared)\n",
    "\n",
    "\n",
    "\n",
    "def summary(clf, X, y, xlabels=None, regressor = ''):\n",
    "\n",
    "    print('Resumen del regresor ' + regressor + '\\n')\n",
    "    \n",
    "    ncols = X.shape[1]\n",
    "    if xlabels is None:\n",
    "        xlabels = np.array(\n",
    "            ['x{0}'.format(i) for i in range(1, ncols + 1)], dtype='str')\n",
    "    elif isinstance(xlabels, (tuple, list)):\n",
    "        xlabels = np.array(xlabels, dtype='str')\n",
    "\n",
    "    # Create data frame of coefficient estimates and associated stats\n",
    "    coef_df = pd.DataFrame(\n",
    "        index=['_intercept'] + list(xlabels),\n",
    "        columns=['Estimate','t value', 'p value']\n",
    "    )\n",
    "    \n",
    "    if(regressor == 'XGBRegressor'):\n",
    "        coef_df['Estimate'] = np.concatenate(\n",
    "            (np.round(np.array([clf.intercept_[0]]), 6), np.round((clf.coef_), 6)))\n",
    "        #coef_df['MSE'] = np.round(mse(clf, X, y), 6)\n",
    "        #coef_df['RMSE'] = np.round(rmse(clf, X, y), 6)\n",
    "        coef_df['t value'] = np.round(coef_tval(clf, X, y), 4)\n",
    "        coef_df['p value'] = np.round(coef_pval(clf, X, y), 20)\n",
    "        # Create data frame to summarize residuals\n",
    "        resids = residuals(clf, X, y, r_type='raw')\n",
    "        resids_df = pd.DataFrame({\n",
    "            'Min': pd.Series(np.round(resids.min(), 4)),\n",
    "            '1Q': pd.Series(np.round(np.percentile(resids, q=25), 4)),\n",
    "            'Median': pd.Series(np.round(np.median(resids), 4)),\n",
    "            '3Q': pd.Series(np.round(np.percentile(resids, q=75), 4)),\n",
    "            'Max': pd.Series(np.round(resids.max(), 4)),\n",
    "        }, columns=['Min', '1Q', 'Median', '3Q', 'Max'])\n",
    "        # Output results\n",
    "        print(\"Residuals:\")\n",
    "        print(resids_df.to_string(index=False))\n",
    "        print('\\n')\n",
    "        print('Coefficients:')\n",
    "        print(coef_df.to_string(index=True))\n",
    "        print('---')\n",
    "        r_sq = adj_r2_score_and_r2_score(clf, X, y)[1]\n",
    "        r_sq_adj = adj_r2_score_and_r2_score(clf, X, y)[0]\n",
    "        f_sq = f_squared(clf, X, y)\n",
    "        \n",
    "        print('R-squared:  {0:.5f},    Adjusted R-squared:  {1:.5f}'.format(\n",
    "           r_sq, r_sq_adj))\n",
    "        print('F-squared:  {0:.5f}'.format(\n",
    "            f_sq))\n",
    "    elif(regressor == 'XGBRegressorNoLinear'):\n",
    "        coef_df = pd.DataFrame(\n",
    "            index=['_intercept'] + list(xlabels),\n",
    "            columns=['Estimate','t value', 'p value']\n",
    "        )\n",
    "\n",
    "        coef_df['Estimate'] = np.concatenate(\n",
    "                (np.round(np.array([np.nan]), 6), np.round((clf.feature_importances_), 6)))\n",
    "\n",
    "        coef_df['t value'] = np.round(coef_tval_XGB_tree(clf, X, y), 4)\n",
    "        coef_df['p value'] = np.round(coef_pval_XGB_tree(clf, X, y), 20)\n",
    "            # Create data frame to summarize residuals\n",
    "        resids = residuals(clf, X, y, r_type='raw')\n",
    "        resids_df = pd.DataFrame({\n",
    "                'Min': pd.Series(np.round(resids.min(), 4)),\n",
    "                '1Q': pd.Series(np.round(np.percentile(resids, q=25), 4)),\n",
    "                'Median': pd.Series(np.round(np.median(resids), 4)),\n",
    "                '3Q': pd.Series(np.round(np.percentile(resids, q=75), 4)),\n",
    "                'Max': pd.Series(np.round(resids.max(), 4)),\n",
    "        }, columns=['Min', '1Q', 'Median', '3Q', 'Max'])\n",
    "            # Output results\n",
    "        print(\"Residuals:\")\n",
    "        print(resids_df.to_string(index=False))\n",
    "        print('\\n')\n",
    "        print('Coefficients:')\n",
    "        print(coef_df.to_string(index=True))\n",
    "        print('---')\n",
    "        r_sq = adj_r2_score_and_r2_score(clf, X, y)[1]\n",
    "        r_sq_adj = adj_r2_score_and_r2_score(clf, X, y)[0]\n",
    "        f_sq = f_squared(clf, X, y)\n",
    "\n",
    "        print('R-squared:  {0:.5f},    Adjusted R-squared:  {1:.5f}'.format(\n",
    "               r_sq, r_sq_adj))\n",
    "        print('F-squared:  {0:.5f}'.format(\n",
    "                f_sq))\n",
    "    else:\n",
    "        coef_df['Estimate'] = np.concatenate(\n",
    "            (np.round(np.array([clf.intercept_]), 6), np.round((clf.coef_), 6)))\n",
    "        #coef_df['MSE'] = np.round(mse(clf, X, y), 6)\n",
    "        #coef_df['RMSE'] = np.round(rmse(clf, X, y), 6)\n",
    "        coef_df['t value'] = abs(np.round(coef_tval(clf, X, y), 4))\n",
    "        coef_df['p value'] = np.round(coef_pval(clf, X, y), 20)\n",
    "        # Create data frame to summarize residuals\n",
    "        resids = residuals(clf, X, y, r_type='raw')\n",
    "        resids_df = pd.DataFrame({\n",
    "            'Min': pd.Series(np.round(resids.min(), 4)),\n",
    "            '1Q': pd.Series(np.round(np.percentile(resids, q=25), 4)),\n",
    "            'Median': pd.Series(np.round(np.median(resids), 4)),\n",
    "            '3Q': pd.Series(np.round(np.percentile(resids, q=75), 4)),\n",
    "            'Max': pd.Series(np.round(resids.max(), 4)),\n",
    "        }, columns=['Min', '1Q', 'Median', '3Q', 'Max'])\n",
    "        # Output results\n",
    "        print(\"Residuals:\")\n",
    "        print(resids_df.to_string(index=False))\n",
    "        print('\\n')\n",
    "        print('Coefficients:')\n",
    "        print(coef_df.to_string(index=True))\n",
    "        print('---')\n",
    "        \n",
    "        r_sq = adj_r2_score_and_r2_score(clf, X, y)[1]\n",
    "        r_sq_adj = adj_r2_score_and_r2_score(clf, X, y)[0]\n",
    "        f_sq = f_squared(clf, X, y)\n",
    "        \n",
    "        print('R-squared:  {0:.5f},    Adjusted R-squared:  {1:.5f}'.format(\n",
    "           r_sq, r_sq_adj))\n",
    "        print('F-squared:  {0:.5f}'.format(\n",
    "            f_sq))\n",
    "        \n",
    "        \n",
    "    print('---------------------------------------------------------------------------\\n\\n')\n",
    "    \n",
    "    \n",
    "    \n",
    "    empty_str = []\n",
    "    for i in range(coef_df.shape[0]):\n",
    "        empty_str.append('')\n",
    "    \n",
    "    coef_df['value'] = empty_str\n",
    "    \n",
    "    coef_df = coef_df.T\n",
    "    coef_df['R-squared'] = ['','','', r_sq]\n",
    "    coef_df['Adjusted R-squared'] = ['','','', r_sq_adj]\n",
    "    coef_df['F-squared'] = ['','','', f_sq]\n",
    "    return [coef_df.T, r_sq, r_sq_adj, f_sq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    sig = 1 / (1 + math.exp(-x))\n",
    "    return sig\n",
    "\n",
    "def get_order_var(model_):\n",
    "\n",
    "    df = model_[0]['Estimate'].iloc[1:-3]\n",
    "    df = np.abs(pd.to_numeric(df,errors = 'coerce'))\n",
    "    df = list(df.sort_values(ascending=False).index)\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_longitudinal(var, y_countrys_, models_, market_size_type = 'log',xlim = [0.25, 5.75], \n",
    "                      years = [2006, 2014, 2016],ylim = [10.0, 11.12], size_init = 1, size_mult = 40, \n",
    "                      size_edge_market = 2, xlabel = True, ylabel = True, ylabel_text = 'MMSE',color_dict_ = '', X_cat_ = ''):\n",
    "    \n",
    "    #X_cat = pd.read_csv('Data/var_name_color_code.csv', encoding='latin-1', sep=\";\")\n",
    "    \n",
    "    color = get_color(var, X_cat_, color_dict_)\n",
    "    edge_color = 'black'\n",
    "\n",
    "    y = []\n",
    "    for i in range(len(y_countrys_)):\n",
    "        y.append(y_countrys_[i].mean())\n",
    "        #y = [y_countrys_[0].mean(), y_countrys_[1].mean(),\n",
    "        #     y_countrys_[2].mean(), y_countrys_[3].mean(),\n",
    "        #     y_countrys_[4].mean()]\n",
    "\n",
    "\n",
    "    #var_ind = list(X_cat.oldname).index(var)\n",
    "    #var_ = list(X_cat.newname)[var_ind]\n",
    "    \n",
    "\n",
    "     \n",
    "    plt.plot(range(1, len(y_countrys_)+1), y, 'k--')\n",
    "\n",
    "    for i in range(len(models_)):\n",
    "        df = models_[i][0]\n",
    "        y = np.abs(df.iloc[df.index.get_loc(var), df.columns.get_loc('Estimate')])\n",
    "        \n",
    "        if(market_size_type=='log'):\n",
    "            if(y < 0.003):\n",
    "                markersize_ = 0\n",
    "            else:\n",
    "                markersize_ = size_mult*(5 + np.log(y))\n",
    "        elif(market_size_type=='log1'):\n",
    "            markersize_ = np.log(100000*y)\n",
    "        elif(market_size_type=='sigmoide'):\n",
    "            markersize_ = size_mult*sigmoid(y)\n",
    "        else:\n",
    "            markersize_ = np.abs(size_mult*y) \n",
    "        \n",
    "        markersize_ +=size_init\n",
    "        plt.plot(i + 1, y_countrys_[i].mean(), marker=\"o\",  \n",
    "                 markeredgewidth = size_edge_market, markeredgecolor = edge_color, markerfacecolor = color, markersize= markersize_)\n",
    "        \n",
    "        \n",
    "        p = df['p value'][var]\n",
    "        \n",
    "        p_text = ''\n",
    "        if(p<= 0.01):\n",
    "            p_text = '**'\n",
    "        elif((p<= 0.05)):\n",
    "            p_text = '*'\n",
    "        \n",
    "        \n",
    "        plt.text(i + 1 , y_countrys_[i].mean(), p_text,\n",
    "                                             size= 22, rotation=0.,\n",
    "                                             ha=\"center\", va=\"top\", color = 'black',\n",
    "                                            # bbox=dict(boxstyle=\"round\", pad=0.1,\n",
    "                                            #           ec='gray',\n",
    "                                            #           fc='gray',\n",
    "                                            #          )\n",
    "                                             );\n",
    "        \n",
    "        #plt.text(i + 1 , ylim[0] - 0.25, str(round(markersize_,2)),\n",
    "         #                                    size= 8, rotation=0.,\n",
    "          #                                   ha=\"center\", va=\"top\", color = 'black',\n",
    "                                            # bbox=dict(boxstyle=\"round\", pad=0.1,\n",
    "                                            #           ec='gray',\n",
    "                                            #           fc='gray',\n",
    "                                            #          )\n",
    "           #                                  );\n",
    "       # print('')\n",
    "        r2 = str(np.round(models_[i][1],2))\n",
    "        f2 = str(np.round(models_[i][3],2))\n",
    "        #plt.text(i+1,10.15,r'$R^2$ ('+r2+') \\n$F^2$ ('+f2+')',\n",
    "        #                         size= 12, rotation=0.,\n",
    "        #                         ha=\"center\", va=\"top\", color = 'black',\n",
    "        #                         bbox=dict(boxstyle=\"round\", pad=0.1,\n",
    "        #                                   ec='ghostwhite',\n",
    "        #                                    fc='ghostwhite',\n",
    "        #                                  )\n",
    "        #                         );\n",
    "\n",
    "    plt.text(xlim[1] , ylim[1], var,\n",
    "                                         size= 13, rotation=0.,\n",
    "                                         ha=\"right\", va=\"center\", color = 'black',\n",
    "                                        # bbox=dict(boxstyle=\"round\", pad=0.1,\n",
    "                                        #           ec='gray',\n",
    "                                        #           fc='gray',\n",
    "                                        #          )\n",
    "                                         );\n",
    "\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim([ylim[0]-0.25, ylim[1]+0.25])\n",
    "    \n",
    "\n",
    "    if(xlabel):\n",
    "        plt.xticks(list(range(1, len(years)+1)), years)\n",
    "    else:\n",
    "        plt.xticks(list(range(1, len(years)+1)), ['', '', '', '', ''])\n",
    "    \n",
    "    if(ylabel):\n",
    "        plt.yticks(np.round(np.linspace(ylim[0], ylim[1], 4),2), np.round(np.linspace(ylim[0], ylim[1], 4),1))\n",
    "    else:\n",
    "        plt.yticks(np.round(np.linspace(ylim[0], ylim[1], 4),2), ['', '', '', ''])\n",
    "\n",
    "    if(ylabel):\n",
    "        plt.ylabel(ylabel_text, fontsize=13)\n",
    "    else:\n",
    "        plt.ylabel('')\n",
    "        \n",
    "    if(xlabel):\n",
    "        plt.xlabel('Years', fontsize=13)\n",
    "    else:\n",
    "        plt.xlabel('')\n",
    "        \n",
    "def plot_r2_f2(models_, xlim = [0.25, 5.75], ylim = [10.0, 11.12]):\n",
    "    \n",
    "    X_cat = pd.read_csv('Data/var_name_color_code.csv', encoding='latin-1', sep=\";\")\n",
    "    \n",
    "    \n",
    "    plt.plot(0.0)\n",
    "\n",
    "    for i in range(len(models)):\n",
    "\n",
    "        r2 = str(np.round(models_[i][1],2))\n",
    "        f2 = str(np.round(models_[i][3],2))\n",
    "        plt.text(i+1,1,r'$R^2$ ('+r2+') \\n$F^2$ ('+f2+')',\n",
    "                                 size= 12, rotation=0.,\n",
    "                                 ha=\"center\", va=\"top\", color = 'black',\n",
    "                                 #bbox=dict(boxstyle=\"round\", pad=0.1,\n",
    "                                 #          ec='ghostwhite',\n",
    "                                 #           fc='ghostwhite',\n",
    "                                 #         )\n",
    "                                 );\n",
    "        \n",
    "    \n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim([ylim[0], ylim[1]])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sabe_chile = pd.read_excel('../Data/cross/SABE_chile.xlsx') # to use it for columns order\n",
    "sabe_chile = sabe_chile.iloc[:,1::]\n",
    "\n",
    "sabe_costarica = pd.read_excel('../Data/long/SABE_costarica_long.xlsx')\n",
    "sabe_costarica = sabe_costarica.iloc[:,1::]\n",
    "\n",
    "sabe_korea_2006 = pd.read_excel('../Data/long/SABE_korea_2006.xlsx')\n",
    "sabe_korea_2006 = sabe_korea_2006.iloc[:,1::]\n",
    "\n",
    "sabe_korea_2006_2008 = pd.read_excel('../Data/long/SABE_korea_2006_2008.xlsx')\n",
    "sabe_korea_2006_2008 = sabe_korea_2006_2008.iloc[:,1::]\n",
    "\n",
    "sabe_korea_2006_2010 = pd.read_excel('../Data/long/SABE_korea_2006_2010.xlsx')\n",
    "sabe_korea_2006_2010 = sabe_korea_2006_2010.iloc[:,1::]\n",
    "\n",
    "sabe_korea_2006_2012 = pd.read_excel('../Data/long/SABE_korea_2006_2012.xlsx')\n",
    "sabe_korea_2006_2012 = sabe_korea_2006_2012.iloc[:,1::]\n",
    "\n",
    "sabe_korea_2006_2014 = pd.read_excel('../Data/long/SABE_korea_2006_2014.xlsx')\n",
    "sabe_korea_2006_2014 = sabe_korea_2006_2014.iloc[:,1::]\n",
    "\n",
    "sabe_korea_2006_2016 = pd.read_excel('../Data/long/SABE_korea_2006_2016.xlsx')\n",
    "sabe_korea_2006_2016 = sabe_korea_2006_2016.iloc[:,1::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FD_none_Edad_a01b',\n",
       " 'FD_none_Sexo_c18',\n",
       " 'FM_CardioMetab_Diabetes_c05',\n",
       " 'FS_Educ_yeduca',\n",
       " 'FS_Aislamiento_ViveSolo_g2',\n",
       " 'FS_EstSocEcon_TipoVivienda_none',\n",
       " 'FS_EstSocEcon_ElectricEquipment_none',\n",
       " 'FM_CardioMetab_IMC_none',\n",
       " 'FM_CardioMetab_Hiperten_c04',\n",
       " 'FM_CardioMetab_IAM_c08',\n",
       " 'FM_CardioMetab_ACV_c09',\n",
       " 'FM_EstiloVida_Alcohol_c23',\n",
       " 'FM_EstiloVida_ActividadFis_c25a',\n",
       " 'FM_EstiloVida_Fuma_c24',\n",
       " 'FM_EstiloVida_Caida12Mes_c11',\n",
       " 'FM_SaludMental_ProbNervDiagnost_c20',\n",
       " 'FS_Adversidad_AgresionFis_j27',\n",
       " 'FS_Adversidad_AgresionVerb_j28',\n",
       " 'MMSE',\n",
       " 'Barthel']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_col = list(sabe_chile.columns)\n",
    "del sabe_chile\n",
    "order_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_costarica_01 = sabe_costarica.copy()\n",
    "\n",
    "X_korea_2006_01 = sabe_korea_2006.copy()\n",
    "X_korea_2006_2008_01 = sabe_korea_2006_2008.copy()\n",
    "X_korea_2006_2010_01 = sabe_korea_2006_2010.copy()\n",
    "X_korea_2006_2012_01 = sabe_korea_2006_2012.copy()\n",
    "X_korea_2006_2014_01 = sabe_korea_2006_2014.copy()\n",
    "X_korea_2006_2016_01 = sabe_korea_2006_2016.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_drop = ['CASEID', 'FD_none_Edad_a01b', 'FD_none_Sexo_c18', 'FM_CardioMetab_Diabetes_c05', 'FS_Educ_yeduca', \n",
    "             'FS_Aislamiento_ViveSolo_g2_med',\n",
    "                'FM_CardioMetab_Hiperten_c04', 'FM_CardioMetab_IAM_c08',\n",
    "                 'FM_EstiloVida_Alcohol_c23', 'FM_EstiloVida_ActividadFis_c25a', 'FM_EstiloVida_Fuma_c24', \n",
    "                 'FM_EstiloVida_Caida12Mes_c11', 'FM_SaludMental_ProbNervDiagnost_c20', 'MMSE_diff', 'Barthel_diff']\n",
    "\n",
    "list_drop.append('Barthel_2008')\n",
    "X_korea_2006_2008_01 = X_korea_2006_2008_01[list_drop]\n",
    "\n",
    "list_drop.remove('Barthel_2008')\n",
    "list_drop.append('Barthel_2010')\n",
    "X_korea_2006_2010_01 = X_korea_2006_2010_01[list_drop]\n",
    "\n",
    "list_drop.remove('Barthel_2010')\n",
    "list_drop.append('Barthel_2012')\n",
    "X_korea_2006_2012_01 = X_korea_2006_2012_01[list_drop]\n",
    "\n",
    "list_drop.remove('Barthel_2012')\n",
    "list_drop.append('Barthel_2014')\n",
    "X_korea_2006_2014_01 = X_korea_2006_2014_01[list_drop]\n",
    "\n",
    "list_drop.remove('Barthel_2014')\n",
    "list_drop.append('Barthel_2016')\n",
    "X_korea_2006_2016_01 = X_korea_2006_2016_01[list_drop]\n",
    "\n",
    "\n",
    "list_drop = ['FD_none_Edad_a01b', 'FD_none_Sexo_c18', 'FM_CardioMetab_Diabetes_c05', 'FS_Educ_yeduca', \n",
    "             'FS_Aislamiento_ViveSolo_g2',\n",
    "                'FM_CardioMetab_Hiperten_c04', 'FM_CardioMetab_IAM_c08',\n",
    "                 'FM_EstiloVida_Alcohol_c23', 'FM_EstiloVida_ActividadFis_c25a', 'FM_EstiloVida_Fuma_c24', \n",
    "                 'FM_EstiloVida_Caida12Mes_c11_med','FM_SaludMental_ProbNervDiagnost_c20', 'MMSE_diff', 'Barthel_diff']\n",
    "\n",
    "\n",
    "list_drop.append('Barthel_w2')\n",
    "list_drop.append('Barthel')\n",
    "X_costarica_01 = X_costarica_01[list_drop]\n",
    "\n",
    "\n",
    "list_drop = ['CASEID', 'FD_none_Edad_a01b', 'FD_none_Sexo_c18', 'FM_CardioMetab_Diabetes_c05', 'FS_Educ_yeduca', 'FS_Aislamiento_ViveSolo_g2_med',\n",
    "                'FM_CardioMetab_Hiperten_c04', 'FM_CardioMetab_IAM_c08',\n",
    "                 'FM_EstiloVida_Alcohol_c23', 'FM_EstiloVida_ActividadFis_c25a', 'FM_EstiloVida_Fuma_c24', \n",
    "                 'FM_EstiloVida_Caida12Mes_c11','FM_SaludMental_ProbNervDiagnost_c20', 'Barthel']\n",
    "\n",
    "\n",
    "X_korea_2006_01 = X_korea_2006_01[list_drop]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data and get common participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9582, 14)\n"
     ]
    }
   ],
   "source": [
    "X_korea_2006_common_subjects = X_korea_2006_01.copy()\n",
    "X_korea_2006_common_subjects.dropna(inplace=True)\n",
    "\n",
    "X_korea_2006_ids = X_korea_2006_common_subjects['CASEID']\n",
    "print(X_korea_2006_common_subjects.shape,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7490, 14)\n"
     ]
    }
   ],
   "source": [
    "X_korea_2006_2008_common_subjects = X_korea_2006_2008_01.drop(['MMSE_diff'], axis=1)\n",
    "X_korea_2006_2008_common_subjects.drop(X_korea_2006_2008_common_subjects[X_korea_2006_2008_common_subjects['Barthel_diff'] <0].index, inplace=True)\n",
    "X_korea_2006_2008_common_subjects = X_korea_2006_2008_common_subjects.drop(['Barthel_diff' ], axis=1)\n",
    "X_korea_2006_2008_common_subjects.dropna(inplace=True)\n",
    "\n",
    "X_korea_2006_2008_ids = X_korea_2006_2008_common_subjects['CASEID']\n",
    "print(X_korea_2006_2008_common_subjects.shape,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6865, 14)\n"
     ]
    }
   ],
   "source": [
    "X_korea_2006_2010_common_subjects = X_korea_2006_2010_01.drop(['MMSE_diff' ], axis=1)\n",
    "X_korea_2006_2010_common_subjects.drop(X_korea_2006_2010_common_subjects[X_korea_2006_2010_common_subjects['Barthel_diff'] <0].index, inplace=True)\n",
    "X_korea_2006_2010_common_subjects = X_korea_2006_2010_common_subjects.drop(['Barthel_diff' ], axis=1)\n",
    "X_korea_2006_2010_common_subjects.dropna(inplace=True)\n",
    "\n",
    "X_korea_2006_2010_ids = X_korea_2006_2010_common_subjects['CASEID']\n",
    "print(X_korea_2006_2010_common_subjects.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6573, 14)\n"
     ]
    }
   ],
   "source": [
    "X_korea_2006_2012_common_subjects = X_korea_2006_2012_01.drop(['MMSE_diff' ], axis=1)\n",
    "X_korea_2006_2012_common_subjects.drop(X_korea_2006_2012_common_subjects[X_korea_2006_2012_common_subjects['Barthel_diff'] <0].index, inplace=True)\n",
    "X_korea_2006_2012_common_subjects = X_korea_2006_2012_common_subjects.drop(['Barthel_diff' ], axis=1)\n",
    "X_korea_2006_2012_common_subjects.dropna(inplace=True)\n",
    "\n",
    "X_korea_2006_2012_ids = X_korea_2006_2012_common_subjects['CASEID']\n",
    "print(X_korea_2006_2012_common_subjects.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6185, 14)\n"
     ]
    }
   ],
   "source": [
    "X_korea_2006_2014_common_subjects = X_korea_2006_2014_01.drop(['MMSE_diff' ], axis=1)\n",
    "X_korea_2006_2014_common_subjects.drop(X_korea_2006_2014_common_subjects[X_korea_2006_2014_common_subjects['Barthel_diff'] <0].index, inplace=True)\n",
    "X_korea_2006_2014_common_subjects = X_korea_2006_2014_common_subjects.drop(['Barthel_diff' ], axis=1)\n",
    "X_korea_2006_2014_common_subjects.dropna(inplace=True)\n",
    "\n",
    "X_korea_2006_2014_ids = X_korea_2006_2014_common_subjects['CASEID']\n",
    "print(X_korea_2006_2014_common_subjects.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5887, 14)\n"
     ]
    }
   ],
   "source": [
    "X_korea_2006_2016_common_subjects = X_korea_2006_2016_01.drop(['MMSE_diff' ], axis=1)\n",
    "X_korea_2006_2016_common_subjects.drop(X_korea_2006_2016_common_subjects[X_korea_2006_2016_common_subjects['Barthel_diff'] <0].index, inplace=True)\n",
    "X_korea_2006_2016_common_subjects = X_korea_2006_2016_common_subjects.drop(['Barthel_diff' ], axis=1)\n",
    "X_korea_2006_2016_common_subjects.dropna(inplace=True)\n",
    "\n",
    "X_korea_2006_2016_ids = X_korea_2006_2016_common_subjects['CASEID']\n",
    "print(X_korea_2006_2016_common_subjects.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5678, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge = X_korea_2006_ids.copy()\n",
    "#merge = pd.merge(merge, X_korea_2006_2008_ids, on='CASEID', how='inner')\n",
    "#merge = pd.merge(merge, X_korea_2006_2010_ids, on='CASEID', how='inner')\n",
    "#merge = pd.merge(merge, X_korea_2006_2012_ids, on='CASEID', how='inner')\n",
    "merge = pd.merge(merge, X_korea_2006_2014_ids, on='CASEID', how='inner')\n",
    "merge = pd.merge(merge, X_korea_2006_2016_ids, on='CASEID', how='inner')\n",
    "\n",
    "merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_korea_2006_common_ids = pd.merge(X_korea_2006_common_subjects, merge, on='CASEID', how='inner')\n",
    "X_korea_2006_common_ids = X_korea_2006_common_ids.drop('CASEID', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_korea_2006_2014_common_ids = pd.merge(X_korea_2006_2014_common_subjects, merge, on='CASEID', how='inner')\n",
    "X_korea_2006_2014_common_ids = X_korea_2006_2014_common_ids.drop('CASEID', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_korea_2006_2016_common_ids = pd.merge(X_korea_2006_2016_common_subjects, merge, on='CASEID', how='inner')\n",
    "X_korea_2006_2016_common_ids = X_korea_2006_2016_common_ids.drop('CASEID', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006: 5678 \t2014: 5678 \t2016: 5678\n",
      "2006: 3904 \t2014: 971 \t2016: 588\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "print('2006:', X_korea_2006_common_ids.shape[0], '\\t2014:', X_korea_2006_2014_common_ids.shape[0], '\\t2016:', X_korea_2006_2016_common_ids.shape[0])\n",
    "print('2006:', X_korea_2006_01.shape[0] - X_korea_2006_common_ids.shape[0], \n",
    "      '\\t2014:', X_korea_2006_2014_01.shape[0] - X_korea_2006_2014_common_ids.shape[0], \n",
    "      '\\t2016:', X_korea_2006_2016_01.shape[0] - X_korea_2006_2016_common_ids.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1502, 14)\n"
     ]
    }
   ],
   "source": [
    "X_costarica_01_common_subjects = X_costarica_01.drop(['MMSE_diff' ], axis=1)\n",
    "X_costarica_01_common_subjects.drop(X_costarica_01_common_subjects[X_costarica_01_common_subjects['Barthel_diff'] <0].index, inplace=True)\n",
    "X_costarica_01_common_subjects = X_costarica_01_common_subjects.drop(['Barthel_diff' ], axis=1)\n",
    "X_costarica_01_common_subjects.dropna(inplace=True)\n",
    "\n",
    "\n",
    "print(X_costarica_01_common_subjects.shape,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_costarica_w1 = X_costarica_01_common_subjects.drop(['Barthel_w2' ], axis=1)\n",
    "X_costarica_w2 = X_costarica_01_common_subjects.drop(['Barthel' ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1: 1502 \\w2: 1502\n",
      "w1: 659 \tw2: 0\n"
     ]
    }
   ],
   "source": [
    "print('w1:', X_costarica_w1.shape[0], '\\w2:', X_costarica_w2.shape[0])\n",
    "print('w1:', X_costarica_01.shape[0] - X_costarica_w1.shape[0], \n",
    "      '\\tw2:', X_costarica_01_common_subjects.shape[0] - X_costarica_w2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colors, variables names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = pd.read_csv('../Data/cross/var_name_color_code_new.csv', encoding='latin-1', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_name = []\n",
    "\n",
    "for i in range(len(X_costarica_w1.columns)):\n",
    "    if(X_costarica_w1.columns[i] == 'FM_EstiloVida_Caida12Mes_c11_med'):\n",
    "        label = 'FM_EstiloVida_Caida12Mes_c11'\n",
    "    else:\n",
    "        label = X_costarica_w1.columns[i]\n",
    "    \n",
    "    index_ = list(X_cat.oldname).index(label)\n",
    "    new_name.append(list(X_cat.newname)[index_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " FD_none_Edad_a01b \n",
      " FD_none_Edad_a01b \n",
      " FD_none_Edad_a01b \n",
      " FD_none_Edad_a01b \n",
      " FD_none_Edad_a01b \n",
      " Age\n",
      "-------------------------------------------\n",
      " FD_none_Sexo_c18 \n",
      " FD_none_Sexo_c18 \n",
      " FD_none_Sexo_c18 \n",
      " FD_none_Sexo_c18 \n",
      " FD_none_Sexo_c18 \n",
      " Sex\n",
      "-------------------------------------------\n",
      " FM_CardioMetab_Diabetes_c05 \n",
      " FM_CardioMetab_Diabetes_c05 \n",
      " FM_CardioMetab_Diabetes_c05 \n",
      " FM_CardioMetab_Diabetes_c05 \n",
      " FM_CardioMetab_Diabetes_c05 \n",
      " Diabetes\n",
      "-------------------------------------------\n",
      " FS_Educ_yeduca \n",
      " FS_Educ_yeduca \n",
      " FS_Educ_yeduca \n",
      " FS_Educ_yeduca \n",
      " FS_Educ_yeduca \n",
      " Education\n",
      "-------------------------------------------\n",
      " FS_Aislamiento_ViveSolo_g2 \n",
      " FS_Aislamiento_ViveSolo_g2 \n",
      " FS_Aislamiento_ViveSolo_g2_med \n",
      " FS_Aislamiento_ViveSolo_g2_med \n",
      " FS_Aislamiento_ViveSolo_g2_med \n",
      " Live Alone\n",
      "-------------------------------------------\n",
      " FM_CardioMetab_Hiperten_c04 \n",
      " FM_CardioMetab_Hiperten_c04 \n",
      " FM_CardioMetab_Hiperten_c04 \n",
      " FM_CardioMetab_Hiperten_c04 \n",
      " FM_CardioMetab_Hiperten_c04 \n",
      " Hypertension\n",
      "-------------------------------------------\n",
      " FM_CardioMetab_IAM_c08 \n",
      " FM_CardioMetab_IAM_c08 \n",
      " FM_CardioMetab_IAM_c08 \n",
      " FM_CardioMetab_IAM_c08 \n",
      " FM_CardioMetab_IAM_c08 \n",
      " Heart Disease\n",
      "-------------------------------------------\n",
      " FM_EstiloVida_Alcohol_c23 \n",
      " FM_EstiloVida_Alcohol_c23 \n",
      " FM_EstiloVida_Alcohol_c23 \n",
      " FM_EstiloVida_Alcohol_c23 \n",
      " FM_EstiloVida_Alcohol_c23 \n",
      " Alcohol consumption\n",
      "-------------------------------------------\n",
      " FM_EstiloVida_ActividadFis_c25a \n",
      " FM_EstiloVida_ActividadFis_c25a \n",
      " FM_EstiloVida_ActividadFis_c25a \n",
      " FM_EstiloVida_ActividadFis_c25a \n",
      " FM_EstiloVida_ActividadFis_c25a \n",
      " Physical activity\n",
      "-------------------------------------------\n",
      " FM_EstiloVida_Fuma_c24 \n",
      " FM_EstiloVida_Fuma_c24 \n",
      " FM_EstiloVida_Fuma_c24 \n",
      " FM_EstiloVida_Fuma_c24 \n",
      " FM_EstiloVida_Fuma_c24 \n",
      " Smoking status\n",
      "-------------------------------------------\n",
      " FM_EstiloVida_Caida12Mes_c11_med \n",
      " FM_EstiloVida_Caida12Mes_c11_med \n",
      " FM_EstiloVida_Caida12Mes_c11 \n",
      " FM_EstiloVida_Caida12Mes_c11 \n",
      " FM_EstiloVida_Caida12Mes_c11 \n",
      " Falls\n",
      "-------------------------------------------\n",
      " FM_SaludMental_ProbNervDiagnost_c20 \n",
      " FM_SaludMental_ProbNervDiagnost_c20 \n",
      " FM_SaludMental_ProbNervDiagnost_c20 \n",
      " FM_SaludMental_ProbNervDiagnost_c20 \n",
      " FM_SaludMental_ProbNervDiagnost_c20 \n",
      " Mental Problems\n",
      "-------------------------------------------\n",
      " Barthel \n",
      " Barthel_w2 \n",
      " Barthel \n",
      " Barthel_2014 \n",
      " Barthel_2016 \n",
      " Barthel\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check\n",
    "for i in range(len(X_costarica_w1.columns)):\n",
    "    print('', X_costarica_w1.columns[i], '\\n', X_costarica_w2.columns[i], '\\n', X_korea_2006_common_ids.columns[i], \n",
    "          '\\n', X_korea_2006_2014_common_ids.columns[i], '\\n', \n",
    "          X_korea_2006_2016_common_ids.columns[i], '\\n',new_name[i])\n",
    "    print('-------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_costarica_w1.columns =  new_name\n",
    "X_costarica_w2.columns =  new_name\n",
    "X_korea_2006_common_ids.columns =  new_name\n",
    "#X_korea_2006_2012_common_ids.columns =  new_name\n",
    "X_korea_2006_2014_common_ids.columns =  new_name\n",
    "X_korea_2006_2016_common_ids.columns =  new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Age \n",
      " Age \n",
      " Age \n",
      " Age \n",
      " Age \n",
      " Age\n",
      "-------------------------------------------\n",
      " Sex \n",
      " Sex \n",
      " Sex \n",
      " Sex \n",
      " Sex \n",
      " Sex\n",
      "-------------------------------------------\n",
      " Diabetes \n",
      " Diabetes \n",
      " Diabetes \n",
      " Diabetes \n",
      " Diabetes \n",
      " Diabetes\n",
      "-------------------------------------------\n",
      " Education \n",
      " Education \n",
      " Education \n",
      " Education \n",
      " Education \n",
      " Education\n",
      "-------------------------------------------\n",
      " Live Alone \n",
      " Live Alone \n",
      " Live Alone \n",
      " Live Alone \n",
      " Live Alone \n",
      " Live Alone\n",
      "-------------------------------------------\n",
      " Hypertension \n",
      " Hypertension \n",
      " Hypertension \n",
      " Hypertension \n",
      " Hypertension \n",
      " Hypertension\n",
      "-------------------------------------------\n",
      " Heart Disease \n",
      " Heart Disease \n",
      " Heart Disease \n",
      " Heart Disease \n",
      " Heart Disease \n",
      " Heart Disease\n",
      "-------------------------------------------\n",
      " Alcohol consumption \n",
      " Alcohol consumption \n",
      " Alcohol consumption \n",
      " Alcohol consumption \n",
      " Alcohol consumption \n",
      " Alcohol consumption\n",
      "-------------------------------------------\n",
      " Physical activity \n",
      " Physical activity \n",
      " Physical activity \n",
      " Physical activity \n",
      " Physical activity \n",
      " Physical activity\n",
      "-------------------------------------------\n",
      " Smoking status \n",
      " Smoking status \n",
      " Smoking status \n",
      " Smoking status \n",
      " Smoking status \n",
      " Smoking status\n",
      "-------------------------------------------\n",
      " Falls \n",
      " Falls \n",
      " Falls \n",
      " Falls \n",
      " Falls \n",
      " Falls\n",
      "-------------------------------------------\n",
      " Mental Problems \n",
      " Mental Problems \n",
      " Mental Problems \n",
      " Mental Problems \n",
      " Mental Problems \n",
      " Mental Problems\n",
      "-------------------------------------------\n",
      " Barthel \n",
      " Barthel \n",
      " Barthel \n",
      " Barthel \n",
      " Barthel \n",
      " Barthel\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check\n",
    "for i in range(len(X_costarica_w1.columns)):\n",
    "    print('', X_costarica_w1.columns[i], '\\n', X_costarica_w2.columns[i], '\\n', X_korea_2006_common_ids.columns[i], \n",
    "          '\\n', X_korea_2006_2014_common_ids.columns[i], '\\n', \n",
    "          X_korea_2006_2016_common_ids.columns[i], '\\n',new_name[i])\n",
    "    print('-------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korea 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_korea_2006 = X_korea_2006_common_ids['Barthel']\n",
    "X_korea_2006 = X_korea_2006_common_ids.drop('Barthel', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge\n",
      "best parameters: OrderedDict([('alpha', 1.0), ('max_iter', 1000), ('solver', 'sag')])\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_korea_2006, y_korea_2006, train_size=0.75, test_size=.25, random_state=0)\n",
    "\n",
    "# log-uniform: understand as search over p = exp(x) by varying x\n",
    "opt_Ridge = BayesSearchCV(\n",
    "    Ridge(),\n",
    "    {\n",
    "        'alpha': (1.0, 0.1, 0.01, 0.001),\n",
    "        'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "        'max_iter': (1000, 10000, 100000, 1000000),\n",
    "        #'tol:' : (1e-6, 1e-3, 1e+1),\n",
    "        #'n_estimators': (100, 1000),\n",
    "\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "opt_Ridge.fit(X_train, y_train)\n",
    "\n",
    "print('Ridge')\n",
    "print(\"best parameters: %s\" % str(opt_Ridge.best_params_))\n",
    "print('---------------------------------------------\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen del regresor Ridge\n",
      "\n",
      "Residuals:\n",
      " Min     1Q  Median     3Q     Max\n",
      "9.54 9.8946  9.9503 10.001 10.1347\n",
      "\n",
      "\n",
      "Coefficients:\n",
      "                     Estimate   t value       p value\n",
      "_intercept           9.534465   0.00010  9.999127e-01\n",
      "Age                 -0.005330  35.01018  0.000000e+00\n",
      "Sex                  0.036085   2.20910  2.720743e-02\n",
      "Diabetes             0.003656   0.17850  8.583025e-01\n",
      "Education            0.009834   0.96160  3.362756e-01\n",
      "Live Alone          -0.000000   0.00000  1.000000e+00\n",
      "Hypertension         0.028923   1.99270  4.634382e-02\n",
      "Heart Disease        0.016554   0.54590  5.851878e-01\n",
      "Alcohol consumption  0.027898   3.14820  1.651216e-03\n",
      "Physical activity   -0.041309   3.22300  1.275648e-03\n",
      "Smoking status       0.023979   1.35240  1.763048e-01\n",
      "Falls                0.055645   1.72860  8.393900e-02\n",
      "Mental Problems      0.219262   5.08280  3.837950e-07\n",
      "---\n",
      "R-squared:  0.02596,    Adjusted R-squared:  0.02390\n",
      "F-squared:  0.02666\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelRidge_korea_2006 = Ridge(alpha=opt_Ridge.best_params_['alpha'], solver = opt_Ridge.best_params_['solver'], \n",
    "                         max_iter=opt_Ridge.best_params_['max_iter'])\n",
    "modelRidge_korea_2006.fit(X_korea_2006, y_korea_2006)\n",
    "\n",
    "parameter_dict['korea_2006'] = opt_Ridge.best_params_\n",
    "\n",
    "modelRidge_sum_korea_2006 = summary(modelRidge_korea_2006, X_korea_2006, y_korea_2006, X_korea_2006.columns, 'Ridge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korea 2006-2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_korea_2006_2014 = X_korea_2006_2014_common_ids['Barthel']\n",
    "X_korea_2006_2014 = X_korea_2006_2014_common_ids.drop('Barthel', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge\n",
      "best parameters: OrderedDict([('alpha', 0.1), ('max_iter', 100000), ('solver', 'lsqr')])\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_korea_2006_2014, y_korea_2006_2014, train_size=0.75, test_size=.25, random_state=0)\n",
    "\n",
    "# log-uniform: understand as search over p = exp(x) by varying x\n",
    "opt_Ridge = BayesSearchCV(\n",
    "    Ridge(),\n",
    "    {\n",
    "        'alpha': (1.0, 0.1, 0.01, 0.001),\n",
    "        'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "        'max_iter': (1000, 10000, 100000, 1000000),\n",
    "        #'tol:' : (1e-6, 1e-3, 1e+1),\n",
    "        #'n_estimators': (100, 1000),\n",
    "\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "opt_Ridge.fit(X_train, y_train)\n",
    "\n",
    "print('Ridge')\n",
    "print(\"best parameters: %s\" % str(opt_Ridge.best_params_))\n",
    "print('---------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen del regresor Ridge\n",
      "\n",
      "Residuals:\n",
      "   Min     1Q  Median     3Q    Max\n",
      "8.2969 9.3551  9.6667 9.9732 10.459\n",
      "\n",
      "\n",
      "Coefficients:\n",
      "                      Estimate  t value   p value\n",
      "_intercept           11.248607   0.0000  0.999964\n",
      "Age                  -0.037981  76.7921  0.000000\n",
      "Sex                   0.034604   0.7457  0.455888\n",
      "Diabetes              0.044966   0.7730  0.439546\n",
      "Education             0.075032   2.5828  0.009825\n",
      "Live Alone           -0.000000   0.0000  1.000000\n",
      "Hypertension          0.065067   1.5780  0.114626\n",
      "Heart Disease         0.007584   0.0880  0.929856\n",
      "Alcohol consumption   0.036180   1.4371  0.150731\n",
      "Physical activity    -0.082492   2.2655  0.023520\n",
      "Smoking status        0.114134   2.2658  0.023500\n",
      "Falls                 0.037987   0.4154  0.677885\n",
      "Mental Problems       0.029836   0.2435  0.807656\n",
      "---\n",
      "R-squared:  0.08232,    Adjusted R-squared:  0.08038\n",
      "F-squared:  0.08971\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelRidge_korea_2006_2014 = Ridge(alpha=0.001, solver = opt_Ridge.best_params_['solver'], \n",
    "                         max_iter=opt_Ridge.best_params_['max_iter'])\n",
    "modelRidge_korea_2006_2014.fit(X_korea_2006_2014, y_korea_2006_2014)\n",
    "\n",
    "parameter_dict['korea_2006_2014'] = opt_Ridge.best_params_\n",
    "\n",
    "modelRidge_sum_korea_2006_2014 = summary(modelRidge_korea_2006_2014, X_korea_2006_2014, y_korea_2006_2014, X_korea_2006_2014.columns, 'Ridge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korea 2006-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_korea_2006_2016 = X_korea_2006_2016_common_ids['Barthel']\n",
    "X_korea_2006_2016 = X_korea_2006_2016_common_ids.drop('Barthel', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge\n",
      "best parameters: OrderedDict([('alpha', 0.01), ('max_iter', 10000), ('solver', 'lsqr')])\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_korea_2006_2016, y_korea_2006_2016, train_size=0.75, test_size=.25, random_state=0)\n",
    "\n",
    "# log-uniform: understand as search over p = exp(x) by varying x\n",
    "opt_Ridge = BayesSearchCV(\n",
    "    Ridge(),\n",
    "    {\n",
    "        'alpha': (1.0, 0.1, 0.01, 0.001),\n",
    "        'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "        'max_iter': (1000, 10000, 100000, 1000000),\n",
    "        #'tol:' : (1e-6, 1e-3, 1e+1),\n",
    "        #'n_estimators': (100, 1000),\n",
    "\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "opt_Ridge.fit(X_train, y_train)\n",
    "\n",
    "print('Ridge')\n",
    "print(\"best parameters: %s\" % str(opt_Ridge.best_params_))\n",
    "print('---------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen del regresor Ridge\n",
      "\n",
      "Residuals:\n",
      "   Min     1Q  Median     3Q     Max\n",
      "7.5183 9.0929  9.5492 9.9894 10.5439\n",
      "\n",
      "\n",
      "Coefficients:\n",
      "                      Estimate  t value   p value\n",
      "_intercept           12.044460   0.0000  0.999968\n",
      "Age                  -0.054669  87.4261  0.000000\n",
      "Sex                  -0.006510   0.1146  0.908748\n",
      "Diabetes              0.088466   1.2427  0.214044\n",
      "Education             0.042057   1.1829  0.236893\n",
      "Live Alone           -0.000000   0.0000  1.000000\n",
      "Hypertension          0.154557   3.0627  0.002204\n",
      "Heart Disease         0.044303   0.4202  0.674379\n",
      "Alcohol consumption   0.026430   0.8578  0.391024\n",
      "Physical activity    -0.124306   2.7894  0.005297\n",
      "Smoking status        0.119072   1.9315  0.053472\n",
      "Falls                -0.008625   0.0771  0.938576\n",
      "Mental Problems       0.044643   0.2977  0.765980\n",
      "---\n",
      "R-squared:  0.10554,    Adjusted R-squared:  0.10364\n",
      "F-squared:  0.11799\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelRidge_korea_2006_2016 = Ridge(alpha=opt_Ridge.best_params_['alpha'], solver = opt_Ridge.best_params_['solver'], \n",
    "                         max_iter=opt_Ridge.best_params_['max_iter'])\n",
    "modelRidge_korea_2006_2016.fit(X_korea_2006_2016, y_korea_2006_2016)\n",
    "\n",
    "parameter_dict['korea_2006_2016'] = opt_Ridge.best_params_\n",
    "\n",
    "modelRidge_sum_korea_2006_2016 = summary(modelRidge_korea_2006_2016, X_korea_2006_2016, y_korea_2006_2016, X_korea_2006_2016.columns, 'Ridge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costa Rica wave 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_costarica_1 = X_costarica_w1['Barthel']\n",
    "X_costarica_1 = X_costarica_w1.drop(['Barthel'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge\n",
      "best parameters: OrderedDict([('alpha', 1.0), ('max_iter', 1000), ('solver', 'lsqr')])\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_costarica_1, y_costarica_1, train_size=0.75, test_size=.25, random_state=0)\n",
    "\n",
    "# log-uniform: understand as search over p = exp(x) by varying x\n",
    "opt_Ridge = BayesSearchCV(\n",
    "    Ridge(),\n",
    "    {\n",
    "        'alpha': (1.0, 0.1, 0.01, 0.001),\n",
    "        'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "        'max_iter': (1000, 10000, 100000, 1000000),\n",
    "        #'tol:' : (1e-6, 1e-3, 1e+1),\n",
    "        #'n_estimators': (100, 1000),\n",
    "\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "opt_Ridge.fit(X_train, y_train)\n",
    "\n",
    "print('Ridge')\n",
    "print(\"best parameters: %s\" % str(opt_Ridge.best_params_))\n",
    "print('---------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen del regresor Ridge\n",
      "\n",
      "Residuals:\n",
      "   Min     1Q  Median     3Q    Max\n",
      "6.8794 8.1914   8.494 8.6979 9.3901\n",
      "\n",
      "\n",
      "Coefficients:\n",
      "                     Estimate   t value       p value\n",
      "_intercept           5.308324  0.000000  9.999974e-01\n",
      "Age                 -0.001196  1.555423  1.200478e-01\n",
      "Sex                  0.130127  2.278200  2.285254e-02\n",
      "Diabetes             0.307382  4.603300  4.508957e-06\n",
      "Education            0.164582  4.891000  1.110973e-06\n",
      "Live Alone           0.065669  0.690400  4.900399e-01\n",
      "Hypertension         0.302587  5.970900  2.939887e-09\n",
      "Heart Disease        0.506584  3.430800  6.181129e-04\n",
      "Alcohol consumption  0.061057  1.389700  1.648274e-01\n",
      "Physical activity   -0.183215  3.300500  9.875988e-04\n",
      "Smoking status      -0.010360  0.189500  8.496960e-01\n",
      "Falls                0.000000  0.000000  1.000000e+00\n",
      "Mental Problems      0.495609  7.943300  3.774760e-15\n",
      "---\n",
      "R-squared:  0.14755,    Adjusted R-squared:  0.14068\n",
      "F-squared:  0.17309\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelRidge_costarica_1 = Ridge(alpha=opt_Ridge.best_params_['alpha'], solver = opt_Ridge.best_params_['solver'], \n",
    "                         max_iter=opt_Ridge.best_params_['max_iter'])\n",
    "modelRidge_costarica_1.fit(X_costarica_1, y_costarica_1)\n",
    "\n",
    "parameter_dict['costarica_wave_1'] = opt_Ridge.best_params_\n",
    "\n",
    "modelRidge_sum_costarica_1 = summary(modelRidge_costarica_1, X_costarica_1, y_costarica_1, X_costarica_1.columns, 'Ridge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costa Rica wave 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_costarica_2 = X_costarica_w2['Barthel']\n",
    "X_costarica_2 = X_costarica_w2.drop(['Barthel'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge\n",
      "best parameters: OrderedDict([('alpha', 1.0), ('max_iter', 1000000), ('solver', 'sparse_cg')])\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_costarica_2, y_costarica_2, train_size=0.75, test_size=.25, random_state=0)\n",
    "\n",
    "# log-uniform: understand as search over p = exp(x) by varying x\n",
    "opt_Ridge = BayesSearchCV(\n",
    "    Ridge(),\n",
    "    {\n",
    "        'alpha': (1.0, 0.1, 0.01, 0.001),\n",
    "        'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "        'max_iter': (1000, 10000, 100000, 1000000),\n",
    "        #'tol:' : (1e-6, 1e-3, 1e+1),\n",
    "        #'n_estimators': (100, 1000),\n",
    "\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "opt_Ridge.fit(X_train, y_train)\n",
    "\n",
    "print('Ridge')\n",
    "print(\"best parameters: %s\" % str(opt_Ridge.best_params_))\n",
    "print('---------------------------------------------\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen del regresor Ridge\n",
      "\n",
      "Residuals:\n",
      "    Min      1Q  Median     3Q    Max\n",
      "-2.7392 -0.8844 -0.3708 0.5036 6.7831\n",
      "\n",
      "\n",
      "Coefficients:\n",
      "                     Estimate  t value       p value\n",
      "_intercept           4.206485   0.0000  9.999986e-01\n",
      "Age                 -0.010381   2.5202  1.183319e-02\n",
      "Sex                  0.146255   1.6914  9.095862e-02\n",
      "Diabetes             0.352379   3.4858  5.047864e-04\n",
      "Education            0.269736   5.2950  1.367179e-07\n",
      "Live Alone          -0.011506   0.0799  9.363174e-01\n",
      "Hypertension         0.421226   5.4904  4.701382e-08\n",
      "Heart Disease        0.799747   3.5775  3.579186e-04\n",
      "Alcohol consumption  0.145927   2.1940  2.838919e-02\n",
      "Physical activity   -0.308504   3.6710  2.500561e-04\n",
      "Smoking status      -0.031276   0.3780  7.055143e-01\n",
      "Falls                0.000000   0.0000  1.000000e+00\n",
      "Mental Problems      0.692651   7.3329  3.670397e-13\n",
      "---\n",
      "R-squared:  0.13703,    Adjusted R-squared:  0.13008\n",
      "F-squared:  0.15879\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelRidge_costarica_2 = Ridge(alpha=opt_Ridge.best_params_['alpha'], solver = opt_Ridge.best_params_['solver'], \n",
    "                         max_iter=opt_Ridge.best_params_['max_iter'])\n",
    "modelRidge_costarica_2.fit(X_costarica_2, y_costarica_2)\n",
    "\n",
    "parameter_dict['costarica_wave_2'] = opt_Ridge.best_params_\n",
    "\n",
    "modelRidge_sum_costarica_2 = summary(modelRidge_costarica_2, X_costarica_2, y_costarica_2, X_costarica_2.columns, 'Ridge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistically significant variables in both Costa Rica wave 2 and Korea 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = get_order_var(modelRidge_sum_costarica_2)\n",
    "df = modelRidge_sum_costarica_2\n",
    "\n",
    "feature_sign = []\n",
    "\n",
    "for i in col:\n",
    "    if df[0]['p value'][i] < 0.05:\n",
    "        feature_sign.append(i)\n",
    "\n",
    "\n",
    "df = modelRidge_sum_korea_2006_2016\n",
    "\n",
    "for i in col:\n",
    "    if df[0]['p value'][i] < 0.05 and i not in feature_sign:\n",
    "        feature_sign.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Heart Disease',\n",
       " 'Mental Problems',\n",
       " 'Hypertension',\n",
       " 'Diabetes',\n",
       " 'Physical activity',\n",
       " 'Education',\n",
       " 'Alcohol consumption',\n",
       " 'Age']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking de variables significativas Costa Rica wave 2\n",
      "                     Estimate\n",
      "Features                     \n",
      "Heart Disease        0.799747\n",
      "Mental Problems      0.692651\n",
      "Hypertension         0.421226\n",
      "Diabetes             0.352379\n",
      "Physical activity    0.308504\n",
      "Education            0.269736\n",
      "Alcohol consumption  0.145927\n",
      "Age                  0.010381\n",
      "\n",
      "\n",
      "Ranking de variables significativas Korea 2016\n",
      "                     Estimate\n",
      "Features                     \n",
      "Hypertension         0.154557\n",
      "Physical activity    0.124306\n",
      "Diabetes             0.088466\n",
      "Age                  0.054669\n",
      "Mental Problems      0.044643\n",
      "Heart Disease        0.044303\n",
      "Education            0.042057\n",
      "Alcohol consumption  0.026430\n"
     ]
    }
   ],
   "source": [
    "## Costa Rica\n",
    "\n",
    "df_costarica_w2 = modelRidge_sum_costarica_2[0].copy()\n",
    "\n",
    "df_costarica_w2.index.name = 'Features'\n",
    "df_costarica_w2 = df_costarica_w2.iloc[1:-3, 0:-1]\n",
    "\n",
    "df_costarica_w2 = df_costarica_w2.loc[feature_sign, :]\n",
    "\n",
    "for i in range(3):\n",
    "    df_costarica_w2[df_costarica_w2.columns[i]] = np.abs(pd.to_numeric(df_costarica_w2[df_costarica_w2.columns[i]],errors = 'coerce'))\n",
    "\n",
    "df = df_costarica_w2.reset_index()\n",
    "data_costarica_w2 = df_costarica_w2.sort_values('Estimate', ascending=False)\n",
    "\n",
    "print('Ranking de variables significativas Costa Rica wave 2')\n",
    "print(pd.DataFrame(data_costarica_w2['Estimate']))\n",
    "\n",
    "## Korea\n",
    "\n",
    "df_korea_2016 = modelRidge_sum_korea_2006_2016[0].copy()\n",
    "\n",
    "df_korea_2016.index.name = 'Features'\n",
    "df_korea_2016 = df_korea_2016.iloc[1:-3, 0:-1]\n",
    "\n",
    "df_korea_2016 = df_korea_2016.loc[feature_sign, :]\n",
    "\n",
    "for i in range(3):\n",
    "    df_korea_2016[df_korea_2016.columns[i]] = np.abs(pd.to_numeric(df_korea_2016[df_korea_2016.columns[i]],errors = 'coerce'))\n",
    "\n",
    "df = df_korea_2016.reset_index()\n",
    "data_korea_2016 = df_korea_2016.sort_values('Estimate', ascending=False)\n",
    "\n",
    "print('\\n\\nRanking de variables significativas Korea 2016')\n",
    "print(pd.DataFrame(data_korea_2016['Estimate']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-test for Coefficients between Costa Rica wave 2 and Korea 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_dict = {}\n",
    "for i in feature_sign:\n",
    "\n",
    "    beta_dict['CR_' + i] = []\n",
    "    beta_dict['KO_' + i] = []\n",
    "\n",
    "\n",
    "y_database = X_costarica_w2['Barthel']\n",
    "X_database = X_costarica_w2.drop('Barthel', axis=1)\n",
    "X_database = X_database[feature_sign]\n",
    "\n",
    "\n",
    "for i in range(0,100,10):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_database, y_database, train_size=0.75, test_size=.25, random_state=i)\n",
    "\n",
    "    opt_Ridge = BayesSearchCV(\n",
    "            Ridge(),\n",
    "            {\n",
    "                'alpha': ( 0.0001, 0.01, 0.001),\n",
    "                'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "                'max_iter': (1000, 10000, 100000, 1000000),\n",
    "            },\n",
    "            n_iter=10,\n",
    "            random_state=i, \n",
    "            scoring='r2',\n",
    "            cv=3\n",
    "        )\n",
    "\n",
    "    opt_Ridge.fit(X_train, y_train)\n",
    "    \n",
    "    ## Ac uso el modelo Ridge con los parmetros entregadps por el optimizacion bayesiano porque el BayesSearch no me entrega los Beta values.\n",
    "\n",
    "    model = Ridge(alpha=opt_Ridge.best_params_['alpha'], solver = opt_Ridge.best_params_['solver'], \n",
    "                             max_iter=opt_Ridge.best_params_['max_iter'])\n",
    "    \n",
    "    model.fit(X_test, y_test)\n",
    "    \n",
    "    # Esta parte la ahago as para ser consecuente con la forma que he ido guardando los resultados y que me sirvan las mismas funciones que ya tengo diseadas (en caso de necesitarlas)\n",
    "    coef_df = pd.DataFrame(\n",
    "        index=['_intercept'] + list(X_test.columns),\n",
    "        columns=['Estimate']\n",
    "        )\n",
    "\n",
    "    coef_df['Estimate'] = np.concatenate((np.round(np.array([model.intercept_]), 12), np.round((model.coef_), 12)))\n",
    "\n",
    "    #Ac guardo los beta values de las variables elegidas\n",
    "    for j in feature_sign:\n",
    "        beta_dict['CR_' + j].append(np.abs(coef_df['Estimate'][j])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_database = X_korea_2006_2016_common_ids['Barthel']\n",
    "X_database = X_korea_2006_2016_common_ids.drop('Barthel', axis=1)\n",
    "X_database = X_database[feature_sign]\n",
    "\n",
    "\n",
    "for i in range(0,100,10):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_database, y_database, train_size=0.75, test_size=.25, random_state=i)\n",
    "\n",
    "    opt_Ridge = BayesSearchCV(\n",
    "            Ridge(),\n",
    "            {\n",
    "                'alpha': ( 0.0001, 0.01, 0.001),\n",
    "                'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "                'max_iter': (1000, 10000, 100000, 1000000),\n",
    "            },\n",
    "            n_iter=10,\n",
    "            random_state=i, \n",
    "            scoring='r2',\n",
    "            cv=3\n",
    "        )\n",
    "\n",
    "    opt_Ridge.fit(X_train, y_train)\n",
    "    \n",
    "    ## Ac uso el modelo Ridge con los parmetros entregadps por el optimizacion bayesiano porque el BayesSearch no me entrega los Beta values.\n",
    "    model = Ridge(alpha=opt_Ridge.best_params_['alpha'], solver = opt_Ridge.best_params_['solver'], \n",
    "                             max_iter=opt_Ridge.best_params_['max_iter'])\n",
    "    \n",
    "    model.fit(X_test, y_test)\n",
    "    \n",
    "    # Esta parte la ahago as para ser consecuente con la forma que he ido guardando los resultados y que me sirvan las mismas funciones que ya tengo diseadas (en caso de necesitarlas)\n",
    "    coef_df = pd.DataFrame(\n",
    "        index=['_intercept'] + list(X_test.columns),\n",
    "        columns=['Estimate']\n",
    "        )\n",
    "\n",
    "    coef_df['Estimate'] = np.concatenate((np.round(np.array([model.intercept_]), 12), np.round((model.coef_), 12)))\n",
    "\n",
    "    #Ac guardo los beta values de las variables elegidas\n",
    "    for j in feature_sign:\n",
    "        beta_dict['KO_'+ j].append(np.abs(coef_df['Estimate'][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_df = pd.DataFrame(beta_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelo/anaconda3/envs/HBL/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:7: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n",
      "/home/marcelo/anaconda3/envs/HBL/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:7: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import statsmodels.api\n",
    "\n",
    "result_scipy_df = pd.DataFrame(\n",
    "        index=['p value'] ,\n",
    "        columns=feature_sign\n",
    "        )\n",
    "\n",
    "result_stats_df = pd.DataFrame(\n",
    "        index=['p value'] ,\n",
    "        columns=feature_sign\n",
    "        )\n",
    "\n",
    "for i in feature_sign:\n",
    "    result_scipy_df[i] = stats.ttest_ind(beta_dict['CR_'+ i], beta_dict['KO_' + i], equal_var=False)[1]\n",
    "    result_stats_df[i] = statsmodels.stats.weightstats.ttest_ind(beta_dict['CR_'+ i], beta_dict['KO_' + i], alternative=\"two-sided\",usevar=\"unequal\")[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-6cc8d65d88a7>:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  beta_df_stat = beta_df_stat.append(beta_df_stat.iloc[1,:]*1.95,ignore_index=True)\n",
      "<ipython-input-51-6cc8d65d88a7>:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  beta_df_stat = beta_df_stat.append(beta_df_stat.iloc[1,:]*2.58,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "beta_df_stat = beta_df.describe().round(3).iloc[1:3,:]\n",
    "beta_df_stat = beta_df_stat.append(beta_df_stat.iloc[1,:]*1.95,ignore_index=True)\n",
    "beta_df_stat = beta_df_stat.append(beta_df_stat.iloc[1,:]*2.58,ignore_index=True)\n",
    "\n",
    "beta_df_stat = beta_df_stat.rename(index={0:'mean', 1:'std', 2:'95', 3:'99'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sign_order = ['Education', 'Age', 'Physical activity', 'Alcohol consumption', 'Heart Disease', 'Hypertension', \n",
    "                      'Diabetes', 'Mental Problems']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CR_mean</th>\n",
       "      <th>CR_std</th>\n",
       "      <th>KO_mean</th>\n",
       "      <th>KO_std</th>\n",
       "      <th>ttest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physical activity</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol consumption</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heart Disease</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertension</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetes</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mental Problems</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    CR_mean CR_std KO_mean KO_std ttest\n",
       "Education              0.29   0.09    0.04   0.03   0.0\n",
       "Age                    0.02   0.01    0.06    0.0   0.0\n",
       "Physical activity      0.35   0.13    0.11   0.08   0.0\n",
       "Alcohol consumption     0.2   0.08    0.04   0.03   0.0\n",
       "Heart Disease          0.46   0.37    0.28   0.17  0.17\n",
       "Hypertension           0.43   0.13    0.16   0.05   0.0\n",
       "Diabetes               0.45   0.18    0.14   0.12   0.0\n",
       "Mental Problems        0.86    0.2    0.19   0.16   0.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_result_df = pd.DataFrame(\n",
    "        index=feature_sign_order ,\n",
    "        columns=['CR_mean', 'CR_std','KO_mean','KO_std', 'ttest']\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "count = 0\n",
    "for i in feature_sign_order:\n",
    "    general_result_df.iloc[count, 0] = np.round(beta_df_stat['CR_' + i][0],2)\n",
    "    general_result_df.iloc[count, 1] = np.round(beta_df_stat['CR_' + i][1],2)\n",
    "    \n",
    "    general_result_df.iloc[count, 2] = np.round(beta_df_stat['KO_' + i][0],2)\n",
    "    general_result_df.iloc[count, 3] = np.round(beta_df_stat['KO_' + i][1],2)\n",
    "    \n",
    "    general_result_df.iloc[count, 4] = np.round(result_stats_df[i][0],2)\n",
    "    \n",
    "    count +=1\n",
    "    \n",
    "general_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_values_ttest(modelRidge_sum_model1, modelRidge_sum_model2, X_1, X_2, only_significance = False):\n",
    "    col = get_order_var(modelRidge_sum_model1)\n",
    "    df = modelRidge_sum_model1\n",
    "\n",
    "    feature_sign = []\n",
    "\n",
    "    for i in col:\n",
    "        if df[0]['p value'][i] < 0.05:\n",
    "            feature_sign.append(i)\n",
    "\n",
    "\n",
    "    df = modelRidge_sum_model2\n",
    "\n",
    "    for i in col:\n",
    "        if df[0]['p value'][i] < 0.05 and i not in feature_sign:\n",
    "            feature_sign.append(i)\n",
    "\n",
    "\n",
    "    beta_dict = {}\n",
    "    for i in feature_sign:\n",
    "\n",
    "        beta_dict['CR_' + i] = []\n",
    "        beta_dict['KO_' + i] = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    y_database = X_1['Barthel']\n",
    "    X_database = X_1.drop('Barthel', axis=1)\n",
    "    \n",
    "    if(only_significance):\n",
    "        X_database = X_database[feature_sign]\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(0,100,10):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_database, y_database, train_size=0.75, test_size=.25, random_state=i)\n",
    "\n",
    "        opt_Ridge = BayesSearchCV(\n",
    "                Ridge(),\n",
    "                {\n",
    "                    'alpha': ( 0.0001, 0.01, 0.001),\n",
    "                    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "                    'max_iter': (1000, 10000, 100000, 1000000),\n",
    "                },\n",
    "                n_iter=10,\n",
    "                random_state=i, \n",
    "                scoring='r2',\n",
    "                cv=3\n",
    "            )\n",
    "\n",
    "        opt_Ridge.fit(X_train, y_train)\n",
    "\n",
    "        ## Ac uso el modelo Ridge con los parmetros entregadps por el optimizacion bayesiano porque el BayesSearch no me entrega los Beta values.\n",
    "\n",
    "        model = Ridge(alpha=opt_Ridge.best_params_['alpha'], solver = opt_Ridge.best_params_['solver'], \n",
    "                                 max_iter=opt_Ridge.best_params_['max_iter'])\n",
    "\n",
    "        model.fit(X_test, y_test)\n",
    "\n",
    "        # Esta parte la ahago as para ser consecuente con la forma que he ido guardando los resultados y que me sirvan las mismas funciones que ya tengo diseadas (en caso de necesitarlas)\n",
    "        coef_df = pd.DataFrame(\n",
    "            index=['_intercept'] + list(X_test.columns),\n",
    "            columns=['Estimate']\n",
    "            )\n",
    "\n",
    "        coef_df['Estimate'] = np.concatenate((np.round(np.array([model.intercept_]), 12), np.round((model.coef_), 12)))\n",
    "\n",
    "        #Ac guardo los beta values de las variables elegidas\n",
    "        for j in feature_sign:\n",
    "            beta_dict['CR_' + j].append(np.abs(coef_df['Estimate'][j])) \n",
    "\n",
    "\n",
    "    y_database = X_2['Barthel']\n",
    "    X_database = X_2.drop('Barthel', axis=1)\n",
    "    if(only_significance):\n",
    "        X_database = X_database[feature_sign]\n",
    "\n",
    "    for i in range(0,100,10):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_database, y_database, train_size=0.75, test_size=.25, random_state=i)\n",
    "\n",
    "        opt_Ridge = BayesSearchCV(\n",
    "                Ridge(),\n",
    "                {\n",
    "                    'alpha': ( 0.0001, 0.01, 0.001),\n",
    "                    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "                    'max_iter': (1000, 10000, 100000, 1000000),\n",
    "                },\n",
    "                n_iter=10,\n",
    "                random_state=i, \n",
    "                scoring='r2',\n",
    "                cv=3\n",
    "            )\n",
    "\n",
    "        opt_Ridge.fit(X_train, y_train)\n",
    "\n",
    "        ## Ac uso el modelo Ridge con los parmetros entregadps por el optimizacion bayesiano porque el BayesSearch no me entrega los Beta values.\n",
    "        model = Ridge(alpha=opt_Ridge.best_params_['alpha'], solver = opt_Ridge.best_params_['solver'], \n",
    "                                 max_iter=opt_Ridge.best_params_['max_iter'])\n",
    "\n",
    "        model.fit(X_test, y_test)\n",
    "\n",
    "        # Esta parte la ahago as para ser consecuente con la forma que he ido guardando los resultados y que me sirvan las mismas funciones que ya tengo diseadas (en caso de necesitarlas)\n",
    "        coef_df = pd.DataFrame(\n",
    "            index=['_intercept'] + list(X_test.columns),\n",
    "            columns=['Estimate']\n",
    "            )\n",
    "\n",
    "        coef_df['Estimate'] = np.concatenate((np.round(np.array([model.intercept_]), 12), np.round((model.coef_), 12)))\n",
    "\n",
    "        #Ac guardo los beta values de las variables elegidas\n",
    "        for j in feature_sign:\n",
    "            beta_dict['KO_'+ j].append(np.abs(coef_df['Estimate'][j]))\n",
    "\n",
    "    beta_df = pd.DataFrame(beta_dict)\n",
    "\n",
    "\n",
    "    from scipy import stats\n",
    "    import statsmodels.api\n",
    "\n",
    "    result_scipy_df = pd.DataFrame(\n",
    "            index=['p value'] ,\n",
    "            columns=feature_sign\n",
    "            )\n",
    "\n",
    "    result_stats_df = pd.DataFrame(\n",
    "            index=['p value'] ,\n",
    "            columns=feature_sign\n",
    "            )\n",
    "\n",
    "    for i in feature_sign:\n",
    "        result_scipy_df[i] = stats.ttest_ind(beta_dict['CR_'+ i], beta_dict['KO_' + i], equal_var=False)[1]\n",
    "        result_stats_df[i] = statsmodels.stats.weightstats.ttest_ind(beta_dict['CR_'+ i], beta_dict['KO_' + i], alternative=\"two-sided\",usevar=\"unequal\")[1]\n",
    "\n",
    "\n",
    "    beta_df_stat = beta_df.describe().round(3).iloc[1:3,:]\n",
    "    beta_df_stat = beta_df_stat.append(beta_df_stat.iloc[1,:]*1.95,ignore_index=True)\n",
    "    beta_df_stat = beta_df_stat.append(beta_df_stat.iloc[1,:]*2.58,ignore_index=True)\n",
    "\n",
    "    beta_df_stat = beta_df_stat.rename(index={0:'mean', 1:'std', 2:'95', 3:'99'})\n",
    "    beta_df_stat.round(3)\n",
    "\n",
    "\n",
    "    general_result_df = pd.DataFrame(\n",
    "            index=feature_sign,\n",
    "            columns=['CR_mean', 'CR_std','KO_mean','KO_std', 'ttest']\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "    count = 0\n",
    "    for i in feature_sign_order:\n",
    "        general_result_df.iloc[count, 0] = np.round(beta_df_stat['CR_' + i][0],2)\n",
    "        general_result_df.iloc[count, 1] = np.round(beta_df_stat['CR_' + i][1],2)\n",
    "\n",
    "        general_result_df.iloc[count, 2] = np.round(beta_df_stat['KO_' + i][0],2)\n",
    "        general_result_df.iloc[count, 3] = np.round(beta_df_stat['KO_' + i][1],2)\n",
    "\n",
    "        general_result_df.iloc[count, 4] = np.round(result_stats_df[i][0],2)\n",
    "\n",
    "        count +=1\n",
    "\n",
    "    return general_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-54-67189c0d5888>:139: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  beta_df_stat = beta_df_stat.append(beta_df_stat.iloc[1,:]*1.95,ignore_index=True)\n",
      "<ipython-input-54-67189c0d5888>:140: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  beta_df_stat = beta_df_stat.append(beta_df_stat.iloc[1,:]*2.58,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "Coef_t_test = beta_values_ttest(modelRidge_sum_costarica_2, modelRidge_sum_korea_2006_2016, X_costarica_w2, X_korea_2006_2016_common_ids, True)#.to_excel('Results/longitudinal/Barthel_beta_ttest_all_feat.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CR_mean</th>\n",
       "      <th>CR_std</th>\n",
       "      <th>KO_mean</th>\n",
       "      <th>KO_std</th>\n",
       "      <th>ttest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heart Disease</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mental Problems</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertension</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetes</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physical activity</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol consumption</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    CR_mean CR_std KO_mean KO_std ttest\n",
       "Heart Disease          0.29   0.09    0.04   0.03   0.0\n",
       "Mental Problems        0.02   0.01    0.06    0.0   0.0\n",
       "Hypertension           0.35   0.13    0.11   0.08   0.0\n",
       "Diabetes                0.2   0.08    0.04   0.03   0.0\n",
       "Physical activity      0.46   0.37    0.28   0.17  0.17\n",
       "Education              0.43   0.13    0.16   0.05   0.0\n",
       "Alcohol consumption    0.45   0.18    0.14   0.12   0.0\n",
       "Age                    0.86    0.2    0.19   0.16   0.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Coef_t_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F-statisitcs, F-pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Korea 2006</th>\n",
       "      <td>[12.58368281184064, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Korea 2006-2014</th>\n",
       "      <td>[42.34994818685124, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Korea 2006-2016</th>\n",
       "      <td>[55.7013111509596, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Costa Rica wave 1</th>\n",
       "      <td>[21.47722565840466, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Costa Rica wave 2</th>\n",
       "      <td>[19.7032264920963, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     F-statisitcs, F-pvalue\n",
       "Korea 2006         [12.58368281184064, 0.0]\n",
       "Korea 2006-2014    [42.34994818685124, 0.0]\n",
       "Korea 2006-2016     [55.7013111509596, 0.0]\n",
       "Costa Rica wave 1  [21.47722565840466, 0.0]\n",
       "Costa Rica wave 2   [19.7032264920963, 0.0]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f_stat(clf, X, y):\n",
    "    \"\"\"Calculate summary F-statistic for beta coefficients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The F-statistic value.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    r_squared = metrics.r2_score(y, clf.predict(X))\n",
    "    return (r_squared / p) / ((1 - r_squared) / (n - p - 1))\n",
    "\n",
    "\n",
    "def f_stat_pvalue(clf, X, y):\n",
    "    \"\"\"Calculate summary F-statistic p value for beta coefficients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The F-statistic p value.\n",
    "    \"\"\"\n",
    "    n = X.shape[0] # Esto se extrae par los grados de libertad del numeador y el denomindor (no. predictores, no. sujetos - no. predictores-1)\n",
    "    p = X.shape[1]\n",
    "    r_squared = metrics.r2_score(y, clf.predict(X))\n",
    "    \n",
    "    return np.round(scipy.stats.f.sf(f_stat(clf, X, y), n, (n - p - 1)), 15)\n",
    "\n",
    "def compute_f_statistics(clf, X, y):\n",
    "    return [f_stat(clf, X, y), f_stat_pvalue(clf, X, y)]\n",
    "\n",
    "F_statistics = {}\n",
    "\n",
    "F_statistics['Korea 2006'] = [compute_f_statistics(modelRidge_korea_2006, X_korea_2006, y_korea_2006)]\n",
    "F_statistics['Korea 2006-2014'] = [compute_f_statistics(modelRidge_korea_2006_2014, X_korea_2006_2014, y_korea_2006_2014)]\n",
    "F_statistics['Korea 2006-2016'] = [compute_f_statistics(modelRidge_korea_2006_2016, X_korea_2006_2016, y_korea_2006_2016)]\n",
    "\n",
    "\n",
    "F_statistics['Costa Rica wave 1'] = [compute_f_statistics(modelRidge_costarica_1, X_costarica_1, y_costarica_1)]\n",
    "F_statistics['Costa Rica wave 2'] = [compute_f_statistics(modelRidge_costarica_2, X_costarica_2, y_costarica_2)]\n",
    "\n",
    "\n",
    "F_statistics_pd = pd.DataFrame(F_statistics, index = ['F-statisitcs, F-pvalue']).T\n",
    "#F_statistics_pd.to_excel('Results/longitudinal/Barthel_F_statitics.xlsx')\n",
    "F_statistics_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korea 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "      <th>t value</th>\n",
       "      <th>p value</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_intercept</th>\n",
       "      <td>9.534465</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.999913</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.00533</td>\n",
       "      <td>35.01018</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.036085</td>\n",
       "      <td>2.2091</td>\n",
       "      <td>0.027207</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetes</th>\n",
       "      <td>0.003656</td>\n",
       "      <td>0.1785</td>\n",
       "      <td>0.858303</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.009834</td>\n",
       "      <td>0.9616</td>\n",
       "      <td>0.336276</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Live Alone</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertension</th>\n",
       "      <td>0.028923</td>\n",
       "      <td>1.9927</td>\n",
       "      <td>0.046344</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heart Disease</th>\n",
       "      <td>0.016554</td>\n",
       "      <td>0.5459</td>\n",
       "      <td>0.585188</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol consumption</th>\n",
       "      <td>0.027898</td>\n",
       "      <td>3.1482</td>\n",
       "      <td>0.001651</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physical activity</th>\n",
       "      <td>-0.041309</td>\n",
       "      <td>3.223</td>\n",
       "      <td>0.001276</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoking status</th>\n",
       "      <td>0.023979</td>\n",
       "      <td>1.3524</td>\n",
       "      <td>0.176305</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Falls</th>\n",
       "      <td>0.055645</td>\n",
       "      <td>1.7286</td>\n",
       "      <td>0.083939</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mental Problems</th>\n",
       "      <td>0.219262</td>\n",
       "      <td>5.0828</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.025964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adjusted R-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.026656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Estimate   t value   p value     value\n",
       "_intercept           9.534465    0.0001  0.999913          \n",
       "Age                  -0.00533  35.01018       0.0          \n",
       "Sex                  0.036085    2.2091  0.027207          \n",
       "Diabetes             0.003656    0.1785  0.858303          \n",
       "Education            0.009834    0.9616  0.336276          \n",
       "Live Alone               -0.0       0.0       1.0          \n",
       "Hypertension         0.028923    1.9927  0.046344          \n",
       "Heart Disease        0.016554    0.5459  0.585188          \n",
       "Alcohol consumption  0.027898    3.1482  0.001651          \n",
       "Physical activity   -0.041309     3.223  0.001276          \n",
       "Smoking status       0.023979    1.3524  0.176305          \n",
       "Falls                0.055645    1.7286  0.083939          \n",
       "Mental Problems      0.219262    5.0828       0.0          \n",
       "R-squared                                          0.025964\n",
       "Adjusted R-squared                                   0.0239\n",
       "F-squared                                          0.026656"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRidge_sum_korea_2006[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F-statisitcs, F-pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Korea 2006</th>\n",
       "      <td>[12.58368281184064, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              F-statisitcs, F-pvalue\n",
       "Korea 2006  [12.58368281184064, 0.0]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_statistics_pd.iloc[0:1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korea 2006 - 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "      <th>t value</th>\n",
       "      <th>p value</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_intercept</th>\n",
       "      <td>11.248607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999964</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.037981</td>\n",
       "      <td>76.7921</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.034604</td>\n",
       "      <td>0.7457</td>\n",
       "      <td>0.455888</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetes</th>\n",
       "      <td>0.044966</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.439546</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.075032</td>\n",
       "      <td>2.5828</td>\n",
       "      <td>0.009825</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Live Alone</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertension</th>\n",
       "      <td>0.065067</td>\n",
       "      <td>1.578</td>\n",
       "      <td>0.114626</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heart Disease</th>\n",
       "      <td>0.007584</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.929856</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol consumption</th>\n",
       "      <td>0.03618</td>\n",
       "      <td>1.4371</td>\n",
       "      <td>0.150731</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physical activity</th>\n",
       "      <td>-0.082492</td>\n",
       "      <td>2.2655</td>\n",
       "      <td>0.02352</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoking status</th>\n",
       "      <td>0.114134</td>\n",
       "      <td>2.2658</td>\n",
       "      <td>0.0235</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Falls</th>\n",
       "      <td>0.037987</td>\n",
       "      <td>0.4154</td>\n",
       "      <td>0.677885</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mental Problems</th>\n",
       "      <td>0.029836</td>\n",
       "      <td>0.2435</td>\n",
       "      <td>0.807656</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.082323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adjusted R-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.08038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.089709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Estimate  t value   p value     value\n",
       "_intercept           11.248607      0.0  0.999964          \n",
       "Age                  -0.037981  76.7921       0.0          \n",
       "Sex                   0.034604   0.7457  0.455888          \n",
       "Diabetes              0.044966    0.773  0.439546          \n",
       "Education             0.075032   2.5828  0.009825          \n",
       "Live Alone                -0.0      0.0       1.0          \n",
       "Hypertension          0.065067    1.578  0.114626          \n",
       "Heart Disease         0.007584    0.088  0.929856          \n",
       "Alcohol consumption    0.03618   1.4371  0.150731          \n",
       "Physical activity    -0.082492   2.2655   0.02352          \n",
       "Smoking status        0.114134   2.2658    0.0235          \n",
       "Falls                 0.037987   0.4154  0.677885          \n",
       "Mental Problems       0.029836   0.2435  0.807656          \n",
       "R-squared                                          0.082323\n",
       "Adjusted R-squared                                  0.08038\n",
       "F-squared                                          0.089709"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRidge_sum_korea_2006_2014[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F-statisitcs, F-pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Korea 2006-2014</th>\n",
       "      <td>[42.34994818685124, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   F-statisitcs, F-pvalue\n",
       "Korea 2006-2014  [42.34994818685124, 0.0]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_statistics_pd.iloc[1:2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korea 2006 - 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "      <th>t value</th>\n",
       "      <th>p value</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_intercept</th>\n",
       "      <td>12.04446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999968</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.054669</td>\n",
       "      <td>87.4261</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>-0.00651</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.908748</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetes</th>\n",
       "      <td>0.088466</td>\n",
       "      <td>1.2427</td>\n",
       "      <td>0.214044</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.042057</td>\n",
       "      <td>1.1829</td>\n",
       "      <td>0.236893</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Live Alone</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertension</th>\n",
       "      <td>0.154557</td>\n",
       "      <td>3.0627</td>\n",
       "      <td>0.002204</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heart Disease</th>\n",
       "      <td>0.044303</td>\n",
       "      <td>0.4202</td>\n",
       "      <td>0.674379</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol consumption</th>\n",
       "      <td>0.02643</td>\n",
       "      <td>0.8578</td>\n",
       "      <td>0.391024</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physical activity</th>\n",
       "      <td>-0.124306</td>\n",
       "      <td>2.7894</td>\n",
       "      <td>0.005297</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoking status</th>\n",
       "      <td>0.119072</td>\n",
       "      <td>1.9315</td>\n",
       "      <td>0.053472</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Falls</th>\n",
       "      <td>-0.008625</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.938576</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mental Problems</th>\n",
       "      <td>0.044643</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.76598</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.105538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adjusted R-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.103643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.11799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Estimate  t value   p value     value\n",
       "_intercept           12.04446      0.0  0.999968          \n",
       "Age                 -0.054669  87.4261       0.0          \n",
       "Sex                  -0.00651   0.1146  0.908748          \n",
       "Diabetes             0.088466   1.2427  0.214044          \n",
       "Education            0.042057   1.1829  0.236893          \n",
       "Live Alone               -0.0      0.0       1.0          \n",
       "Hypertension         0.154557   3.0627  0.002204          \n",
       "Heart Disease        0.044303   0.4202  0.674379          \n",
       "Alcohol consumption   0.02643   0.8578  0.391024          \n",
       "Physical activity   -0.124306   2.7894  0.005297          \n",
       "Smoking status       0.119072   1.9315  0.053472          \n",
       "Falls               -0.008625   0.0771  0.938576          \n",
       "Mental Problems      0.044643   0.2977   0.76598          \n",
       "R-squared                                         0.105538\n",
       "Adjusted R-squared                                0.103643\n",
       "F-squared                                          0.11799"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRidge_sum_korea_2006_2016[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F-statisitcs, F-pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Korea 2006-2016</th>\n",
       "      <td>[55.7013111509596, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  F-statisitcs, F-pvalue\n",
       "Korea 2006-2016  [55.7013111509596, 0.0]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_statistics_pd.iloc[2:3,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costa Rica wave 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "      <th>t value</th>\n",
       "      <th>p value</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_intercept</th>\n",
       "      <td>5.308324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999997</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.001196</td>\n",
       "      <td>1.555423</td>\n",
       "      <td>0.120048</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.130127</td>\n",
       "      <td>2.2782</td>\n",
       "      <td>0.022853</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetes</th>\n",
       "      <td>0.307382</td>\n",
       "      <td>4.6033</td>\n",
       "      <td>0.000005</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.164582</td>\n",
       "      <td>4.891</td>\n",
       "      <td>0.000001</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Live Alone</th>\n",
       "      <td>0.065669</td>\n",
       "      <td>0.6904</td>\n",
       "      <td>0.49004</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertension</th>\n",
       "      <td>0.302587</td>\n",
       "      <td>5.9709</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heart Disease</th>\n",
       "      <td>0.506584</td>\n",
       "      <td>3.4308</td>\n",
       "      <td>0.000618</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol consumption</th>\n",
       "      <td>0.061057</td>\n",
       "      <td>1.3897</td>\n",
       "      <td>0.164827</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physical activity</th>\n",
       "      <td>-0.183215</td>\n",
       "      <td>3.3005</td>\n",
       "      <td>0.000988</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoking status</th>\n",
       "      <td>-0.01036</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.849696</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Falls</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mental Problems</th>\n",
       "      <td>0.495609</td>\n",
       "      <td>7.9433</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.147548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adjusted R-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.140678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.173087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Estimate   t value   p value     value\n",
       "_intercept           5.308324       0.0  0.999997          \n",
       "Age                 -0.001196  1.555423  0.120048          \n",
       "Sex                  0.130127    2.2782  0.022853          \n",
       "Diabetes             0.307382    4.6033  0.000005          \n",
       "Education            0.164582     4.891  0.000001          \n",
       "Live Alone           0.065669    0.6904   0.49004          \n",
       "Hypertension         0.302587    5.9709       0.0          \n",
       "Heart Disease        0.506584    3.4308  0.000618          \n",
       "Alcohol consumption  0.061057    1.3897  0.164827          \n",
       "Physical activity   -0.183215    3.3005  0.000988          \n",
       "Smoking status       -0.01036    0.1895  0.849696          \n",
       "Falls                     0.0       0.0       1.0          \n",
       "Mental Problems      0.495609    7.9433       0.0          \n",
       "R-squared                                          0.147548\n",
       "Adjusted R-squared                                 0.140678\n",
       "F-squared                                          0.173087"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRidge_sum_costarica_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F-statisitcs, F-pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Costa Rica wave 1</th>\n",
       "      <td>[21.47722565840466, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     F-statisitcs, F-pvalue\n",
       "Costa Rica wave 1  [21.47722565840466, 0.0]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_statistics_pd.iloc[3:4,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costa Rica wave 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "      <th>t value</th>\n",
       "      <th>p value</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_intercept</th>\n",
       "      <td>4.206485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.010381</td>\n",
       "      <td>2.5202</td>\n",
       "      <td>0.011833</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.146255</td>\n",
       "      <td>1.6914</td>\n",
       "      <td>0.090959</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetes</th>\n",
       "      <td>0.352379</td>\n",
       "      <td>3.4858</td>\n",
       "      <td>0.000505</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.269736</td>\n",
       "      <td>5.295</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Live Alone</th>\n",
       "      <td>-0.011506</td>\n",
       "      <td>0.0799</td>\n",
       "      <td>0.936317</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertension</th>\n",
       "      <td>0.421226</td>\n",
       "      <td>5.4904</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heart Disease</th>\n",
       "      <td>0.799747</td>\n",
       "      <td>3.5775</td>\n",
       "      <td>0.000358</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol consumption</th>\n",
       "      <td>0.145927</td>\n",
       "      <td>2.194</td>\n",
       "      <td>0.028389</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physical activity</th>\n",
       "      <td>-0.308504</td>\n",
       "      <td>3.671</td>\n",
       "      <td>0.00025</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoking status</th>\n",
       "      <td>-0.031276</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.705514</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Falls</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mental Problems</th>\n",
       "      <td>0.692651</td>\n",
       "      <td>7.3329</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.137031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adjusted R-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.130076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.15879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Estimate t value   p value     value\n",
       "_intercept           4.206485     0.0  0.999999          \n",
       "Age                 -0.010381  2.5202  0.011833          \n",
       "Sex                  0.146255  1.6914  0.090959          \n",
       "Diabetes             0.352379  3.4858  0.000505          \n",
       "Education            0.269736   5.295       0.0          \n",
       "Live Alone          -0.011506  0.0799  0.936317          \n",
       "Hypertension         0.421226  5.4904       0.0          \n",
       "Heart Disease        0.799747  3.5775  0.000358          \n",
       "Alcohol consumption  0.145927   2.194  0.028389          \n",
       "Physical activity   -0.308504   3.671   0.00025          \n",
       "Smoking status      -0.031276   0.378  0.705514          \n",
       "Falls                     0.0     0.0       1.0          \n",
       "Mental Problems      0.692651  7.3329       0.0          \n",
       "R-squared                                        0.137031\n",
       "Adjusted R-squared                               0.130076\n",
       "F-squared                                         0.15879"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRidge_sum_costarica_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F-statisitcs, F-pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Costa Rica wave 2</th>\n",
       "      <td>[19.7032264920963, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    F-statisitcs, F-pvalue\n",
       "Costa Rica wave 2  [19.7032264920963, 0.0]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_statistics_pd.iloc[4:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>solver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>korea_2006</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>sag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korea_2006_2014</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100000</td>\n",
       "      <td>lsqr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korea_2006_2016</th>\n",
       "      <td>0.01</td>\n",
       "      <td>10000</td>\n",
       "      <td>lsqr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>costarica_wave_1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>lsqr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>costarica_wave_2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1000000</td>\n",
       "      <td>sparse_cg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 alpha max_iter     solver\n",
       "korea_2006         1.0     1000        sag\n",
       "korea_2006_2014    0.1   100000       lsqr\n",
       "korea_2006_2016   0.01    10000       lsqr\n",
       "costarica_wave_1   1.0     1000       lsqr\n",
       "costarica_wave_2   1.0  1000000  sparse_cg"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_pd = pd.DataFrame(parameter_dict).T\n",
    "parameter_pd#.to_excel('Results/longitudinal/Barthel_hyperparameters.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99% confidence interval (+- 0.0211 )\n",
      "99% confidence interval (+- 0.0228 )\n",
      "99% confidence interval (+- 0.0221 )\n",
      "99% confidence interval (+- 0.0568 )\n",
      "99% confidence interval (+- 0.071 )\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conf interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>korea_2006</th>\n",
       "      <td>0.0211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korea_2006_2014</th>\n",
       "      <td>0.0228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korea_2006_2016</th>\n",
       "      <td>0.0221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>costarica_wave_1</th>\n",
       "      <td>0.0568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>costarica_wave_w2</th>\n",
       "      <td>0.0710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   conf interval\n",
       "korea_2006                0.0211\n",
       "korea_2006_2014           0.0228\n",
       "korea_2006_2016           0.0221\n",
       "costarica_wave_1          0.0568\n",
       "costarica_wave_w2         0.0710"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_interval_dict = {}\n",
    "\n",
    "conf_interval_dict['korea_2006'] = [conf_interval(X_korea_2006_common_ids)]\n",
    "conf_interval_dict['korea_2006_2014'] = [conf_interval(X_korea_2006_2014_common_ids)]\n",
    "conf_interval_dict['korea_2006_2016'] = [conf_interval(X_korea_2006_2016_common_ids)]\n",
    "\n",
    "\n",
    "conf_interval_dict['costarica_wave_1'] = [conf_interval(X_costarica_w1)]\n",
    "conf_interval_dict['costarica_wave_w2'] = [conf_interval(X_costarica_w2)]\n",
    "\n",
    "\n",
    "conf_interval_pd = pd.DataFrame(conf_interval_dict, index = ['conf interval']).T\n",
    "conf_interval_pd#.to_excel('Results/longitudinal/Barthel_conf_interval.xlsx')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
