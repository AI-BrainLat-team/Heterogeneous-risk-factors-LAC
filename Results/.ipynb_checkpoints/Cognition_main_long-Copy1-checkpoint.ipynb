{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelo/anaconda3/envs/HBL/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "import matplotlib.font_manager\n",
    "from matplotlib import style\n",
    "style.use('seaborn') or plt.style.use('seaborn')\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, f1_score, accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "import operator\n",
    "\n",
    "\n",
    "from xgboost import plot_importance\n",
    "\n",
    "\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import PatchCollection\n",
    "import scipy.stats as ss\n",
    "\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import Lasso, MultiTaskLasso, Ridge, ElasticNet\n",
    "import math\n",
    "\n",
    "#from regressors import stats\n",
    "\n",
    "\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import PatchCollection\n",
    "import scipy.stats as ss\n",
    "\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "\n",
    "import scipy\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "import colorsys\n",
    "import matplotlib.colors as cconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_bib as mb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color(var, X_cat_, color_dict_):\n",
    "\n",
    "    X_factors = list(X_cat_.factors)\n",
    "    X_name = list(X_cat_.newname)\n",
    "\n",
    "    index_code = X_name.index(var)\n",
    "    cat = X_factors[index_code]\n",
    "\n",
    "    return color_dict_[cat]\n",
    "\n",
    "color_dict = {}\n",
    "color_dict['Country'] = [40/255, 43/255, 95/255]\n",
    "color_dict['HF'] = '#A31300'\n",
    "color_dict['LSF'] = '#FF9E0D'\n",
    "color_dict['PSF'] = '#FF4800'\n",
    "color_dict['SDHF'] = '#1C4F9E'\n",
    "color_dict['DF'] = '#009E32'\n",
    "\n",
    "def get_bar_colors(data_, X_cat_):\n",
    "    color_dict = {}\n",
    "    color_dict['Country'] = [40/255, 43/255, 95/255]\n",
    "    color_dict['HF'] = '#A31300'\n",
    "    color_dict['LSF'] = '#FF9E0D'\n",
    "    color_dict['PSF'] = '#FF4800'\n",
    "    color_dict['SDHF'] = '#1C4F9E'\n",
    "    color_dict['DF'] = '#009E32'\n",
    "    \n",
    "    #color_dict = {}\n",
    "    #color_dict = {'DF':'#5975a4', 'MF':'#cc8963', 'SF':'#5f9e6e', 'SLF':'#b55d60',\n",
    "    #              'n':'#857aab', 'country':'#8d7866'}#, '#d095bf'}\n",
    "\n",
    "    X_factors = list(X_cat_.factors)\n",
    "    X_name = list(X_cat_.newname)\n",
    "\n",
    "    bar_color_total = []\n",
    "    for i in list(data_.Features):\n",
    "        if(i == 'Country'):\n",
    "            bar_color_total.append(color_dict['Country'])\n",
    "            continue\n",
    "        index_code = X_name.index(i)\n",
    "        cat = X_factors[index_code]\n",
    "        bar_color_total.append(color_dict[cat])\n",
    "    return bar_color_total\n",
    "\n",
    "\n",
    "def plot_estimate_value(regression_model, X_cat_ = [], title = '',  xlim =[0, 2] ,fig_size = (8,12), size = 14, pvalue_type = 'False'):\n",
    "\n",
    "    df = regression_model[0]\n",
    "    df.index.name = 'Features'\n",
    "    df = df.iloc[1:-3, 0:-1]\n",
    "\n",
    "    for i in range(3):\n",
    "            #print(i, X_RAW_edu_level[X_RAW_edu_level.columns[i]].dtype)\n",
    "        df[df.columns[i]] = np.abs(pd.to_numeric(df[df.columns[i]],errors = 'coerce'))\n",
    "\n",
    "    df = df.reset_index()\n",
    "    data = df.sort_values('Estimate', ascending=False)\n",
    "\n",
    "    \n",
    "    if(len(X_cat_)>0):\n",
    "        \n",
    "        bar_color = get_bar_colors(data, X_cat_)\n",
    "        \n",
    "        plt.title(title)\n",
    "        sns.barplot(x=\"Estimate\", y=\"Features\", data = data, palette =bar_color)\n",
    "        plt.xlim(xlim)\n",
    "    else:\n",
    "        plt.title(title)\n",
    "        sns.barplot(x=\"Estimate\", y=\"Features\", data = data, color = 'darkblue')\n",
    "        plt.xlim(xlim)\n",
    "\n",
    "\n",
    "    y_step=0  \n",
    "    for i in range(df.shape[0]):\n",
    "        if(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],3)<=0.01):\n",
    "            color = 'green'\n",
    "        elif(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],3)<=0.05):\n",
    "            color = 'gray'\n",
    "        else:\n",
    "            color = 'red'        \n",
    "        \n",
    "        if(pvalue_type == 'color'):\n",
    "                plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]-0.005, y_step, \n",
    "                                 '' + str(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],2)),\n",
    "                                 size= size, rotation=0.,\n",
    "                                 ha=\"left\", va=\"center\", color = 'white',\n",
    "                                 bbox=dict(boxstyle=\"round\",\n",
    "                                           ec=color,\n",
    "                                            fc=color,\n",
    "                                           )\n",
    "                                 )\n",
    "                y_step+=1\n",
    "\n",
    "        elif(pvalue_type == 'value'):\n",
    "                plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                 '(' + str(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],8))+')',\n",
    "                                 size= size, rotation=0.,\n",
    "                                 ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                 )\n",
    "                y_step+=1\n",
    "        else:\n",
    "            if(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step]<0.01):\n",
    "                \n",
    "                    plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                     '**',\n",
    "                                     size= size, rotation=0.,\n",
    "                                     ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                     )\n",
    "            elif(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step]>= 0.01 and df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step]<0.05):\n",
    "                  \n",
    "                    plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                     '*',\n",
    "                                     size= size, rotation=0.,\n",
    "                                     ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                     )  \n",
    "            else:\n",
    "                    plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]+0.005, y_step, \n",
    "                                     '',\n",
    "                                     size= size, rotation=0.,\n",
    "                                     ha=\"left\", va=\"center\", color = 'black',\n",
    "\n",
    "                                     )      \n",
    "            y_step+=1\n",
    "            \n",
    "         \n",
    "    text_diff =xlim[1]/2.2\n",
    "    plt.text(xlim[1] - text_diff, df.shape[0]-1.5,r'$ R^2 $(' + str(np.round(regression_model[1],2)) + ') \\t$F^2 $(' + str(np.round(regression_model[3],2)) + ')',\n",
    "                             size= 12, rotation=0.,\n",
    "                             ha=\"left\", va=\"center\", color = 'black',\n",
    "                             bbox=dict(boxstyle=\"round\",\n",
    "                                       ec='gray',\n",
    "                                        fc='gray',\n",
    "                                       )\n",
    "                             )\n",
    "\n",
    "\n",
    "    plt.locator_params(axis='x', nbins=4)\n",
    "\n",
    "\n",
    "def plot_estimate_value_no_sort(regression_model, title = '',  xlim =[0, 2] ,fig_size = (8,12), size = 14, ylabel = True, ylabelR = False ):\n",
    "\n",
    "    df = regression_model\n",
    "    df.index.name = 'Features'\n",
    "    df = df.iloc[1:-3, 0:-1]\n",
    "\n",
    "    for i in range(3):\n",
    "            #print(i, X_RAW_edu_level[X_RAW_edu_level.columns[i]].dtype)\n",
    "        df[df.columns[i]] = np.abs(pd.to_numeric(df[df.columns[i]],errors = 'coerce'))\n",
    "\n",
    "    df = df.reset_index()\n",
    "\n",
    "    #plt.figure(figsize=(8,12))\n",
    "    plt.title(title)\n",
    "    sns.barplot(x=\"Estimate\", y=\"Features\", data = df, color = 'Brown')\n",
    "    if(ylabel == False):\n",
    "        plt.ylabel('')\n",
    "        plt.yticks([])\n",
    "    plt.xlim(xlim)\n",
    "    \n",
    "    if(ylabelR):\n",
    "        plt.tick_params (axis = 'y', which = 'both', labelleft = False, labelright = True)\n",
    "\n",
    "    y_step=0  \n",
    "    for i in range(df.shape[0]):\n",
    "        if(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],3)<=0.01):\n",
    "            color = 'green'\n",
    "        elif(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],3)<=0.05):\n",
    "            color = 'gray'\n",
    "        else:\n",
    "            color = 'red'        \n",
    "        \n",
    "        plt.text(df.sort_values('Estimate', ascending=False)['Estimate'].iloc[y_step]-0.005, y_step, \n",
    "                         '' + str(np.round(df.sort_values('Estimate', ascending=False)['p value'].iloc[y_step],3)),\n",
    "                         size= size, rotation=0.,\n",
    "                         ha=\"left\", va=\"center\", color = 'white',\n",
    "                         bbox=dict(boxstyle=\"round\",\n",
    "                                   ec=color,\n",
    "                                    fc=color,\n",
    "                                   )\n",
    "                         )\n",
    "        y_step+=1\n",
    "        \n",
    "\n",
    "def conf_interval(database):\n",
    "    r_squared_list = []\n",
    "\n",
    "    y_database = database['MMSE']\n",
    "    X_database = database.drop('MMSE', axis=1)\n",
    "\n",
    "    for i in range(0,100,10):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_database, y_database, train_size=0.75, test_size=.25, random_state=i)\n",
    "\n",
    "        opt_Ridge = BayesSearchCV(\n",
    "            Ridge(),\n",
    "            {\n",
    "                'alpha': ( 0.0001, 0.01, 0.001),\n",
    "                'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "                'max_iter': (1000, 10000, 100000, 1000000),\n",
    "            },\n",
    "            n_iter=10,\n",
    "            random_state=i, \n",
    "            scoring='r2',\n",
    "            cv=3\n",
    "        )\n",
    "\n",
    "        opt_Ridge.fit(X_train, y_train)\n",
    "\n",
    "        r_squared_list.append(opt_Ridge.score(X_test, y_test))\n",
    "\n",
    "\n",
    "    print(r'99% confidence interval (+-', np.round(np.std(r_squared_list)*2.58, 4),')')\n",
    "    return np.round(np.std(r_squared_list)*2.58, 4)\n",
    "\n",
    "        \n",
    "def adj_r2_score_and_r2_score(clf, X, y):\n",
    "    n = X.shape[0]  # Number of observations\n",
    "    p = X.shape[1]  # Number of features\n",
    "    r_squared = r2_score(y, clf.predict(X))\n",
    "    return [1 - (1 - r_squared) * ((n - 1) / (n - p - 1)), r_squared]\n",
    "\n",
    "\n",
    "def mse(clf, X, y):\n",
    "    return mean_squared_error(y, clf.predict(X))\n",
    "\n",
    "def rmse(clf, X, y):\n",
    "    mse = mean_squared_error(y, clf.predict(X))\n",
    "    return math.sqrt(mse)    \n",
    "\n",
    "def coef_se(clf, X, y):\n",
    "    n = X.shape[0]\n",
    "    X1 = np.hstack((np.ones((n, 1)), np.matrix(X)))\n",
    "    se_matrix = scipy.linalg.sqrtm(\n",
    "        metrics.mean_squared_error(y, clf.predict(X)) *\n",
    "        np.linalg.inv(X1.T * X1)\n",
    "    )\n",
    "    return np.diagonal(se_matrix)\n",
    "\n",
    "def coef_tval(clf, X, y):\n",
    "    a = np.array(clf.intercept_ / coef_se(clf, X, y)[0])\n",
    "    b = np.array(clf.coef_ / coef_se(clf, X, y)[1:])\n",
    "    return np.append(a, b)\n",
    "\n",
    "def coef_tval_XGB_tree(clf, X, y):\n",
    "    a = np.nan\n",
    "    b = np.array(clf.feature_importances_ / coef_se(clf, X, y)[1:])\n",
    "    return np.append(a, b)\n",
    "\n",
    "def coef_pval(clf, X, y):\n",
    "\n",
    "    n = X.shape[0]\n",
    "    t = coef_tval(clf, X, y)\n",
    "    p = 2 * (1 - scipy.stats.t.cdf(abs(t), n - 1))\n",
    "    return p\n",
    "\n",
    "def coef_pval_XGB_tree(clf, X, y):\n",
    "\n",
    "    n = X.shape[0]\n",
    "    t = coef_tval_XGB_tree(clf, X, y)\n",
    "    p = 2 * (1 - scipy.stats.t.cdf(abs(t), n - 1))\n",
    "    return p\n",
    "\n",
    "def residuals(clf, X, y, r_type='standardized'):\n",
    "\n",
    "    # Make sure value of parameter 'r_type' is one we recognize\n",
    "    assert r_type in ('raw', 'standardized', 'studentized'), (\n",
    "        \"Invalid option for 'r_type': {0}\".format(r_type))\n",
    "    y_true = y.view(dtype='float')\n",
    "    # Use classifier to make predictions\n",
    "    y_pred = clf.predict(X)\n",
    "    # Make sure dimensions agree (Numpy still allows subtraction if they don't)\n",
    "    assert y_true.shape == y_pred.shape, (\n",
    "        \"Dimensions of y_true {0} do not match y_pred {1}\".format(y_true.shape,\n",
    "                                                                  y_pred.shape))\n",
    "    # Get raw residuals, or standardized or standardized residuals\n",
    "    resids = y_pred - y_true\n",
    "    if r_type == 'standardized':\n",
    "        resids = resids / np.std(resids)\n",
    "    elif r_type == 'studentized':\n",
    "        # Prepare a blank array to hold studentized residuals\n",
    "        studentized_resids = np.zeros(y_true.shape[0], dtype='float')\n",
    "        # Calcluate hat matrix of X values so you can get leverage scores\n",
    "        hat_matrix = np.dot(\n",
    "            np.dot(X, np.linalg.inv(np.dot(np.transpose(X), X))),\n",
    "            np.transpose(X))\n",
    "        # For each point, calculate studentized residuals w/ leave-one-out MSE\n",
    "        for i in range(y_true.shape[0]):\n",
    "            # Make a mask so you can calculate leave-one-out MSE\n",
    "            mask = np.ones(y_true.shape[0], dtype='bool')\n",
    "            mask[i] = 0\n",
    "            loo_mse = np.average(resids[mask] ** 2, axis=0)  # Leave-one-out MSE\n",
    "            # Calculate studentized residuals\n",
    "            studentized_resids[i] = resids[i] / np.sqrt(\n",
    "                loo_mse * (1 - hat_matrix[i, i]))\n",
    "        resids = studentized_resids\n",
    "    return resids\n",
    "\n",
    "\n",
    "def f_squared(clf, X, y):\n",
    "\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    r_squared = metrics.r2_score(y, clf.predict(X))\n",
    "    return r_squared  / (1 - r_squared)\n",
    "\n",
    "\n",
    "\n",
    "def summary(clf, X, y, xlabels=None, regressor = ''):\n",
    "\n",
    "    print('Resumen del regresor ' + regressor + '\\n')\n",
    "    \n",
    "    ncols = X.shape[1]\n",
    "    if xlabels is None:\n",
    "        xlabels = np.array(\n",
    "            ['x{0}'.format(i) for i in range(1, ncols + 1)], dtype='str')\n",
    "    elif isinstance(xlabels, (tuple, list)):\n",
    "        xlabels = np.array(xlabels, dtype='str')\n",
    "\n",
    "    # Create data frame of coefficient estimates and associated stats\n",
    "    coef_df = pd.DataFrame(\n",
    "        index=['_intercept'] + list(xlabels),\n",
    "        columns=['Estimate','t value', 'p value']\n",
    "    )\n",
    "    \n",
    "    if(regressor == 'XGBRegressor'):\n",
    "        coef_df['Estimate'] = np.concatenate(\n",
    "            (np.round(np.array([clf.intercept_[0]]), 6), np.round((clf.coef_), 6)))\n",
    "        #coef_df['MSE'] = np.round(mse(clf, X, y), 6)\n",
    "        #coef_df['RMSE'] = np.round(rmse(clf, X, y), 6)\n",
    "        coef_df['t value'] = np.round(coef_tval(clf, X, y), 4)\n",
    "        coef_df['p value'] = np.round(coef_pval(clf, X, y), 20)\n",
    "        # Create data frame to summarize residuals\n",
    "        resids = residuals(clf, X, y, r_type='raw')\n",
    "        resids_df = pd.DataFrame({\n",
    "            'Min': pd.Series(np.round(resids.min(), 4)),\n",
    "            '1Q': pd.Series(np.round(np.percentile(resids, q=25), 4)),\n",
    "            'Median': pd.Series(np.round(np.median(resids), 4)),\n",
    "            '3Q': pd.Series(np.round(np.percentile(resids, q=75), 4)),\n",
    "            'Max': pd.Series(np.round(resids.max(), 4)),\n",
    "        }, columns=['Min', '1Q', 'Median', '3Q', 'Max'])\n",
    "        # Output results\n",
    "        print(\"Residuals:\")\n",
    "        print(resids_df.to_string(index=False))\n",
    "        print('\\n')\n",
    "        print('Coefficients:')\n",
    "        print(coef_df.to_string(index=True))\n",
    "        print('---')\n",
    "        r_sq = adj_r2_score_and_r2_score(clf, X, y)[1]\n",
    "        r_sq_adj = adj_r2_score_and_r2_score(clf, X, y)[0]\n",
    "        f_sq = f_squared(clf, X, y)\n",
    "        \n",
    "        print('R-squared:  {0:.5f},    Adjusted R-squared:  {1:.5f}'.format(\n",
    "           r_sq, r_sq_adj))\n",
    "        print('F-squared:  {0:.5f}'.format(\n",
    "            f_sq))\n",
    "    elif(regressor == 'XGBRegressorNoLinear'):\n",
    "        coef_df = pd.DataFrame(\n",
    "            index=['_intercept'] + list(xlabels),\n",
    "            columns=['Estimate','t value', 'p value']\n",
    "        )\n",
    "\n",
    "        coef_df['Estimate'] = np.concatenate(\n",
    "                (np.round(np.array([np.nan]), 6), np.round((clf.feature_importances_), 6)))\n",
    "\n",
    "        coef_df['t value'] = np.round(coef_tval_XGB_tree(clf, X, y), 4)\n",
    "        coef_df['p value'] = np.round(coef_pval_XGB_tree(clf, X, y), 20)\n",
    "            # Create data frame to summarize residuals\n",
    "        resids = residuals(clf, X, y, r_type='raw')\n",
    "        resids_df = pd.DataFrame({\n",
    "                'Min': pd.Series(np.round(resids.min(), 4)),\n",
    "                '1Q': pd.Series(np.round(np.percentile(resids, q=25), 4)),\n",
    "                'Median': pd.Series(np.round(np.median(resids), 4)),\n",
    "                '3Q': pd.Series(np.round(np.percentile(resids, q=75), 4)),\n",
    "                'Max': pd.Series(np.round(resids.max(), 4)),\n",
    "        }, columns=['Min', '1Q', 'Median', '3Q', 'Max'])\n",
    "            # Output results\n",
    "        print(\"Residuals:\")\n",
    "        print(resids_df.to_string(index=False))\n",
    "        print('\\n')\n",
    "        print('Coefficients:')\n",
    "        print(coef_df.to_string(index=True))\n",
    "        print('---')\n",
    "        r_sq = adj_r2_score_and_r2_score(clf, X, y)[1]\n",
    "        r_sq_adj = adj_r2_score_and_r2_score(clf, X, y)[0]\n",
    "        f_sq = f_squared(clf, X, y)\n",
    "\n",
    "        print('R-squared:  {0:.5f},    Adjusted R-squared:  {1:.5f}'.format(\n",
    "               r_sq, r_sq_adj))\n",
    "        print('F-squared:  {0:.5f}'.format(\n",
    "                f_sq))\n",
    "    else:\n",
    "        coef_df['Estimate'] = np.concatenate(\n",
    "            (np.round(np.array([clf.intercept_]), 6), np.round((clf.coef_), 6)))\n",
    "        #coef_df['MSE'] = np.round(mse(clf, X, y), 6)\n",
    "        #coef_df['RMSE'] = np.round(rmse(clf, X, y), 6)\n",
    "        coef_df['t value'] = abs(np.round(coef_tval(clf, X, y), 4))\n",
    "        coef_df['p value'] = np.round(coef_pval(clf, X, y), 20)\n",
    "        # Create data frame to summarize residuals\n",
    "        resids = residuals(clf, X, y, r_type='raw')\n",
    "        resids_df = pd.DataFrame({\n",
    "            'Min': pd.Series(np.round(resids.min(), 4)),\n",
    "            '1Q': pd.Series(np.round(np.percentile(resids, q=25), 4)),\n",
    "            'Median': pd.Series(np.round(np.median(resids), 4)),\n",
    "            '3Q': pd.Series(np.round(np.percentile(resids, q=75), 4)),\n",
    "            'Max': pd.Series(np.round(resids.max(), 4)),\n",
    "        }, columns=['Min', '1Q', 'Median', '3Q', 'Max'])\n",
    "        # Output results\n",
    "        print(\"Residuals:\")\n",
    "        print(resids_df.to_string(index=False))\n",
    "        print('\\n')\n",
    "        print('Coefficients:')\n",
    "        print(coef_df.to_string(index=True))\n",
    "        print('---')\n",
    "        \n",
    "        r_sq = adj_r2_score_and_r2_score(clf, X, y)[1]\n",
    "        r_sq_adj = adj_r2_score_and_r2_score(clf, X, y)[0]\n",
    "        f_sq = f_squared(clf, X, y)\n",
    "        \n",
    "        print('R-squared:  {0:.5f},    Adjusted R-squared:  {1:.5f}'.format(\n",
    "           r_sq, r_sq_adj))\n",
    "        print('F-squared:  {0:.5f}'.format(\n",
    "            f_sq))\n",
    "        \n",
    "        \n",
    "    print('---------------------------------------------------------------------------\\n\\n')\n",
    "    \n",
    "    \n",
    "    \n",
    "    empty_str = []\n",
    "    for i in range(coef_df.shape[0]):\n",
    "        empty_str.append('')\n",
    "    \n",
    "    coef_df['value'] = empty_str\n",
    "    \n",
    "    coef_df = coef_df.T\n",
    "    coef_df['R-squared'] = ['','','', r_sq]\n",
    "    coef_df['Adjusted R-squared'] = ['','','', r_sq_adj]\n",
    "    coef_df['F-squared'] = ['','','', f_sq]\n",
    "    return [coef_df.T, r_sq, r_sq_adj, f_sq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    sig = 1 / (1 + math.exp(-x))\n",
    "    return sig\n",
    "\n",
    "def get_order_var(model_):\n",
    "\n",
    "    df = model_[0]['Estimate'].iloc[1:-3]\n",
    "    df = np.abs(pd.to_numeric(df,errors = 'coerce'))\n",
    "    df = list(df.sort_values(ascending=False).index)\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_longitudinal(var, y_countrys_, models_, market_size_type = 'log',xlim = [0.25, 5.75], \n",
    "                      years = [2006, 2014, 2016],ylim = [10.0, 11.12], size_init = 1, size_mult = 40, \n",
    "                      size_edge_market = 2, xlabel = True, ylabel = True, ylabel_text = 'MMSE',color_dict_ = '', X_cat_ = ''):\n",
    "    \n",
    "    #X_cat = pd.read_csv('Data/var_name_color_code.csv', encoding='latin-1', sep=\";\")\n",
    "    \n",
    "    color = get_color(var, X_cat_, color_dict_)\n",
    "    edge_color = 'black'\n",
    "\n",
    "    y = []\n",
    "    for i in range(len(y_countrys_)):\n",
    "        y.append(y_countrys_[i].mean())\n",
    "        #y = [y_countrys_[0].mean(), y_countrys_[1].mean(),\n",
    "        #     y_countrys_[2].mean(), y_countrys_[3].mean(),\n",
    "        #     y_countrys_[4].mean()]\n",
    "\n",
    "\n",
    "    #var_ind = list(X_cat.oldname).index(var)\n",
    "    #var_ = list(X_cat.newname)[var_ind]\n",
    "    \n",
    "\n",
    "     \n",
    "    plt.plot(range(1, len(y_countrys_)+1), y, 'k--')\n",
    "\n",
    "    for i in range(len(models_)):\n",
    "        df = models_[i][0]\n",
    "        y = np.abs(df.iloc[df.index.get_loc(var), df.columns.get_loc('Estimate')])\n",
    "        \n",
    "        if(market_size_type=='log'):\n",
    "            if(y < 0.003):\n",
    "                markersize_ = 0\n",
    "            else:\n",
    "                markersize_ = size_mult*(5 + np.log(y))\n",
    "        elif(market_size_type=='log1'):\n",
    "            markersize_ = np.log(100000*y)\n",
    "        elif(market_size_type=='sigmoide'):\n",
    "            markersize_ = size_mult*sigmoid(y)\n",
    "        else:\n",
    "            markersize_ = np.abs(size_mult*y) \n",
    "        \n",
    "        \n",
    "        markersize_ +=size_init\n",
    "        plt.plot(i + 1, y_countrys_[i].mean(), marker=\"o\",  \n",
    "                 markeredgewidth = size_edge_market, markeredgecolor = edge_color, markerfacecolor = color, markersize= markersize_)\n",
    "        \n",
    "        \n",
    "        p = df['p value'][var]\n",
    "        \n",
    "        p_text = ''\n",
    "        if(p<= 0.01):\n",
    "            p_text = '**'\n",
    "        elif((p<= 0.05)):\n",
    "            p_text = '*'\n",
    "        \n",
    "        \n",
    "        plt.text(i + 1 , y_countrys_[i].mean(), p_text,\n",
    "                                             size= 22, rotation=0.,\n",
    "                                             ha=\"center\", va=\"top\", color = 'black',\n",
    "                                            # bbox=dict(boxstyle=\"round\", pad=0.1,\n",
    "                                            #           ec='gray',\n",
    "                                            #           fc='gray',\n",
    "                                            #          )\n",
    "                                             );\n",
    "        \n",
    "       # plt.text(i + 1 , ylim[0] - 0.25, str(round(markersize_,2)),\n",
    "        #                                     size= 8, rotation=0.,\n",
    "         #                                    ha=\"center\", va=\"top\", color = 'black',\n",
    "                                            # bbox=dict(boxstyle=\"round\", pad=0.1,\n",
    "                                            #           ec='gray',\n",
    "                                            #           fc='gray',\n",
    "                                            #          )\n",
    "          #                                   );\n",
    "       # print('')\n",
    "        r2 = str(np.round(models_[i][1],2))\n",
    "        f2 = str(np.round(models_[i][3],2))\n",
    "        #plt.text(i+1,10.15,r'$R^2$ ('+r2+') \\n$F^2$ ('+f2+')',\n",
    "        #                         size= 12, rotation=0.,\n",
    "        #                         ha=\"center\", va=\"top\", color = 'black',\n",
    "        #                         bbox=dict(boxstyle=\"round\", pad=0.1,\n",
    "        #                                   ec='ghostwhite',\n",
    "        #                                    fc='ghostwhite',\n",
    "        #                                  )\n",
    "        #                         );\n",
    "\n",
    "    plt.text(xlim[1] , ylim[1], var,\n",
    "                                         size= 13, rotation=0.,\n",
    "                                         ha=\"right\", va=\"center\", color = 'black',\n",
    "                                        # bbox=dict(boxstyle=\"round\", pad=0.1,\n",
    "                                        #           ec='gray',\n",
    "                                        #           fc='gray',\n",
    "                                        #          )\n",
    "                                         );\n",
    "\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim([ylim[0]-0.25, ylim[1]+0.25])\n",
    "    \n",
    "\n",
    "    if(xlabel):\n",
    "        plt.xticks(list(range(1, len(years)+1)), years)\n",
    "    else:\n",
    "        plt.xticks(list(range(1, len(years)+1)), ['', '', '', '', ''])\n",
    "    \n",
    "    if(ylabel):\n",
    "        plt.yticks(np.round(np.linspace(ylim[0], ylim[1], 4),2), np.round(np.linspace(ylim[0], ylim[1], 4),1))\n",
    "    else:\n",
    "        plt.yticks(np.round(np.linspace(ylim[0], ylim[1], 4),2), ['', '', '', ''])\n",
    "\n",
    "    if(ylabel):\n",
    "        plt.ylabel(ylabel_text, fontsize=13)\n",
    "    else:\n",
    "        plt.ylabel('')\n",
    "        \n",
    "    if(xlabel):\n",
    "        plt.xlabel('Years', fontsize=13)\n",
    "    else:\n",
    "        plt.xlabel('')\n",
    "\n",
    "def plot_r2_f2(models_, xlim = [0.25, 5.75], ylim = [10.0, 11.12]):\n",
    "    \n",
    "    X_cat = pd.read_csv('Data/var_name_color_code.csv', encoding='latin-1', sep=\";\")\n",
    "    \n",
    "    \n",
    "    plt.plot(0.0)\n",
    "\n",
    "    for i in range(len(models)):\n",
    "\n",
    "        r2 = str(np.round(models_[i][1],2))\n",
    "        f2 = str(np.round(models_[i][3],2))\n",
    "        plt.text(i+1,1,r'$R^2$ ('+r2+') \\n$F^2$ ('+f2+')',\n",
    "                                 size= 12, rotation=0.,\n",
    "                                 ha=\"center\", va=\"top\", color = 'black',\n",
    "                                 #bbox=dict(boxstyle=\"round\", pad=0.1,\n",
    "                                 #          ec='ghostwhite',\n",
    "                                 #           fc='ghostwhite',\n",
    "                                 #         )\n",
    "                                 );\n",
    "        \n",
    "    \n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim([ylim[0], ylim[1]])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sabe_chile = pd.read_excel('../Data/cross/SABE_chile.xlsx') # to use it for columns order\n",
    "sabe_chile = sabe_chile.iloc[:,1::]\n",
    "\n",
    "sabe_costarica = pd.read_excel('../Data/long/SABE_costarica_long.xlsx')\n",
    "sabe_costarica = sabe_costarica.iloc[:,1::]\n",
    "\n",
    "sabe_korea_2006 = pd.read_excel('../Data/long/SABE_korea_2006.xlsx')\n",
    "sabe_korea_2006 = sabe_korea_2006.iloc[:,1::]\n",
    "\n",
    "sabe_korea_2006_2008 = pd.read_excel('../Data/long/SABE_korea_2006_2008.xlsx')\n",
    "sabe_korea_2006_2008 = sabe_korea_2006_2008.iloc[:,1::]\n",
    "\n",
    "sabe_korea_2006_2010 = pd.read_excel('../Data/long/SABE_korea_2006_2010.xlsx')\n",
    "sabe_korea_2006_2010 = sabe_korea_2006_2010.iloc[:,1::]\n",
    "\n",
    "sabe_korea_2006_2012 = pd.read_excel('../Data/long/SABE_korea_2006_2012.xlsx')\n",
    "sabe_korea_2006_2012 = sabe_korea_2006_2012.iloc[:,1::]\n",
    "\n",
    "sabe_korea_2006_2014 = pd.read_excel('../Data/long/SABE_korea_2006_2014.xlsx')\n",
    "sabe_korea_2006_2014 = sabe_korea_2006_2014.iloc[:,1::]\n",
    "\n",
    "sabe_korea_2006_2016 = pd.read_excel('../Data/long/SABE_korea_2006_2016.xlsx')\n",
    "sabe_korea_2006_2016 = sabe_korea_2006_2016.iloc[:,1::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FD_none_Edad_a01b',\n",
       " 'FD_none_Sexo_c18',\n",
       " 'FM_CardioMetab_Diabetes_c05',\n",
       " 'FS_Educ_yeduca',\n",
       " 'FS_Aislamiento_ViveSolo_g2',\n",
       " 'FS_EstSocEcon_TipoVivienda_none',\n",
       " 'FS_EstSocEcon_ElectricEquipment_none',\n",
       " 'FM_CardioMetab_IMC_none',\n",
       " 'FM_CardioMetab_Hiperten_c04',\n",
       " 'FM_CardioMetab_IAM_c08',\n",
       " 'FM_CardioMetab_ACV_c09',\n",
       " 'FM_EstiloVida_Alcohol_c23',\n",
       " 'FM_EstiloVida_ActividadFis_c25a',\n",
       " 'FM_EstiloVida_Fuma_c24',\n",
       " 'FM_EstiloVida_Caida12Mes_c11',\n",
       " 'FM_SaludMental_ProbNervDiagnost_c20',\n",
       " 'FS_Adversidad_AgresionFis_j27',\n",
       " 'FS_Adversidad_AgresionVerb_j28',\n",
       " 'MMSE',\n",
       " 'Barthel']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_col = list(sabe_chile.columns)\n",
    "del sabe_chile\n",
    "order_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_costarica_01 = sabe_costarica.copy()\n",
    "\n",
    "X_korea_2006_01 = sabe_korea_2006.copy()\n",
    "X_korea_2006_2008_01 = sabe_korea_2006_2008.copy()\n",
    "X_korea_2006_2010_01 = sabe_korea_2006_2010.copy()\n",
    "X_korea_2006_2012_01 = sabe_korea_2006_2012.copy()\n",
    "X_korea_2006_2014_01 = sabe_korea_2006_2014.copy()\n",
    "X_korea_2006_2016_01 = sabe_korea_2006_2016.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_drop = ['CASEID', 'FD_none_Edad_a01b', 'FD_none_Sexo_c18', 'FM_CardioMetab_Diabetes_c05', 'FS_Educ_yeduca', \n",
    "             'FS_Aislamiento_ViveSolo_g2_med',\n",
    "                'FM_CardioMetab_Hiperten_c04', 'FM_CardioMetab_IAM_c08',\n",
    "                 'FM_EstiloVida_Alcohol_c23', 'FM_EstiloVida_ActividadFis_c25a', 'FM_EstiloVida_Fuma_c24', \n",
    "                 'FM_EstiloVida_Caida12Mes_c11', 'FM_SaludMental_ProbNervDiagnost_c20', 'MMSE_diff', 'Barthel_diff']\n",
    "\n",
    "list_drop.append('MMSE_2008')\n",
    "X_korea_2006_2008_01 = X_korea_2006_2008_01[list_drop]\n",
    "\n",
    "list_drop.remove('MMSE_2008')\n",
    "list_drop.append('MMSE_2010')\n",
    "X_korea_2006_2010_01 = X_korea_2006_2010_01[list_drop]\n",
    "\n",
    "list_drop.remove('MMSE_2010')\n",
    "list_drop.append('MMSE_2012')\n",
    "X_korea_2006_2012_01 = X_korea_2006_2012_01[list_drop]\n",
    "\n",
    "list_drop.remove('MMSE_2012')\n",
    "list_drop.append('MMSE_2014')\n",
    "X_korea_2006_2014_01 = X_korea_2006_2014_01[list_drop]\n",
    "\n",
    "list_drop.remove('MMSE_2014')\n",
    "list_drop.append('MMSE_2016')\n",
    "X_korea_2006_2016_01 = X_korea_2006_2016_01[list_drop]\n",
    "\n",
    "\n",
    "list_drop = ['FD_none_Edad_a01b', 'FD_none_Sexo_c18', 'FM_CardioMetab_Diabetes_c05', 'FS_Educ_yeduca', \n",
    "             'FS_Aislamiento_ViveSolo_g2',\n",
    "                'FM_CardioMetab_Hiperten_c04', 'FM_CardioMetab_IAM_c08',\n",
    "                 'FM_EstiloVida_Alcohol_c23', 'FM_EstiloVida_ActividadFis_c25a', 'FM_EstiloVida_Fuma_c24', \n",
    "                 'FM_EstiloVida_Caida12Mes_c11_med','FM_SaludMental_ProbNervDiagnost_c20', 'MMSE_diff', 'Barthel_diff']\n",
    "\n",
    "\n",
    "list_drop.append('MMSE_w2')\n",
    "list_drop.append('MMSE')\n",
    "X_costarica_01 = X_costarica_01[list_drop]\n",
    "\n",
    "\n",
    "list_drop = ['CASEID', 'FD_none_Edad_a01b', 'FD_none_Sexo_c18', 'FM_CardioMetab_Diabetes_c05', 'FS_Educ_yeduca', 'FS_Aislamiento_ViveSolo_g2_med',\n",
    "                'FM_CardioMetab_Hiperten_c04', 'FM_CardioMetab_IAM_c08',\n",
    "                 'FM_EstiloVida_Alcohol_c23', 'FM_EstiloVida_ActividadFis_c25a', 'FM_EstiloVida_Fuma_c24', \n",
    "                 'FM_EstiloVida_Caida12Mes_c11','FM_SaludMental_ProbNervDiagnost_c20', 'MMSE']\n",
    "\n",
    "\n",
    "X_korea_2006_01 = X_korea_2006_01[list_drop]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data and get common participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9582, 14)\n"
     ]
    }
   ],
   "source": [
    "X_korea_2006_common_subjects = X_korea_2006_01.copy()\n",
    "X_korea_2006_common_subjects.dropna(inplace=True)\n",
    "\n",
    "X_korea_2006_ids = X_korea_2006_common_subjects['CASEID']\n",
    "print(X_korea_2006_common_subjects.shape,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5604, 14)\n"
     ]
    }
   ],
   "source": [
    "X_korea_2006_2008_common_subjects = X_korea_2006_2008_01.drop(['Barthel_diff'], axis=1)\n",
    "X_korea_2006_2008_common_subjects.drop(X_korea_2006_2008_common_subjects[X_korea_2006_2008_common_subjects['MMSE_diff'] <0].index, inplace=True)\n",
    "X_korea_2006_2008_common_subjects = X_korea_2006_2008_common_subjects.drop(['MMSE_diff' ], axis=1)\n",
    "X_korea_2006_2008_common_subjects.dropna(inplace=True)\n",
    "\n",
    "X_korea_2006_2008_ids = X_korea_2006_2008_common_subjects['CASEID']\n",
    "print(X_korea_2006_2008_common_subjects.shape,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4937, 14)\n"
     ]
    }
   ],
   "source": [
    "X_korea_2006_2010_common_subjects = X_korea_2006_2010_01.drop(['Barthel_diff' ], axis=1)\n",
    "X_korea_2006_2010_common_subjects.drop(X_korea_2006_2010_common_subjects[X_korea_2006_2010_common_subjects['MMSE_diff'] <0].index, inplace=True)\n",
    "X_korea_2006_2010_common_subjects = X_korea_2006_2010_common_subjects.drop(['MMSE_diff' ], axis=1)\n",
    "X_korea_2006_2010_common_subjects.dropna(inplace=True)\n",
    "\n",
    "X_korea_2006_2010_ids = X_korea_2006_2010_common_subjects['CASEID']\n",
    "print(X_korea_2006_2010_common_subjects.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4639, 14)\n"
     ]
    }
   ],
   "source": [
    "X_korea_2006_2012_common_subjects = X_korea_2006_2012_01.drop(['Barthel_diff' ], axis=1)\n",
    "X_korea_2006_2012_common_subjects.drop(X_korea_2006_2012_common_subjects[X_korea_2006_2012_common_subjects['MMSE_diff'] <0].index, inplace=True)\n",
    "X_korea_2006_2012_common_subjects = X_korea_2006_2012_common_subjects.drop(['MMSE_diff' ], axis=1)\n",
    "X_korea_2006_2012_common_subjects.dropna(inplace=True)\n",
    "\n",
    "X_korea_2006_2012_ids = X_korea_2006_2012_common_subjects['CASEID']\n",
    "print(X_korea_2006_2012_common_subjects.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4470, 14)\n"
     ]
    }
   ],
   "source": [
    "X_korea_2006_2014_common_subjects = X_korea_2006_2014_01.drop(['Barthel_diff' ], axis=1)\n",
    "X_korea_2006_2014_common_subjects.drop(X_korea_2006_2014_common_subjects[X_korea_2006_2014_common_subjects['MMSE_diff'] <0].index, inplace=True)\n",
    "X_korea_2006_2014_common_subjects = X_korea_2006_2014_common_subjects.drop(['MMSE_diff' ], axis=1)\n",
    "X_korea_2006_2014_common_subjects.dropna(inplace=True)\n",
    "\n",
    "X_korea_2006_2014_ids = X_korea_2006_2014_common_subjects['CASEID']\n",
    "print(X_korea_2006_2014_common_subjects.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4370, 14)\n"
     ]
    }
   ],
   "source": [
    "X_korea_2006_2016_common_subjects = X_korea_2006_2016_01.drop(['Barthel_diff' ], axis=1)\n",
    "X_korea_2006_2016_common_subjects.drop(X_korea_2006_2016_common_subjects[X_korea_2006_2016_common_subjects['MMSE_diff'] <0].index, inplace=True)\n",
    "X_korea_2006_2016_common_subjects = X_korea_2006_2016_common_subjects.drop(['MMSE_diff' ], axis=1)\n",
    "X_korea_2006_2016_common_subjects.dropna(inplace=True)\n",
    "\n",
    "X_korea_2006_2016_ids = X_korea_2006_2016_common_subjects['CASEID']\n",
    "print(X_korea_2006_2016_common_subjects.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3585, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge = X_korea_2006_ids.copy()\n",
    "#merge = pd.merge(merge, X_korea_2006_2008_ids, on='CASEID', how='inner')\n",
    "#merge = pd.merge(merge, X_korea_2006_2010_ids, on='CASEID', how='inner')\n",
    "#merge = pd.merge(merge, X_korea_2006_2012_ids, on='CASEID', how='inner')\n",
    "merge = pd.merge(merge, X_korea_2006_2014_ids, on='CASEID', how='inner')\n",
    "merge = pd.merge(merge, X_korea_2006_2016_ids, on='CASEID', how='inner')\n",
    "\n",
    "merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_korea_2006_common_ids = pd.merge(X_korea_2006_common_subjects, merge, on='CASEID', how='inner')\n",
    "X_korea_2006_common_ids = X_korea_2006_common_ids.drop('CASEID', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_korea_2006_2014_common_ids = pd.merge(X_korea_2006_2014_common_subjects, merge, on='CASEID', how='inner')\n",
    "X_korea_2006_2014_common_ids = X_korea_2006_2014_common_ids.drop('CASEID', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_korea_2006_2016_common_ids = pd.merge(X_korea_2006_2016_common_subjects, merge, on='CASEID', how='inner')\n",
    "X_korea_2006_2016_common_ids = X_korea_2006_2016_common_ids.drop('CASEID', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006: 3585 \t2014: 3585 \t2016: 3585\n",
      "2006: 5997 \t2014: 3064 \t2016: 2681\n"
     ]
    }
   ],
   "source": [
    "print('2006:', X_korea_2006_common_ids.shape[0], '\\t2014:', X_korea_2006_2014_common_ids.shape[0], '\\t2016:', X_korea_2006_2016_common_ids.shape[0])\n",
    "print('2006:', X_korea_2006_01.shape[0] - X_korea_2006_common_ids.shape[0], \n",
    "      '\\t2014:', X_korea_2006_2014_01.shape[0] - X_korea_2006_2014_common_ids.shape[0], \n",
    "      '\\t2016:', X_korea_2006_2016_01.shape[0] - X_korea_2006_2016_common_ids.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1751, 14)\n"
     ]
    }
   ],
   "source": [
    "X_costarica_01_common_subjects = X_costarica_01.drop(['Barthel_diff' ], axis=1)\n",
    "X_costarica_01_common_subjects.drop(X_costarica_01_common_subjects[X_costarica_01_common_subjects['MMSE_diff'] <0].index, inplace=True)\n",
    "X_costarica_01_common_subjects = X_costarica_01_common_subjects.drop(['MMSE_diff' ], axis=1)\n",
    "X_costarica_01_common_subjects.dropna(inplace=True)\n",
    "\n",
    "\n",
    "print(X_costarica_01_common_subjects.shape,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_costarica_w1 = X_costarica_01_common_subjects.drop(['MMSE_w2' ], axis=1)\n",
    "X_costarica_w2 = X_costarica_01_common_subjects.drop(['MMSE' ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1: 1751 \\w2: 1751\n",
      "w1: 410 \tw2: 0\n"
     ]
    }
   ],
   "source": [
    "print('w1:', X_costarica_w1.shape[0], '\\w2:', X_costarica_w2.shape[0])\n",
    "print('w1:', X_costarica_01.shape[0] - X_costarica_w1.shape[0], \n",
    "      '\\tw2:', X_costarica_01_common_subjects.shape[0] - X_costarica_w2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colors, variables names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = pd.read_csv('../Data/cross/var_name_color_code_new.csv', encoding='latin-1', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_name = []\n",
    "\n",
    "for i in range(len(X_costarica_w1.columns)):\n",
    "    if(X_costarica_w1.columns[i] == 'FM_EstiloVida_Caida12Mes_c11_med'):\n",
    "        label = 'FM_EstiloVida_Caida12Mes_c11'\n",
    "    else:\n",
    "        label = X_costarica_w1.columns[i]\n",
    "    \n",
    "    index_ = list(X_cat.oldname).index(label)\n",
    "    new_name.append(list(X_cat.newname)[index_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " FD_none_Edad_a01b \n",
      " FD_none_Edad_a01b \n",
      " FD_none_Edad_a01b \n",
      " FD_none_Edad_a01b \n",
      " FD_none_Edad_a01b \n",
      " Age\n",
      "-------------------------------------------\n",
      " FD_none_Sexo_c18 \n",
      " FD_none_Sexo_c18 \n",
      " FD_none_Sexo_c18 \n",
      " FD_none_Sexo_c18 \n",
      " FD_none_Sexo_c18 \n",
      " Sex\n",
      "-------------------------------------------\n",
      " FM_CardioMetab_Diabetes_c05 \n",
      " FM_CardioMetab_Diabetes_c05 \n",
      " FM_CardioMetab_Diabetes_c05 \n",
      " FM_CardioMetab_Diabetes_c05 \n",
      " FM_CardioMetab_Diabetes_c05 \n",
      " Diabetes\n",
      "-------------------------------------------\n",
      " FS_Educ_yeduca \n",
      " FS_Educ_yeduca \n",
      " FS_Educ_yeduca \n",
      " FS_Educ_yeduca \n",
      " FS_Educ_yeduca \n",
      " Education\n",
      "-------------------------------------------\n",
      " FS_Aislamiento_ViveSolo_g2 \n",
      " FS_Aislamiento_ViveSolo_g2 \n",
      " FS_Aislamiento_ViveSolo_g2_med \n",
      " FS_Aislamiento_ViveSolo_g2_med \n",
      " FS_Aislamiento_ViveSolo_g2_med \n",
      " Live Alone\n",
      "-------------------------------------------\n",
      " FM_CardioMetab_Hiperten_c04 \n",
      " FM_CardioMetab_Hiperten_c04 \n",
      " FM_CardioMetab_Hiperten_c04 \n",
      " FM_CardioMetab_Hiperten_c04 \n",
      " FM_CardioMetab_Hiperten_c04 \n",
      " Hypertension\n",
      "-------------------------------------------\n",
      " FM_CardioMetab_IAM_c08 \n",
      " FM_CardioMetab_IAM_c08 \n",
      " FM_CardioMetab_IAM_c08 \n",
      " FM_CardioMetab_IAM_c08 \n",
      " FM_CardioMetab_IAM_c08 \n",
      " Heart Disease\n",
      "-------------------------------------------\n",
      " FM_EstiloVida_Alcohol_c23 \n",
      " FM_EstiloVida_Alcohol_c23 \n",
      " FM_EstiloVida_Alcohol_c23 \n",
      " FM_EstiloVida_Alcohol_c23 \n",
      " FM_EstiloVida_Alcohol_c23 \n",
      " Alcohol consumption\n",
      "-------------------------------------------\n",
      " FM_EstiloVida_ActividadFis_c25a \n",
      " FM_EstiloVida_ActividadFis_c25a \n",
      " FM_EstiloVida_ActividadFis_c25a \n",
      " FM_EstiloVida_ActividadFis_c25a \n",
      " FM_EstiloVida_ActividadFis_c25a \n",
      " Physical activity\n",
      "-------------------------------------------\n",
      " FM_EstiloVida_Fuma_c24 \n",
      " FM_EstiloVida_Fuma_c24 \n",
      " FM_EstiloVida_Fuma_c24 \n",
      " FM_EstiloVida_Fuma_c24 \n",
      " FM_EstiloVida_Fuma_c24 \n",
      " Smoking status\n",
      "-------------------------------------------\n",
      " FM_EstiloVida_Caida12Mes_c11_med \n",
      " FM_EstiloVida_Caida12Mes_c11_med \n",
      " FM_EstiloVida_Caida12Mes_c11 \n",
      " FM_EstiloVida_Caida12Mes_c11 \n",
      " FM_EstiloVida_Caida12Mes_c11 \n",
      " Falls\n",
      "-------------------------------------------\n",
      " FM_SaludMental_ProbNervDiagnost_c20 \n",
      " FM_SaludMental_ProbNervDiagnost_c20 \n",
      " FM_SaludMental_ProbNervDiagnost_c20 \n",
      " FM_SaludMental_ProbNervDiagnost_c20 \n",
      " FM_SaludMental_ProbNervDiagnost_c20 \n",
      " Mental Problems\n",
      "-------------------------------------------\n",
      " MMSE \n",
      " MMSE_w2 \n",
      " MMSE \n",
      " MMSE_2014 \n",
      " MMSE_2016 \n",
      " MMSE\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check\n",
    "for i in range(len(X_costarica_w1.columns)):\n",
    "    print('', X_costarica_w1.columns[i], '\\n', X_costarica_w2.columns[i], '\\n', X_korea_2006_common_ids.columns[i], \n",
    "          '\\n', X_korea_2006_2014_common_ids.columns[i], '\\n', \n",
    "          X_korea_2006_2016_common_ids.columns[i], '\\n',new_name[i])\n",
    "    print('-------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_costarica_w1.columns =  new_name\n",
    "X_costarica_w2.columns =  new_name\n",
    "X_korea_2006_common_ids.columns =  new_name\n",
    "#X_korea_2006_2012_common_ids.columns =  new_name\n",
    "X_korea_2006_2014_common_ids.columns =  new_name\n",
    "X_korea_2006_2016_common_ids.columns =  new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Age \n",
      " Age \n",
      " Age \n",
      " Age \n",
      " Age \n",
      " Age\n",
      "-------------------------------------------\n",
      " Sex \n",
      " Sex \n",
      " Sex \n",
      " Sex \n",
      " Sex \n",
      " Sex\n",
      "-------------------------------------------\n",
      " Diabetes \n",
      " Diabetes \n",
      " Diabetes \n",
      " Diabetes \n",
      " Diabetes \n",
      " Diabetes\n",
      "-------------------------------------------\n",
      " Education \n",
      " Education \n",
      " Education \n",
      " Education \n",
      " Education \n",
      " Education\n",
      "-------------------------------------------\n",
      " Live Alone \n",
      " Live Alone \n",
      " Live Alone \n",
      " Live Alone \n",
      " Live Alone \n",
      " Live Alone\n",
      "-------------------------------------------\n",
      " Hypertension \n",
      " Hypertension \n",
      " Hypertension \n",
      " Hypertension \n",
      " Hypertension \n",
      " Hypertension\n",
      "-------------------------------------------\n",
      " Heart Disease \n",
      " Heart Disease \n",
      " Heart Disease \n",
      " Heart Disease \n",
      " Heart Disease \n",
      " Heart Disease\n",
      "-------------------------------------------\n",
      " Alcohol consumption \n",
      " Alcohol consumption \n",
      " Alcohol consumption \n",
      " Alcohol consumption \n",
      " Alcohol consumption \n",
      " Alcohol consumption\n",
      "-------------------------------------------\n",
      " Physical activity \n",
      " Physical activity \n",
      " Physical activity \n",
      " Physical activity \n",
      " Physical activity \n",
      " Physical activity\n",
      "-------------------------------------------\n",
      " Smoking status \n",
      " Smoking status \n",
      " Smoking status \n",
      " Smoking status \n",
      " Smoking status \n",
      " Smoking status\n",
      "-------------------------------------------\n",
      " Falls \n",
      " Falls \n",
      " Falls \n",
      " Falls \n",
      " Falls \n",
      " Falls\n",
      "-------------------------------------------\n",
      " Mental Problems \n",
      " Mental Problems \n",
      " Mental Problems \n",
      " Mental Problems \n",
      " Mental Problems \n",
      " Mental Problems\n",
      "-------------------------------------------\n",
      " MMSE \n",
      " MMSE \n",
      " MMSE \n",
      " MMSE \n",
      " MMSE \n",
      " MMSE\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check\n",
    "for i in range(len(X_costarica_w1.columns)):\n",
    "    print('', X_costarica_w1.columns[i], '\\n', X_costarica_w2.columns[i], '\\n', X_korea_2006_common_ids.columns[i],\n",
    "          '\\n', X_korea_2006_2014_common_ids.columns[i], '\\n', \n",
    "          X_korea_2006_2016_common_ids.columns[i], '\\n',new_name[i])\n",
    "    print('-------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korea 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_korea_2006 = X_korea_2006_common_ids['MMSE']\n",
    "X_korea_2006 = X_korea_2006_common_ids.drop('MMSE', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge\n",
      "best parameters: OrderedDict([('alpha', 0.1), ('max_iter', 1000000), ('solver', 'lsqr')])\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_korea_2006, y_korea_2006, train_size=0.75, test_size=.25, random_state=0)\n",
    "\n",
    "# log-uniform: understand as search over p = exp(x) by varying x\n",
    "opt_Ridge = BayesSearchCV(\n",
    "    Ridge(),\n",
    "    {\n",
    "        'alpha': (1.0, 0.1, 0.01, 0.001),\n",
    "        'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "        'max_iter': (1000, 10000, 100000, 1000000),\n",
    "        #'tol:' : (1e-6, 1e-3, 1e+1),\n",
    "        #'n_estimators': (100, 1000),\n",
    "\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "opt_Ridge.fit(X_train, y_train)\n",
    "\n",
    "print('Ridge')\n",
    "print(\"best parameters: %s\" % str(opt_Ridge.best_params_))\n",
    "print('---------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen del regresor Ridge\n",
      "\n",
      "Residuals:\n",
      "   Min      1Q  Median      3Q     Max\n",
      "9.2964 11.3491 12.0835 12.6615 13.8536\n",
      "\n",
      "\n",
      "Coefficients:\n",
      "                      Estimate  t value       p value\n",
      "_intercept           15.274409   0.0000  9.999708e-01\n",
      "Age                  -0.062307  83.8701  0.000000e+00\n",
      "Sex                  -0.292865   5.0816  3.933631e-07\n",
      "Diabetes              0.132756   1.7673  7.726612e-02\n",
      "Education             0.440133  12.1468  0.000000e+00\n",
      "Live Alone           -0.000000   0.0000  1.000000e+00\n",
      "Hypertension          0.111018   2.1401  3.241097e-02\n",
      "Heart Disease        -0.006217   0.0585  9.533610e-01\n",
      "Alcohol consumption  -0.060297   1.8918  5.859650e-02\n",
      "Physical activity    -0.252662   5.5396  3.249453e-08\n",
      "Smoking status       -0.021470   0.3451  7.300428e-01\n",
      "Falls                 0.035277   0.3079  7.581774e-01\n",
      "Mental Problems       0.072102   0.4600  6.455541e-01\n",
      "---\n",
      "R-squared:  0.27992,    Adjusted R-squared:  0.27750\n",
      "F-squared:  0.38874\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelRidge_korea_2006 = Ridge(alpha=opt_Ridge.best_params_['alpha'], solver = opt_Ridge.best_params_['solver'], \n",
    "                         max_iter=opt_Ridge.best_params_['max_iter'])\n",
    "modelRidge_korea_2006.fit(X_korea_2006, y_korea_2006)\n",
    "\n",
    "parameter_dict['korea_2006'] = opt_Ridge.best_params_\n",
    "\n",
    "modelRidge_sum_korea_2006 = summary(modelRidge_korea_2006, X_korea_2006, y_korea_2006, X_korea_2006.columns, 'Ridge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korea 2006-2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_korea_2006_2014 = X_korea_2006_2014_common_ids['MMSE']\n",
    "X_korea_2006_2014 = X_korea_2006_2014_common_ids.drop('MMSE', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge\n",
      "best parameters: OrderedDict([('alpha', 1.0), ('max_iter', 1000000), ('solver', 'lsqr')])\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_korea_2006_2014, y_korea_2006_2014, train_size=0.75, test_size=.25, random_state=0)\n",
    "\n",
    "# log-uniform: understand as search over p = exp(x) by varying x\n",
    "opt_Ridge = BayesSearchCV(\n",
    "    Ridge(),\n",
    "    {\n",
    "        'alpha': (1.0, 0.1, 0.01, 0.001),\n",
    "        'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "        'max_iter': (1000, 10000, 100000, 1000000),\n",
    "        #'tol:' : (1e-6, 1e-3, 1e+1),\n",
    "        #'n_estimators': (100, 1000),\n",
    "\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "opt_Ridge.fit(X_train, y_train)\n",
    "\n",
    "print('Ridge')\n",
    "print(\"best parameters: %s\" % str(opt_Ridge.best_params_))\n",
    "print('---------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen del regresor Ridge\n",
      "\n",
      "Residuals:\n",
      "    Min      1Q  Median     3Q     Max\n",
      "-5.2427 -1.5535 -0.4105 1.1613 12.0742\n",
      "\n",
      "\n",
      "Coefficients:\n",
      "                      Estimate    t value       p value\n",
      "_intercept           16.638637   0.000000  9.999815e-01\n",
      "Age                  -0.124376  94.090762  0.000000e+00\n",
      "Sex                  -0.613927   6.181900  7.045089e-10\n",
      "Diabetes              0.217922   1.683600  9.235474e-02\n",
      "Education             0.695698  11.141200  0.000000e+00\n",
      "Live Alone            0.000000   0.000000  1.000000e+00\n",
      "Hypertension          0.085979   0.961900  3.361892e-01\n",
      "Heart Disease         0.083298   0.454800  6.492795e-01\n",
      "Alcohol consumption  -0.018425   0.335500  7.372819e-01\n",
      "Physical activity    -0.340770   4.335900  1.491485e-05\n",
      "Smoking status        0.128410   1.197800  2.310731e-01\n",
      "Falls                -0.077588   0.393000  6.943592e-01\n",
      "Mental Problems       0.257884   0.954700  3.397713e-01\n",
      "---\n",
      "R-squared:  0.30939,    Adjusted R-squared:  0.30707\n",
      "F-squared:  0.44799\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelRidge_korea_2006_2014 = Ridge(alpha=0.001, solver = opt_Ridge.best_params_['solver'], \n",
    "                         max_iter=opt_Ridge.best_params_['max_iter'])\n",
    "modelRidge_korea_2006_2014.fit(X_korea_2006_2014, y_korea_2006_2014)\n",
    "\n",
    "parameter_dict['korea_2006_2014'] = opt_Ridge.best_params_\n",
    "\n",
    "modelRidge_sum_korea_2006_2014 = summary(modelRidge_korea_2006_2014, X_korea_2006_2014, y_korea_2006_2014, X_korea_2006_2014.columns, 'Ridge')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korea 2006-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_korea_2006_2016 = X_korea_2006_2016_common_ids['MMSE']\n",
    "X_korea_2006_2016 = X_korea_2006_2016_common_ids.drop('MMSE', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge\n",
      "best parameters: OrderedDict([('alpha', 1.0), ('max_iter', 10000), ('solver', 'auto')])\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_korea_2006_2016, y_korea_2006_2016, train_size=0.75, test_size=.25, random_state=0)\n",
    "\n",
    "# log-uniform: understand as search over p = exp(x) by varying x\n",
    "opt_Ridge = BayesSearchCV(\n",
    "    Ridge(),\n",
    "    {\n",
    "        'alpha': (1.0, 0.1, 0.01, 0.001),\n",
    "        'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "        'max_iter': (1000, 10000, 100000, 1000000),\n",
    "        #'tol:' : (1e-6, 1e-3, 1e+1),\n",
    "        #'n_estimators': (100, 1000),\n",
    "\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "opt_Ridge.fit(X_train, y_train)\n",
    "\n",
    "print('Ridge')\n",
    "print(\"best parameters: %s\" % str(opt_Ridge.best_params_))\n",
    "print('---------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen del regresor Ridge\n",
      "\n",
      "Residuals:\n",
      "    Min      1Q  Median     3Q     Max\n",
      "-5.8774 -1.6313 -0.4012 1.4022 11.5649\n",
      "\n",
      "\n",
      "Coefficients:\n",
      "                      Estimate    t value       p value\n",
      "_intercept           17.111794    0.00000  9.999819e-01\n",
      "Age                  -0.142852  157.46363  0.000000e+00\n",
      "Sex                  -0.552568    5.30430  1.199350e-07\n",
      "Diabetes              0.102014    0.75130  4.525121e-01\n",
      "Education             0.728242   11.11940  0.000000e+00\n",
      "Live Alone            0.000000    0.00000  1.000000e+00\n",
      "Hypertension         -0.089467    0.95420  3.400617e-01\n",
      "Heart Disease         0.277857    1.44630  1.481806e-01\n",
      "Alcohol consumption  -0.081920    1.42200  1.551243e-01\n",
      "Physical activity    -0.305520    3.70590  2.138366e-04\n",
      "Smoking status        0.074637    0.66370  5.069238e-01\n",
      "Falls                -0.212129    1.02430  3.057686e-01\n",
      "Mental Problems       0.638267    2.25270  2.433593e-02\n",
      "---\n",
      "R-squared:  0.32710,    Adjusted R-squared:  0.32484\n",
      "F-squared:  0.48610\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelRidge_korea_2006_2016 = Ridge(alpha=opt_Ridge.best_params_['alpha'], solver = opt_Ridge.best_params_['solver'], \n",
    "                         max_iter=opt_Ridge.best_params_['max_iter'])\n",
    "modelRidge_korea_2006_2016.fit(X_korea_2006_2016, y_korea_2006_2016)\n",
    "\n",
    "parameter_dict['korea_2006_2016'] = opt_Ridge.best_params_\n",
    "\n",
    "modelRidge_sum_korea_2006_2016 = summary(modelRidge_korea_2006_2016, X_korea_2006_2016, y_korea_2006_2016, X_korea_2006_2016.columns, 'Ridge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costa Rica wave 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_costarica_1 = X_costarica_w1['MMSE']\n",
    "X_costarica_1 = X_costarica_w1.drop(['MMSE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge\n",
      "val. score: 0.056519190556453415\n",
      "test score: 0.057231873665858246\n",
      "best parameters: OrderedDict([('alpha', 1.0), ('max_iter', 1000000), ('solver', 'cholesky')])\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_costarica_1, y_costarica_1, train_size=0.75, test_size=.25, random_state=0)\n",
    "\n",
    "# log-uniform: understand as search over p = exp(x) by varying x\n",
    "opt_Ridge = BayesSearchCV(\n",
    "    Ridge(),\n",
    "    {\n",
    "        'alpha': (1.0, 0.1, 0.01, 0.001),\n",
    "        'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "        'max_iter': (1000, 10000, 100000, 1000000),\n",
    "        #'tol:' : (1e-6, 1e-3, 1e+1),\n",
    "        #'n_estimators': (100, 1000),\n",
    "\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "opt_Ridge.fit(X_train, y_train)\n",
    "\n",
    "print('Ridge')\n",
    "print(\"val. score: %s\" % opt_Ridge.best_score_)\n",
    "print(\"test score: %s\" % opt_Ridge.score(X_test, y_test))\n",
    "print(\"best parameters: %s\" % str(opt_Ridge.best_params_))\n",
    "print('---------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen del regresor Ridge\n",
      "\n",
      "Residuals:\n",
      "    Min     1Q  Median      3Q     Max\n",
      "11.4285 11.794 11.9451 12.2435 12.7967\n",
      "\n",
      "\n",
      "Coefficients:\n",
      "                      Estimate    t value   p value\n",
      "_intercept           11.469816   0.000000  0.999990\n",
      "Age                   0.002211   1.522572  0.128042\n",
      "Sex                  -0.174254   3.087000  0.002054\n",
      "Diabetes              0.080067   1.257600  0.208712\n",
      "Education             0.391147  12.118600  0.000000\n",
      "Live Alone           -0.135211   1.416900  0.156676\n",
      "Hypertension          0.045561   0.934000  0.350426\n",
      "Heart Disease        -0.102902   0.740800  0.458895\n",
      "Alcohol consumption  -0.033660   0.793000  0.427902\n",
      "Physical activity    -0.020888   0.381000  0.703281\n",
      "Smoking status        0.037334   0.692900  0.488446\n",
      "Falls                 0.000000   0.000000  1.000000\n",
      "Mental Problems       0.127929   2.184700  0.029040\n",
      "---\n",
      "R-squared:  0.08766,    Adjusted R-squared:  0.08136\n",
      "F-squared:  0.09608\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelRidge_costarica_1 = Ridge(alpha=opt_Ridge.best_params_['alpha'], solver = opt_Ridge.best_params_['solver'], \n",
    "                         max_iter=opt_Ridge.best_params_['max_iter'])\n",
    "modelRidge_costarica_1.fit(X_costarica_1, y_costarica_1)\n",
    "\n",
    "parameter_dict['costarica_wave_1'] = opt_Ridge.best_params_\n",
    "\n",
    "modelRidge_sum_costarica_1 = summary(modelRidge_costarica_1, X_costarica_1, y_costarica_1, X_costarica_1.columns, 'Ridge')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costa Rica wave 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_costarica_2 = X_costarica_w2['MMSE']\n",
    "X_costarica_2 = X_costarica_w2.drop(['MMSE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge\n",
      "val. score: 0.07198211461795201\n",
      "test score: 0.09786400640076154\n",
      "best parameters: OrderedDict([('alpha', 1.0), ('max_iter', 1000), ('solver', 'svd')])\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_costarica_2, y_costarica_2, train_size=0.75, test_size=.25, random_state=0)\n",
    "\n",
    "# log-uniform: understand as search over p = exp(x) by varying x\n",
    "opt_Ridge = BayesSearchCV(\n",
    "    Ridge(),\n",
    "    {\n",
    "        'alpha': (1.0, 0.1, 0.01, 0.001),\n",
    "        'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "        'max_iter': (1000, 10000, 100000, 1000000),\n",
    "        #'tol:' : (1e-6, 1e-3, 1e+1),\n",
    "        #'n_estimators': (100, 1000),\n",
    "\n",
    "    },\n",
    "    n_iter=10,\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "opt_Ridge.fit(X_train, y_train)\n",
    "\n",
    "print('Ridge')\n",
    "print(\"val. score: %s\" % opt_Ridge.best_score_)\n",
    "print(\"test score: %s\" % opt_Ridge.score(X_test, y_test))\n",
    "print(\"best parameters: %s\" % str(opt_Ridge.best_params_))\n",
    "print('---------------------------------------------\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen del regresor Ridge\n",
      "\n",
      "Residuals:\n",
      "    Min     1Q  Median     3Q   Max\n",
      "-1.9954 -0.789 -0.2779 0.6224 9.948\n",
      "\n",
      "\n",
      "Coefficients:\n",
      "                      Estimate    t value   p value\n",
      "_intercept           11.787070   0.000000  0.999992\n",
      "Age                  -0.023115  11.142468  0.000000\n",
      "Sex                  -0.315532   4.506800  0.000007\n",
      "Diabetes              0.123090   1.558700  0.119238\n",
      "Education             0.509850  12.735900  0.000000\n",
      "Live Alone           -0.154121   1.302200  0.193021\n",
      "Hypertension         -0.003576   0.059100  0.952879\n",
      "Heart Disease        -0.175377   1.018000  0.308837\n",
      "Alcohol consumption  -0.059209   1.124600  0.260910\n",
      "Physical activity    -0.019755   0.290500  0.771484\n",
      "Smoking status        0.077234   1.155800  0.247936\n",
      "Falls                 0.000000   0.000000  1.000000\n",
      "Mental Problems       0.178755   2.461300  0.013940\n",
      "---\n",
      "R-squared:  0.10557,    Adjusted R-squared:  0.09939\n",
      "F-squared:  0.11802\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelRidge_costarica_2 = Ridge(alpha=opt_Ridge.best_params_['alpha'], solver = opt_Ridge.best_params_['solver'], \n",
    "                         max_iter=opt_Ridge.best_params_['max_iter'])\n",
    "modelRidge_costarica_2.fit(X_costarica_2, y_costarica_2)\n",
    "\n",
    "parameter_dict['costarica_wave_2'] = opt_Ridge.best_params_\n",
    "\n",
    "modelRidge_sum_costarica_2 = summary(modelRidge_costarica_2, X_costarica_2, y_costarica_2, X_costarica_2.columns, 'Ridge')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistically significant variables in both Costa Rica wave 2 and Korea 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = get_order_var(modelRidge_sum_costarica_2)\n",
    "df = modelRidge_sum_costarica_2\n",
    "\n",
    "feature_sign = []\n",
    "\n",
    "for i in col:\n",
    "    if df[0]['p value'][i] < 0.05:\n",
    "        feature_sign.append(i)\n",
    "\n",
    "\n",
    "df = modelRidge_sum_korea_2006_2016\n",
    "\n",
    "for i in col:\n",
    "    if df[0]['p value'][i] < 0.05 and i not in feature_sign:\n",
    "        feature_sign.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Education', 'Sex', 'Mental Problems', 'Age', 'Physical activity']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking de variables significativas Costa Rica wave 2\n",
      "                   Estimate\n",
      "Features                   \n",
      "Education          0.509850\n",
      "Sex                0.315532\n",
      "Mental Problems    0.178755\n",
      "Age                0.023115\n",
      "Physical activity  0.019755\n",
      "\n",
      "\n",
      "Ranking de variables significativas Korea 2016\n",
      "                   Estimate\n",
      "Features                   \n",
      "Education          0.728242\n",
      "Mental Problems    0.638267\n",
      "Sex                0.552568\n",
      "Physical activity  0.305520\n",
      "Age                0.142852\n"
     ]
    }
   ],
   "source": [
    "## Costa Rica\n",
    "\n",
    "df_costarica_w2 = modelRidge_sum_costarica_2[0].copy()\n",
    "\n",
    "df_costarica_w2.index.name = 'Features'\n",
    "df_costarica_w2 = df_costarica_w2.iloc[1:-3, 0:-1]\n",
    "\n",
    "df_costarica_w2 = df_costarica_w2.loc[feature_sign, :]\n",
    "\n",
    "for i in range(3):\n",
    "    df_costarica_w2[df_costarica_w2.columns[i]] = np.abs(pd.to_numeric(df_costarica_w2[df_costarica_w2.columns[i]],errors = 'coerce'))\n",
    "\n",
    "df = df_costarica_w2.reset_index()\n",
    "data_costarica_w2 = df_costarica_w2.sort_values('Estimate', ascending=False)\n",
    "\n",
    "print('Ranking de variables significativas Costa Rica wave 2')\n",
    "print(pd.DataFrame(data_costarica_w2['Estimate']))\n",
    "\n",
    "## Korea\n",
    "\n",
    "df_korea_2016 = modelRidge_sum_korea_2006_2016[0].copy()\n",
    "\n",
    "df_korea_2016.index.name = 'Features'\n",
    "df_korea_2016 = df_korea_2016.iloc[1:-3, 0:-1]\n",
    "\n",
    "df_korea_2016 = df_korea_2016.loc[feature_sign, :]\n",
    "\n",
    "for i in range(3):\n",
    "    df_korea_2016[df_korea_2016.columns[i]] = np.abs(pd.to_numeric(df_korea_2016[df_korea_2016.columns[i]],errors = 'coerce'))\n",
    "\n",
    "df = df_korea_2016.reset_index()\n",
    "data_korea_2016 = df_korea_2016.sort_values('Estimate', ascending=False)\n",
    "\n",
    "print('\\n\\nRanking de variables significativas Korea 2016')\n",
    "print(pd.DataFrame(data_korea_2016['Estimate']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-test for Coefficients between Costa Rica wave 2 and Korea 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_dict = {}\n",
    "for i in feature_sign:\n",
    "\n",
    "    beta_dict['CR_' + i] = []\n",
    "    beta_dict['KO_' + i] = []\n",
    "\n",
    "\n",
    "y_database = X_costarica_w2['MMSE']\n",
    "X_database = X_costarica_w2.drop('MMSE', axis=1)\n",
    "X_database = X_database[feature_sign]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,100,10):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_database, y_database, train_size=0.75, test_size=.25, random_state=i)\n",
    "\n",
    "    opt_Ridge = BayesSearchCV(\n",
    "            Ridge(),\n",
    "            {\n",
    "                'alpha': ( 0.0001, 0.01, 0.001),\n",
    "                'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "                'max_iter': (1000, 10000, 100000, 1000000),\n",
    "            },\n",
    "            n_iter=10,\n",
    "            random_state=i, \n",
    "            scoring='r2',\n",
    "            cv=3\n",
    "        )\n",
    "\n",
    "    opt_Ridge.fit(X_train, y_train)\n",
    "    \n",
    "    ## Acá uso el modelo Ridge con los parámetros entregadps por el optimizacion bayesiano porque el BayesSearch no me entrega los Beta values.\n",
    "\n",
    "    model = Ridge(alpha=opt_Ridge.best_params_['alpha'], solver = opt_Ridge.best_params_['solver'], \n",
    "                             max_iter=opt_Ridge.best_params_['max_iter'])\n",
    "    \n",
    "    model.fit(X_test, y_test)\n",
    "    \n",
    "    # Esta parte la ahago así para ser consecuente con la forma que he ido guardando los resultados y que me sirvan las mismas funciones que ya tengo diseñadas (en caso de necesitarlas)\n",
    "    coef_df = pd.DataFrame(\n",
    "        index=['_intercept'] + list(X_test.columns),\n",
    "        columns=['Estimate']\n",
    "        )\n",
    "\n",
    "    coef_df['Estimate'] = np.concatenate((np.round(np.array([model.intercept_]), 12), np.round((model.coef_), 12)))\n",
    "\n",
    "    #Acá guardo los beta values de las variables elegidas\n",
    "    for j in feature_sign:\n",
    "        beta_dict['CR_' + j].append(np.abs(coef_df['Estimate'][j])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_database = X_korea_2006_2016_common_ids['MMSE']\n",
    "X_database = X_korea_2006_2016_common_ids.drop('MMSE', axis=1)\n",
    "X_database = X_database[feature_sign]\n",
    "\n",
    "for i in range(0,100,10):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_database, y_database, train_size=0.75, test_size=.25, random_state=i)\n",
    "\n",
    "    opt_Ridge = BayesSearchCV(\n",
    "            Ridge(),\n",
    "            {\n",
    "                'alpha': ( 0.0001, 0.01, 0.001),\n",
    "                'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "                'max_iter': (1000, 10000, 100000, 1000000),\n",
    "            },\n",
    "            n_iter=10,\n",
    "            random_state=i, \n",
    "            scoring='r2',\n",
    "            cv=3\n",
    "        )\n",
    "\n",
    "    opt_Ridge.fit(X_train, y_train)\n",
    "    \n",
    "    ## Acá uso el modelo Ridge con los parámetros entregadps por el optimizacion bayesiano porque el BayesSearch no me entrega los Beta values.\n",
    "    model = Ridge(alpha=opt_Ridge.best_params_['alpha'], solver = opt_Ridge.best_params_['solver'], \n",
    "                             max_iter=opt_Ridge.best_params_['max_iter'])\n",
    "    \n",
    "    model.fit(X_test, y_test)\n",
    "    \n",
    "    # Esta parte la ahago así para ser consecuente con la forma que he ido guardando los resultados y que me sirvan las mismas funciones que ya tengo diseñadas (en caso de necesitarlas)\n",
    "    coef_df = pd.DataFrame(\n",
    "        index=['_intercept'] + list(X_test.columns),\n",
    "        columns=['Estimate']\n",
    "        )\n",
    "\n",
    "    coef_df['Estimate'] = np.concatenate((np.round(np.array([model.intercept_]), 12), np.round((model.coef_), 12)))\n",
    "\n",
    "    #Acá guardo los beta values de las variables elegidas\n",
    "    for j in feature_sign:\n",
    "        beta_dict['KO_'+ j].append(np.abs(coef_df['Estimate'][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_df = pd.DataFrame(beta_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelo/anaconda3/envs/HBL/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:7: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n",
      "/home/marcelo/anaconda3/envs/HBL/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:7: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import statsmodels.api\n",
    "\n",
    "result_scipy_df = pd.DataFrame(\n",
    "        index=['p value'] ,\n",
    "        columns=feature_sign\n",
    "        )\n",
    "\n",
    "result_stats_df = pd.DataFrame(\n",
    "        index=['p value'] ,\n",
    "        columns=feature_sign\n",
    "        )\n",
    "\n",
    "for i in feature_sign:\n",
    "    result_scipy_df[i] = stats.ttest_ind(beta_dict['CR_'+ i], beta_dict['KO_' + i], equal_var=False)[1]\n",
    "    result_stats_df[i] = statsmodels.stats.weightstats.ttest_ind(beta_dict['CR_'+ i], beta_dict['KO_' + i], alternative=\"two-sided\",usevar=\"unequal\")[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-6cc8d65d88a7>:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  beta_df_stat = beta_df_stat.append(beta_df_stat.iloc[1,:]*1.95,ignore_index=True)\n",
      "<ipython-input-51-6cc8d65d88a7>:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  beta_df_stat = beta_df_stat.append(beta_df_stat.iloc[1,:]*2.58,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "beta_df_stat = beta_df.describe().round(3).iloc[1:3,:]\n",
    "beta_df_stat = beta_df_stat.append(beta_df_stat.iloc[1,:]*1.95,ignore_index=True)\n",
    "beta_df_stat = beta_df_stat.append(beta_df_stat.iloc[1,:]*2.58,ignore_index=True)\n",
    "\n",
    "beta_df_stat = beta_df_stat.rename(index={0:'mean', 1:'std', 2:'95', 3:'99'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sign_order = ['Education', 'Sex', 'Age', 'Physical activity', 'Mental Problems']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CR_mean</th>\n",
       "      <th>CR_std</th>\n",
       "      <th>KO_mean</th>\n",
       "      <th>KO_std</th>\n",
       "      <th>ttest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physical activity</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mental Problems</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  CR_mean CR_std KO_mean KO_std ttest\n",
       "Education            0.53   0.08    0.63   0.14  0.08\n",
       "Sex                  0.46   0.07    0.49   0.14  0.47\n",
       "Age                  0.02   0.02    0.15   0.01   0.0\n",
       "Physical activity    0.16   0.08    0.32   0.17  0.02\n",
       "Mental Problems      0.16   0.13     0.4   0.42  0.12"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_result_df = pd.DataFrame(\n",
    "        index=feature_sign_order ,\n",
    "        columns=['CR_mean', 'CR_std','KO_mean','KO_std', 'ttest']\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "count = 0\n",
    "for i in feature_sign_order:\n",
    "    general_result_df.iloc[count, 0] = np.round(beta_df_stat['CR_' + i][0],2)\n",
    "    general_result_df.iloc[count, 1] = np.round(beta_df_stat['CR_' + i][1],2)\n",
    "    \n",
    "    general_result_df.iloc[count, 2] = np.round(beta_df_stat['KO_' + i][0],2)\n",
    "    general_result_df.iloc[count, 3] = np.round(beta_df_stat['KO_' + i][1],2)\n",
    "    \n",
    "    general_result_df.iloc[count, 4] = np.round(result_stats_df[i][0],2)\n",
    "    \n",
    "    count +=1\n",
    "    \n",
    "general_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_values_ttest(modelRidge_sum_model1, modelRidge_sum_model2, X_1, X_2, only_significance = False):\n",
    "    col = get_order_var(modelRidge_sum_model1)\n",
    "    df = modelRidge_sum_model1\n",
    "\n",
    "    feature_sign = []\n",
    "\n",
    "    for i in col:\n",
    "        if df[0]['p value'][i] < 0.05:\n",
    "            feature_sign.append(i)\n",
    "\n",
    "\n",
    "    df = modelRidge_sum_model2\n",
    "\n",
    "    for i in col:\n",
    "        if df[0]['p value'][i] < 0.05 and i not in feature_sign:\n",
    "            feature_sign.append(i)\n",
    "\n",
    "\n",
    "    beta_dict = {}\n",
    "    for i in feature_sign:\n",
    "\n",
    "        beta_dict['CR_' + i] = []\n",
    "        beta_dict['KO_' + i] = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    y_database = X_1['MMSE']\n",
    "    X_database = X_1.drop('MMSE', axis=1)\n",
    "    \n",
    "    if(only_significance):\n",
    "        X_database = X_database[feature_sign]\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(0,100,10):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_database, y_database, train_size=0.75, test_size=.25, random_state=i)\n",
    "\n",
    "        opt_Ridge = BayesSearchCV(\n",
    "                Ridge(),\n",
    "                {\n",
    "                    'alpha': ( 0.0001, 0.01, 0.001),\n",
    "                    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "                    'max_iter': (1000, 10000, 100000, 1000000),\n",
    "                },\n",
    "                n_iter=10,\n",
    "                random_state=i, \n",
    "                scoring='r2',\n",
    "                cv=3\n",
    "            )\n",
    "\n",
    "        opt_Ridge.fit(X_train, y_train)\n",
    "\n",
    "        ## Acá uso el modelo Ridge con los parámetros entregadps por el optimizacion bayesiano porque el BayesSearch no me entrega los Beta values.\n",
    "\n",
    "        model = Ridge(alpha=opt_Ridge.best_params_['alpha'], solver = opt_Ridge.best_params_['solver'], \n",
    "                                 max_iter=opt_Ridge.best_params_['max_iter'])\n",
    "\n",
    "        model.fit(X_test, y_test)\n",
    "\n",
    "        # Esta parte la ahago así para ser consecuente con la forma que he ido guardando los resultados y que me sirvan las mismas funciones que ya tengo diseñadas (en caso de necesitarlas)\n",
    "        coef_df = pd.DataFrame(\n",
    "            index=['_intercept'] + list(X_test.columns),\n",
    "            columns=['Estimate']\n",
    "            )\n",
    "\n",
    "        coef_df['Estimate'] = np.concatenate((np.round(np.array([model.intercept_]), 12), np.round((model.coef_), 12)))\n",
    "\n",
    "        #Acá guardo los beta values de las variables elegidas\n",
    "        for j in feature_sign:\n",
    "            beta_dict['CR_' + j].append(np.abs(coef_df['Estimate'][j])) \n",
    "\n",
    "\n",
    "    y_database = X_2['MMSE']\n",
    "    X_database = X_2.drop('MMSE', axis=1)\n",
    "    if(only_significance):\n",
    "        X_database = X_database[feature_sign]\n",
    "\n",
    "    for i in range(0,100,10):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_database, y_database, train_size=0.75, test_size=.25, random_state=i)\n",
    "\n",
    "        opt_Ridge = BayesSearchCV(\n",
    "                Ridge(),\n",
    "                {\n",
    "                    'alpha': ( 0.0001, 0.01, 0.001),\n",
    "                    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "                    'max_iter': (1000, 10000, 100000, 1000000),\n",
    "                },\n",
    "                n_iter=10,\n",
    "                random_state=i, \n",
    "                scoring='r2',\n",
    "                cv=3\n",
    "            )\n",
    "\n",
    "        opt_Ridge.fit(X_train, y_train)\n",
    "\n",
    "        ## Acá uso el modelo Ridge con los parámetros entregadps por el optimizacion bayesiano porque el BayesSearch no me entrega los Beta values.\n",
    "        model = Ridge(alpha=opt_Ridge.best_params_['alpha'], solver = opt_Ridge.best_params_['solver'], \n",
    "                                 max_iter=opt_Ridge.best_params_['max_iter'])\n",
    "\n",
    "        model.fit(X_test, y_test)\n",
    "\n",
    "        # Esta parte la ahago así para ser consecuente con la forma que he ido guardando los resultados y que me sirvan las mismas funciones que ya tengo diseñadas (en caso de necesitarlas)\n",
    "        coef_df = pd.DataFrame(\n",
    "            index=['_intercept'] + list(X_test.columns),\n",
    "            columns=['Estimate']\n",
    "            )\n",
    "\n",
    "        coef_df['Estimate'] = np.concatenate((np.round(np.array([model.intercept_]), 12), np.round((model.coef_), 12)))\n",
    "\n",
    "        #Acá guardo los beta values de las variables elegidas\n",
    "        for j in feature_sign:\n",
    "            beta_dict['KO_'+ j].append(np.abs(coef_df['Estimate'][j]))\n",
    "\n",
    "    beta_df = pd.DataFrame(beta_dict)\n",
    "\n",
    "\n",
    "    from scipy import stats\n",
    "    import statsmodels.api\n",
    "\n",
    "    result_scipy_df = pd.DataFrame(\n",
    "            index=['p value'] ,\n",
    "            columns=feature_sign\n",
    "            )\n",
    "\n",
    "    result_stats_df = pd.DataFrame(\n",
    "            index=['p value'] ,\n",
    "            columns=feature_sign\n",
    "            )\n",
    "\n",
    "    for i in feature_sign:\n",
    "        result_scipy_df[i] = stats.ttest_ind(beta_dict['CR_'+ i], beta_dict['KO_' + i], equal_var=False)[1]\n",
    "        result_stats_df[i] = statsmodels.stats.weightstats.ttest_ind(beta_dict['CR_'+ i], beta_dict['KO_' + i], alternative=\"two-sided\",usevar=\"unequal\")[1]\n",
    "\n",
    "\n",
    "    beta_df_stat = beta_df.describe().round(3).iloc[1:3,:]\n",
    "    beta_df_stat = beta_df_stat.append(beta_df_stat.iloc[1,:]*1.95,ignore_index=True)\n",
    "    beta_df_stat = beta_df_stat.append(beta_df_stat.iloc[1,:]*2.58,ignore_index=True)\n",
    "\n",
    "    beta_df_stat = beta_df_stat.rename(index={0:'mean', 1:'std', 2:'95', 3:'99'})\n",
    "    beta_df_stat.round(3)\n",
    "\n",
    "\n",
    "    general_result_df = pd.DataFrame(\n",
    "            index=feature_sign,\n",
    "            columns=['CR_mean', 'CR_std','KO_mean','KO_std', 'ttest']\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "    count = 0\n",
    "    for i in feature_sign_order:\n",
    "        general_result_df.iloc[count, 0] = np.round(beta_df_stat['CR_' + i][0],2)\n",
    "        general_result_df.iloc[count, 1] = np.round(beta_df_stat['CR_' + i][1],2)\n",
    "\n",
    "        general_result_df.iloc[count, 2] = np.round(beta_df_stat['KO_' + i][0],2)\n",
    "        general_result_df.iloc[count, 3] = np.round(beta_df_stat['KO_' + i][1],2)\n",
    "\n",
    "        general_result_df.iloc[count, 4] = np.round(result_stats_df[i][0],2)\n",
    "\n",
    "        count +=1\n",
    "\n",
    "    return general_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-54-cecd386dcc2b>:139: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  beta_df_stat = beta_df_stat.append(beta_df_stat.iloc[1,:]*1.95,ignore_index=True)\n",
      "<ipython-input-54-cecd386dcc2b>:140: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  beta_df_stat = beta_df_stat.append(beta_df_stat.iloc[1,:]*2.58,ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CR_mean</th>\n",
       "      <th>CR_std</th>\n",
       "      <th>KO_mean</th>\n",
       "      <th>KO_std</th>\n",
       "      <th>ttest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mental Problems</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physical activity</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  CR_mean CR_std KO_mean KO_std ttest\n",
       "Education            0.53   0.08    0.63   0.14  0.08\n",
       "Sex                  0.46   0.07    0.49   0.14  0.47\n",
       "Mental Problems      0.02   0.02    0.15   0.01   0.0\n",
       "Age                  0.16   0.08    0.32   0.17  0.02\n",
       "Physical activity    0.16   0.13     0.4   0.42  0.12"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Coef_t_test =beta_values_ttest(modelRidge_sum_costarica_2, modelRidge_sum_korea_2006_2016, X_costarica_w2, X_korea_2006_2016_common_ids, True)\n",
    "Coef_t_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F-statisitcs, F-pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Korea 2006</th>\n",
       "      <td>[115.71394309889916, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Korea 2006-2014</th>\n",
       "      <td>[133.3507050306133, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Korea 2006-2016</th>\n",
       "      <td>[144.6961712048959, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Costa Rica wave 1</th>\n",
       "      <td>[13.915203028954092, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Costa Rica wave 2</th>\n",
       "      <td>[17.09388472878028, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      F-statisitcs, F-pvalue\n",
       "Korea 2006         [115.71394309889916, 0.0]\n",
       "Korea 2006-2014     [133.3507050306133, 0.0]\n",
       "Korea 2006-2016     [144.6961712048959, 0.0]\n",
       "Costa Rica wave 1  [13.915203028954092, 0.0]\n",
       "Costa Rica wave 2   [17.09388472878028, 0.0]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f_stat(clf, X, y):\n",
    "    \"\"\"Calculate summary F-statistic for beta coefficients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The F-statistic value.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    r_squared = metrics.r2_score(y, clf.predict(X))\n",
    "    return (r_squared / p) / ((1 - r_squared) / (n - p - 1))\n",
    "\n",
    "\n",
    "def f_stat_pvalue(clf, X, y):\n",
    "    \"\"\"Calculate summary F-statistic p value for beta coefficients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The F-statistic p value.\n",
    "    \"\"\"\n",
    "    n = X.shape[0] # Esto se extrae par los grados de libertad del numeador y el denomindor (no. predictores, no. sujetos - no. predictores-1)\n",
    "    p = X.shape[1]\n",
    "    r_squared = metrics.r2_score(y, clf.predict(X))\n",
    "    \n",
    "    return np.round(scipy.stats.f.sf(f_stat(clf, X, y), n, (n - p - 1)), 15)\n",
    "\n",
    "def compute_f_statistics(clf, X, y):\n",
    "    return [f_stat(clf, X, y), f_stat_pvalue(clf, X, y)]\n",
    "\n",
    "F_statistics = {}\n",
    "\n",
    "F_statistics['Korea 2006'] = [compute_f_statistics(modelRidge_korea_2006, X_korea_2006, y_korea_2006)]\n",
    "F_statistics['Korea 2006-2014'] = [compute_f_statistics(modelRidge_korea_2006_2014, X_korea_2006_2014, y_korea_2006_2014)]\n",
    "F_statistics['Korea 2006-2016'] = [compute_f_statistics(modelRidge_korea_2006_2016, X_korea_2006_2016, y_korea_2006_2016)]\n",
    "\n",
    "\n",
    "F_statistics['Costa Rica wave 1'] = [compute_f_statistics(modelRidge_costarica_1, X_costarica_1, y_costarica_1)]\n",
    "F_statistics['Costa Rica wave 2'] = [compute_f_statistics(modelRidge_costarica_2, X_costarica_2, y_costarica_2)]\n",
    "\n",
    "\n",
    "F_statistics_pd = pd.DataFrame(F_statistics, index = ['F-statisitcs, F-pvalue']).T\n",
    "F_statistics_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sumamry Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korea 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "      <th>t value</th>\n",
       "      <th>p value</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_intercept</th>\n",
       "      <td>15.274409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999971</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.062307</td>\n",
       "      <td>83.8701</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>-0.292865</td>\n",
       "      <td>5.0816</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetes</th>\n",
       "      <td>0.132756</td>\n",
       "      <td>1.7673</td>\n",
       "      <td>0.077266</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.440133</td>\n",
       "      <td>12.1468</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Live Alone</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertension</th>\n",
       "      <td>0.111018</td>\n",
       "      <td>2.1401</td>\n",
       "      <td>0.032411</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heart Disease</th>\n",
       "      <td>-0.006217</td>\n",
       "      <td>0.0585</td>\n",
       "      <td>0.953361</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol consumption</th>\n",
       "      <td>-0.060297</td>\n",
       "      <td>1.8918</td>\n",
       "      <td>0.058596</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physical activity</th>\n",
       "      <td>-0.252662</td>\n",
       "      <td>5.5396</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoking status</th>\n",
       "      <td>-0.02147</td>\n",
       "      <td>0.3451</td>\n",
       "      <td>0.730043</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Falls</th>\n",
       "      <td>0.035277</td>\n",
       "      <td>0.3079</td>\n",
       "      <td>0.758177</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mental Problems</th>\n",
       "      <td>0.072102</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.645554</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.279921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adjusted R-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.277502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.388737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Estimate  t value   p value     value\n",
       "_intercept           15.274409      0.0  0.999971          \n",
       "Age                  -0.062307  83.8701       0.0          \n",
       "Sex                  -0.292865   5.0816       0.0          \n",
       "Diabetes              0.132756   1.7673  0.077266          \n",
       "Education             0.440133  12.1468       0.0          \n",
       "Live Alone                -0.0      0.0       1.0          \n",
       "Hypertension          0.111018   2.1401  0.032411          \n",
       "Heart Disease        -0.006217   0.0585  0.953361          \n",
       "Alcohol consumption  -0.060297   1.8918  0.058596          \n",
       "Physical activity    -0.252662   5.5396       0.0          \n",
       "Smoking status        -0.02147   0.3451  0.730043          \n",
       "Falls                 0.035277   0.3079  0.758177          \n",
       "Mental Problems       0.072102     0.46  0.645554          \n",
       "R-squared                                          0.279921\n",
       "Adjusted R-squared                                 0.277502\n",
       "F-squared                                          0.388737"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRidge_sum_korea_2006[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F-statisitcs, F-pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Korea 2006</th>\n",
       "      <td>[115.71394309889916, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               F-statisitcs, F-pvalue\n",
       "Korea 2006  [115.71394309889916, 0.0]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_statistics_pd.iloc[0:1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korea 2006 - 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "      <th>t value</th>\n",
       "      <th>p value</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_intercept</th>\n",
       "      <td>16.638637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999982</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.124376</td>\n",
       "      <td>94.090762</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>-0.613927</td>\n",
       "      <td>6.1819</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetes</th>\n",
       "      <td>0.217922</td>\n",
       "      <td>1.6836</td>\n",
       "      <td>0.092355</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.695698</td>\n",
       "      <td>11.1412</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Live Alone</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertension</th>\n",
       "      <td>0.085979</td>\n",
       "      <td>0.9619</td>\n",
       "      <td>0.336189</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heart Disease</th>\n",
       "      <td>0.083298</td>\n",
       "      <td>0.4548</td>\n",
       "      <td>0.649279</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol consumption</th>\n",
       "      <td>-0.018425</td>\n",
       "      <td>0.3355</td>\n",
       "      <td>0.737282</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physical activity</th>\n",
       "      <td>-0.34077</td>\n",
       "      <td>4.3359</td>\n",
       "      <td>0.000015</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoking status</th>\n",
       "      <td>0.12841</td>\n",
       "      <td>1.1978</td>\n",
       "      <td>0.231073</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Falls</th>\n",
       "      <td>-0.077588</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.694359</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mental Problems</th>\n",
       "      <td>0.257884</td>\n",
       "      <td>0.9547</td>\n",
       "      <td>0.339771</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.309386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adjusted R-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.307066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.447987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Estimate    t value   p value     value\n",
       "_intercept           16.638637        0.0  0.999982          \n",
       "Age                  -0.124376  94.090762       0.0          \n",
       "Sex                  -0.613927     6.1819       0.0          \n",
       "Diabetes              0.217922     1.6836  0.092355          \n",
       "Education             0.695698    11.1412       0.0          \n",
       "Live Alone                 0.0        0.0       1.0          \n",
       "Hypertension          0.085979     0.9619  0.336189          \n",
       "Heart Disease         0.083298     0.4548  0.649279          \n",
       "Alcohol consumption  -0.018425     0.3355  0.737282          \n",
       "Physical activity     -0.34077     4.3359  0.000015          \n",
       "Smoking status         0.12841     1.1978  0.231073          \n",
       "Falls                -0.077588      0.393  0.694359          \n",
       "Mental Problems       0.257884     0.9547  0.339771          \n",
       "R-squared                                            0.309386\n",
       "Adjusted R-squared                                   0.307066\n",
       "F-squared                                            0.447987"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRidge_sum_korea_2006_2014[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F-statisitcs, F-pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Korea 2006-2014</th>\n",
       "      <td>[133.3507050306133, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   F-statisitcs, F-pvalue\n",
       "Korea 2006-2014  [133.3507050306133, 0.0]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_statistics_pd.iloc[1:2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korea 2006 - 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "      <th>t value</th>\n",
       "      <th>p value</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_intercept</th>\n",
       "      <td>17.111794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999982</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.142852</td>\n",
       "      <td>157.46363</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>-0.552568</td>\n",
       "      <td>5.3043</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetes</th>\n",
       "      <td>0.102014</td>\n",
       "      <td>0.7513</td>\n",
       "      <td>0.452512</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.728242</td>\n",
       "      <td>11.1194</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Live Alone</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertension</th>\n",
       "      <td>-0.089467</td>\n",
       "      <td>0.9542</td>\n",
       "      <td>0.340062</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heart Disease</th>\n",
       "      <td>0.277857</td>\n",
       "      <td>1.4463</td>\n",
       "      <td>0.148181</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol consumption</th>\n",
       "      <td>-0.08192</td>\n",
       "      <td>1.422</td>\n",
       "      <td>0.155124</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physical activity</th>\n",
       "      <td>-0.30552</td>\n",
       "      <td>3.7059</td>\n",
       "      <td>0.000214</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoking status</th>\n",
       "      <td>0.074637</td>\n",
       "      <td>0.6637</td>\n",
       "      <td>0.506924</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Falls</th>\n",
       "      <td>-0.212129</td>\n",
       "      <td>1.0243</td>\n",
       "      <td>0.305769</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mental Problems</th>\n",
       "      <td>0.638267</td>\n",
       "      <td>2.2527</td>\n",
       "      <td>0.024336</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.327098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adjusted R-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.324838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.486101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Estimate    t value   p value     value\n",
       "_intercept           17.111794        0.0  0.999982          \n",
       "Age                  -0.142852  157.46363       0.0          \n",
       "Sex                  -0.552568     5.3043       0.0          \n",
       "Diabetes              0.102014     0.7513  0.452512          \n",
       "Education             0.728242    11.1194       0.0          \n",
       "Live Alone                 0.0        0.0       1.0          \n",
       "Hypertension         -0.089467     0.9542  0.340062          \n",
       "Heart Disease         0.277857     1.4463  0.148181          \n",
       "Alcohol consumption   -0.08192      1.422  0.155124          \n",
       "Physical activity     -0.30552     3.7059  0.000214          \n",
       "Smoking status        0.074637     0.6637  0.506924          \n",
       "Falls                -0.212129     1.0243  0.305769          \n",
       "Mental Problems       0.638267     2.2527  0.024336          \n",
       "R-squared                                            0.327098\n",
       "Adjusted R-squared                                   0.324838\n",
       "F-squared                                            0.486101"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRidge_sum_korea_2006_2016[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F-statisitcs, F-pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Korea 2006-2016</th>\n",
       "      <td>[144.6961712048959, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   F-statisitcs, F-pvalue\n",
       "Korea 2006-2016  [144.6961712048959, 0.0]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_statistics_pd.iloc[2:3,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costa Rica wave 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "      <th>t value</th>\n",
       "      <th>p value</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_intercept</th>\n",
       "      <td>11.469816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99999</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.002211</td>\n",
       "      <td>1.522572</td>\n",
       "      <td>0.128042</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>-0.174254</td>\n",
       "      <td>3.087</td>\n",
       "      <td>0.002054</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetes</th>\n",
       "      <td>0.080067</td>\n",
       "      <td>1.2576</td>\n",
       "      <td>0.208712</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.391147</td>\n",
       "      <td>12.1186</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Live Alone</th>\n",
       "      <td>-0.135211</td>\n",
       "      <td>1.4169</td>\n",
       "      <td>0.156676</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertension</th>\n",
       "      <td>0.045561</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.350426</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heart Disease</th>\n",
       "      <td>-0.102902</td>\n",
       "      <td>0.7408</td>\n",
       "      <td>0.458895</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol consumption</th>\n",
       "      <td>-0.03366</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.427902</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physical activity</th>\n",
       "      <td>-0.020888</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.703281</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoking status</th>\n",
       "      <td>0.037334</td>\n",
       "      <td>0.6929</td>\n",
       "      <td>0.488446</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Falls</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mental Problems</th>\n",
       "      <td>0.127929</td>\n",
       "      <td>2.1847</td>\n",
       "      <td>0.02904</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.087656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adjusted R-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.081356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.096077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Estimate   t value   p value     value\n",
       "_intercept           11.469816       0.0   0.99999          \n",
       "Age                   0.002211  1.522572  0.128042          \n",
       "Sex                  -0.174254     3.087  0.002054          \n",
       "Diabetes              0.080067    1.2576  0.208712          \n",
       "Education             0.391147   12.1186       0.0          \n",
       "Live Alone           -0.135211    1.4169  0.156676          \n",
       "Hypertension          0.045561     0.934  0.350426          \n",
       "Heart Disease        -0.102902    0.7408  0.458895          \n",
       "Alcohol consumption   -0.03366     0.793  0.427902          \n",
       "Physical activity    -0.020888     0.381  0.703281          \n",
       "Smoking status        0.037334    0.6929  0.488446          \n",
       "Falls                      0.0       0.0       1.0          \n",
       "Mental Problems       0.127929    2.1847   0.02904          \n",
       "R-squared                                           0.087656\n",
       "Adjusted R-squared                                  0.081356\n",
       "F-squared                                           0.096077"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRidge_sum_costarica_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F-statisitcs, F-pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Costa Rica wave 1</th>\n",
       "      <td>[13.915203028954092, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      F-statisitcs, F-pvalue\n",
       "Costa Rica wave 1  [13.915203028954092, 0.0]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_statistics_pd.iloc[3:4,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costa Rica wave 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "      <th>t value</th>\n",
       "      <th>p value</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_intercept</th>\n",
       "      <td>11.78707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999992</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.023115</td>\n",
       "      <td>11.142468</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>-0.315532</td>\n",
       "      <td>4.5068</td>\n",
       "      <td>0.000007</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetes</th>\n",
       "      <td>0.12309</td>\n",
       "      <td>1.5587</td>\n",
       "      <td>0.119238</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.50985</td>\n",
       "      <td>12.7359</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Live Alone</th>\n",
       "      <td>-0.154121</td>\n",
       "      <td>1.3022</td>\n",
       "      <td>0.193021</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertension</th>\n",
       "      <td>-0.003576</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.952879</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heart Disease</th>\n",
       "      <td>-0.175377</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.308837</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol consumption</th>\n",
       "      <td>-0.059209</td>\n",
       "      <td>1.1246</td>\n",
       "      <td>0.26091</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physical activity</th>\n",
       "      <td>-0.019755</td>\n",
       "      <td>0.2905</td>\n",
       "      <td>0.771484</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoking status</th>\n",
       "      <td>0.077234</td>\n",
       "      <td>1.1558</td>\n",
       "      <td>0.247936</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Falls</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mental Problems</th>\n",
       "      <td>0.178755</td>\n",
       "      <td>2.4613</td>\n",
       "      <td>0.01394</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.105565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adjusted R-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.09939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-squared</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.118025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Estimate    t value   p value     value\n",
       "_intercept           11.78707        0.0  0.999992          \n",
       "Age                 -0.023115  11.142468       0.0          \n",
       "Sex                 -0.315532     4.5068  0.000007          \n",
       "Diabetes              0.12309     1.5587  0.119238          \n",
       "Education             0.50985    12.7359       0.0          \n",
       "Live Alone          -0.154121     1.3022  0.193021          \n",
       "Hypertension        -0.003576     0.0591  0.952879          \n",
       "Heart Disease       -0.175377      1.018  0.308837          \n",
       "Alcohol consumption -0.059209     1.1246   0.26091          \n",
       "Physical activity   -0.019755     0.2905  0.771484          \n",
       "Smoking status       0.077234     1.1558  0.247936          \n",
       "Falls                     0.0        0.0       1.0          \n",
       "Mental Problems      0.178755     2.4613   0.01394          \n",
       "R-squared                                           0.105565\n",
       "Adjusted R-squared                                   0.09939\n",
       "F-squared                                           0.118025"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRidge_sum_costarica_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F-statisitcs, F-pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Costa Rica wave 2</th>\n",
       "      <td>[17.09388472878028, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     F-statisitcs, F-pvalue\n",
       "Costa Rica wave 2  [17.09388472878028, 0.0]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_statistics_pd.iloc[4:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>solver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>korea_2006</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1000000</td>\n",
       "      <td>lsqr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korea_2006_2014</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1000000</td>\n",
       "      <td>lsqr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korea_2006_2016</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>costarica_wave_1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1000000</td>\n",
       "      <td>cholesky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>costarica_wave_2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>svd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 alpha max_iter    solver\n",
       "korea_2006         0.1  1000000      lsqr\n",
       "korea_2006_2014    1.0  1000000      lsqr\n",
       "korea_2006_2016    1.0    10000      auto\n",
       "costarica_wave_1   1.0  1000000  cholesky\n",
       "costarica_wave_2   1.0     1000       svd"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_pd = pd.DataFrame(parameter_dict).T\n",
    "parameter_pd#.to_excel('Results/longitudinal/MMSE_hyperparameters.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99% confidence interval (+- 0.0577 )\n",
      "99% confidence interval (+- 0.0784 )\n",
      "99% confidence interval (+- 0.0826 )\n",
      "99% confidence interval (+- 0.0305 )\n",
      "99% confidence interval (+- 0.0631 )\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conf interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>korea_2006</th>\n",
       "      <td>0.0577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korea_2006_2014</th>\n",
       "      <td>0.0784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korea_2006_2016</th>\n",
       "      <td>0.0826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>costarica_wave_1</th>\n",
       "      <td>0.0305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>costarica_wave_w2</th>\n",
       "      <td>0.0631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   conf interval\n",
       "korea_2006                0.0577\n",
       "korea_2006_2014           0.0784\n",
       "korea_2006_2016           0.0826\n",
       "costarica_wave_1          0.0305\n",
       "costarica_wave_w2         0.0631"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_interval_dict = {}\n",
    "\n",
    "conf_interval_dict['korea_2006'] = [conf_interval(X_korea_2006_common_ids)]\n",
    "conf_interval_dict['korea_2006_2014'] = [conf_interval(X_korea_2006_2014_common_ids)]\n",
    "conf_interval_dict['korea_2006_2016'] = [conf_interval(X_korea_2006_2016_common_ids)]\n",
    "\n",
    "\n",
    "conf_interval_dict['costarica_wave_1'] = [conf_interval(X_costarica_w1)]\n",
    "conf_interval_dict['costarica_wave_w2'] = [conf_interval(X_costarica_w2)]\n",
    "\n",
    "\n",
    "conf_interval_pd = pd.DataFrame(conf_interval_dict, index = ['conf interval']).T\n",
    "conf_interval_pd#.to_excel('Results/longitudinal/MMSE_conf_interval.xlsx')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
